AB,NO
"this work investigates unsupervised domain adaptation (uda)-based semantic segmentation of very high-resolution (vhr) remote sensing (rs) images from different domains. most existing uda methods resort to generative adversarial networks (gans) to cope with the domain shift problem caused by the discrepancies across different domains. however, these gan-based uda methods directly align two domains in the appearance, latent, or output space based on convolutional neural networks (cnns), making them ineffective in exploiting long-range dependencies across the high-level feature maps derived from different domains. unfortunately, such high-level features play an essential role in characterizing rs images with complex content. to circumvent this obstacle, a mutually boosted attention transformer (mbatrans) is proposed to capture cross-domain dependencies of semantic feature representations in this work. compared with conventional uda methods, mbatrans can significantly reduce domain discrepancies by capturing transferable features using global attention. more specifically, mbatrans utilizes a novel mutually boosted attention (mba) module to align cross-domain feature maps while enhancing domain-general features. furthermore, a novel gan-based network with improved discriminative capability is devised by integrating an additional discriminator to learn domain-specific features. extensive experiments on two large-scale vhr rs datasets, namely, international society for photogrammetry and remote sensing (isprs) potsdam and vaihingen, confirm the superior performance of the proposed mbatrans-augmented gan (mbata-gan) architecture. the source code in this work is available at https://github.com/sstary/ssrs.",AB_0266
"to minimize the feature redundancy of multispectral (ms) and panchromatic (pan) images and maximize the complementary advantages of pan and ms, a dual-stream transformer with diff-attention (dstd)-net is proposed for pan and ms classification in this article. first, in terms of feature extraction, we use self-attention and coattention (sca) block to extract both specific advantageous features and common essential features. based on that, a self-attention module strengthened by diff-attention (ssda) that pays attention to the difference between two specific advantageous features is designed to reduce the essential redundancy in specific features. it can take advantage of the difference between two specific features and reduce the essential redundancy of the specific advantageous features, making them purer and better for classification. finally, since the specific features and common features of ms and pan images make different contributions to classification, a multistage gated fusion strategy is used. the multistage gate fusion (mgf) strategy mainly uses gated multisource units (gmus) to adapt the weight of different features and fuse them. so, our mgf strategy can strengthen the specific advantageous features beneficial for classification. above all, the several experiment results verify our proposed networks' effectiveness and robustness. our code is available at: https://github.com/blackkiring/dstd.",AB_0266
"the process of annotating hyperspectral image (hsi) data is characterized by its time-consuming and labor-intensive nature. to address this challenge, researchers often employ a meta-learning paradigm known as few-shot learning (fsl), which leverages source domains containing a substantial number of labeled samples to assist in the classification of target domains with limited labeled samples. many existing fsl methods rely on a conditional domain-adversarial strategy to mitigate the domain shift between the source and target domains. however, these methods overlook the fact that the degrees of conditional distribution discrepancies between the two domains can vary significantly across different classes, leading to suboptimal conditional distribution alignment. to address this problem, we propose a framework called adaptive domain-adversarial fsl (adafsl). overall, the proposed adafsl employs an adaptive strategy that assigns varying weights to the conditional adversarial losses for different classes based on their respective degrees of discrepancies, thereby achieving global conditional distribution alignment. specifically, a local alignment score map is constructed by measuring the similarity between labeled and unlabeled samples using both euclidean and class-covariance metrics. this map is then multiplied with the conditional adversarial loss map, thus allocating more emphasis to the classes exhibiting greater discrepancies between the two domains. moreover, to enhance cross-domain fsl, we design a multiscale spectral-spatial feature extraction (msfe) module that incorporates cascaded multiscale dilated convolutions. experimental results on four public hsi datasets demonstrate that the proposed adafsl outperforms other state-of-the-art methods. the source code of this method can be found at https://github.com/jiew-ww/adafsl.",AB_0266
"change detection (cd) using deep learning techniques is a trending topic in the field of remote sensing; however, most existing networks require pixel-level labels for supervised learning, which is difficult and time-consuming to label all changed pixels from multitemporal images. to address this challenge, we propose a novel framework for weakly supervised cd (wscd), namely cs-wscdnet, which can achieve pixel-level results by training on samples with image-level labels. specifically, the framework is built upon the localization capability of class activation mapping (cam) and the powerful zero-shot segmentation ability of the foundation model, i.e., the segment anything model (sam). after training an image-level classifier to identify whether changes have occurred in the image pair, cam is used to roughly localize the regions of change in the image pairs. subsequently, sam is employed to optimize these rough regions and generate pixel-level pseudo labels for changed objects. these pseudo labels are then used to train a cd model at the pixel level. to evaluate the effectiveness of cs-wscdnet, experiments are conducted on two high-resolution remote sensing datasets. it shows that the proposed framework not only achieves state-of-the-art (sota) performance in wscd tasks but also demonstrates the potential of weakly supervised learning in the field of cd. the demo codes are available at https://github.com/wanglukang/cs-wscdnet.",AB_0266
"hyperspectral image (hsi) classification is an important issue in remote sensing field with extensive applications in earth science. in recent years, a large number of deep learning-based hsi classification methods have been proposed. however, the existing methods have limited ability to handle high-dimensional, highly redundant, and complex data, making it challenging to capture the spectral-spatial distributions of data and relationships between samples. to address this issue, we propose a generative framework for hsi classification with diffusion models (spectraldiff) that effectively mines the distribution information of high-dimensional and highly redundant data by iteratively denoising and explicitly constructing the data generation process, thus better reflecting the relationships between samples. the framework consists of a spectral-spatial diffusion module and an attention-based classification module. the spectral-spatial diffusion module adopts forward and reverse spectral-spatial diffusion processes to achieve adaptive construction of sample relationships without requiring prior knowledge of graphical structure or neighborhood information. it captures spectral-spatial distribution and contextual information of objects in hsi and mines unsupervised spectral-spatial diffusion features within the reverse diffusion process. finally, these features are fed into the attention-based classification module for per-pixel classification. the diffusion features can facilitate cross-sample perception via reconstruction distribution, leading to improved classification performance. experiments on three public hsi datasets demonstrate that the proposed method can achieve better performance than state-of-the-art methods. for the sake of reproducibility, the source code of spectraldiff will be publicly available at https://github.com/chenning0115/spectraldiff.",AB_0266
"unsupervised domain adaptation (uda) is an important solution to reduce the bias between the labeled source domain and the unlabeled target domain. it has attracted more attention for optical remote sensing image scene classification and retrieval. currently, most of the previous work is devoted to closed-set uda. in fact, the target domain often contains unknown classes. moreover, some open uda methods mine structural information of the target domain directly from the type knowledge of the source domain and less directly from the unlabeled data of the target domain. in this article, we propose a new self-supervised-driven open-set uda (ssouda) method combining contrastive self-supervised learning with consistency self-training (cst) for optical remote sensing scene classification and retrieval. specifically, a contrastive self-supervised learning network is introduced to learn discriminative features from the unlabeled target domain data. moreover, a novel open-set class learning module is developed based on two-level confidence rules and the consistency self-training strategy, which can obtain reliable unknown class samples for co-training. finally, an open-set dataset including six cross-domain scenarios is constructed based on three public datasets, and several experiments are conducted with 11 state-of-the-art domain adaptation methods. experimental results demonstrate that our proposed method achieves superior performances on the six open-set cross-domain scenarios in both scene classification and retrieval. especially, our method improves the overall classification accuracies by 9.72%-24.06% and improves mean average retrieval precisions by 8.06%-16.21% on the complex university of california merced land use dataset (ucmd) (source domain) -> northwestern polytechnical university (nwpu) (target domain) scenario, compared with the other 11 state-of-the-art methods. our code is available at https://github.com/georsai/ssouda.",AB_0266
"recently, remote sensing image super-resolution (rsisr) has drawn considerable attention and made great breakthroughs based on convolutional neural networks (cnns). due to the scale and richness of texture and structural information frequently recurring inside the same remote sensing images (rsis) but varying greatly with different rsis, state-of-the-art cnn-based methods have begun to explore the multiscale global features in rsis by using attention mechanisms. however, they are still insufficient to explore significant content attention clues in rsis. in this article, we present a new hybrid attention-based u-shaped network (haunet) for rsisr to effectively explore the multiscale features and enhance the global feature representation by hybrid convolution-based attention. it contains two kinds of convolutional attention-based single-scale feature extraction modules (sem) to explore the global spatial context information and abstract content information, and a cross-scale interaction module (cim) as the skip connection between different scale feature outputs of encoders to bridge the semantic and resolution gaps between them. considering the existence of equipment with poor hardware facilities, we further design a lighter haunet-s with about 596k parameters. experimental attribution analysis method lam results demonstrate that our haunet is a more efficient way to capture meaningful content information and quantitative results can show that our haunet can significantly improve the performance of rsisr on four remote sensing test datasets. meanwhile, haunet-s also maintains competitive performance. our code is available at https://github.com/likakakaka/haunet_rsisr.",AB_0266
"recently, multi-object tracking (mot) has attracted rising attention, and accordingly, remarkable progresses have been achieved. however, the existing methods tend to use various basic models (e.g, detector and embedding model), and different training or inference tricks, etc. as a result, the construction of a good baseline for a fair comparison is essential. in this paper, a classic tracker, i.e., deepsort, is first revisited, and then is significantly improved from multiple perspectives such as object detection, feature embedding, and trajectory association. the proposed tracker, named strongsort, contributes a strong and fair baseline for the mot community. moreover, two lightweight and plug-and-play algorithms are proposed to address two inherent missing problems of mot: missing association and missing detection. specifically, unlike most methods, which associate short tracklets into complete trajectories at high computation complexity, we propose an appearance-free link model (aflink) to perform global association without appearance information, and achieve a good balance between speed and accuracy. furthermore, we propose a gaussian-smoothed interpolation (gsi) based on gaussian process regression to relieve the missing detection. aflink and gsi can be easily plugged into various trackers with a negligible extra computational cost (1.7 ms and 7.1 ms per image, respectively, on mot17). finally, by fusing strongsort with aflink and gsi, the final tracker (strongsort++) achieves state-of-the-art results on multiple public benchmarks, i.e., mot17, mot20, dancetrack and kitti. codes are available at https://github.com/dyhbupt/strongsort and https://github.com/open-mmlab/mmtracking.",AB_0266
"transformer has been widely used in classification tasks for hyperspectral images (hsis) in recent years. because it can mine spectral sequence information to establish long-range dependence, its classification performance can be comparable with the convolutional neural network (cnn). however, both cnn and transformer focus excessively on spatial or spectral domain features, resulting in an insufficient combination of spatial-spectral domain information from hsi for modeling. to solve this problem, we propose a new end-to-end graph convolutional network (gcn) and transformer fusion network (gtfn) with the spatial-spectral feature extraction in this article, which combines the strengths of gcn and transformer in both spatial and spectral domain feature extraction, taking full advantage of the contextual information of classified pixels while establishing remote dependencies in the spectral domain compared with previous approaches. in addition, gtfn uses follow patch as an input to the gcn and effectively solves the problem of high model complexity while mining the relationship between pixels. it is worth noting that the spectral attention module is introduced in the process of gcn feature extraction, focusing on the contribution of different spectral bands to the classification. more importantly, to overcome the problem that transformer is too scattered in the frequency domain feature extraction, a neighborhood convolution module is designed to fuse the local spectral domain features. on indian pines, salinas, and pavia university datasets, the overall accuracies (oas) of our gtfn are 94.00%, 96.81%, and 95.14%, respectively. the core code of gtfn is released at https://github.com/1useryang/gtfn.",AB_0266
"in hyperspectral image (hsi) classification, objects corresponding to pixels of different classes exhibit varying size characteristics, which causes a challenge for effective pixelwise feature extraction and classification. in this article, we propose a novel multiscale model, called multiarea target attention (mata). the proposed mata uses an architecture that includes a shared feature extractor (fe) and classifier to capture multiscale spectral-spatial information effectively and efficiently. the fe uses a multiscale target attention module (mstam) to extract spectral-spatial information from target pixels and their similar pixels across multiscale areas, while l-2-normalization is used to address discrepancies between features of different scales. the classifier adopts a classwise decision weighting strategy to account for the varying sizes of different classes and the different contributions of semantic features at each scale to each class. experimental results on five public hsi datasets demonstrate that the proposed mata outperforms existing state-of-the-art single- and multiscale models, confirming its effectiveness and efficiency in hsi classification. code is available at https://github.com/huanliu233/mata.",AB_0266
