AB,NO
"quadruplexes are four-stranded dna/rna motifs of high functional significance that fold into complex shapes. they are widely recognized as important regulators of genomic processes and are among the most frequently investigated potential drug targets. despite interest in quadruplexes, few studies focus on automatic tools that help to understand the many unique features of their 3d folds. in this paper, we introduce webtetrado, a web server for analyzing 3d structures of quadruplex structures. it has a user-friendly interface and offers many advanced features, including automatic identification, annotation, clas-sification, and visualization of the motif. the program applies to the experimental or in silico generated 3d models provided in the pdb and pdbx/mmcif files. it supports canonical g-quadruplexes as well as non-g-based quartets. it can process unimolecular, bi-molecular, and tetramolecular quadruplexes. webte-trado is implemented as a publicly available web server with an intuitive interface and can be freely accessed at https://webtetrado.cs.put.poznan.pl/.",AB_0537
"today, the huge variety of foods and the existence of different food preferences among people have made it difficult to choose the right food according to people's food preferences for different meals. also, achieving a pleasant balance between users' food preferences and health requirements, considering the physical condition, diseases/allergies of users, and having a suitable dietary diversity, has become a requirement in the field of nutrition. therefore, the need for an intelligent system to recommend and choose the proper food based on these criteria is felt more and more. in this paper, a deep learning-based food recommender system, termed foodrecnet, is presented using a comprehensive set of characteristics and features of users and foods, including users' long-term and short-term preferences, users' health conditions, demographic information, culture, religion, food ingredients, type of cooking, food category, food tags, diet, allergies, text description, and even the images of the foods. the appropriate combination of features used in the proposed system has been identified based on detailed investigations conducted in this research. in order to achieve a desired architecture of the deep artificial neural network for our purpose, five different architectures are designed and evaluated, considering the specific characteristics of the intended application in addition, to evaluate the foodrecnet, this work constructs a large-scale annotated dataset, consisting of 3,335,492 records of food information, users and their scores, and 54,554 food images. the experiments conducted on this dataset and the food.com benchmark dataset confirm the effectiveness of the combination of features used in foodrecnet. the rmse rates obtained by foodrecnet on these two datasets are 0.7167 and 0.4930, respectively, which are much better than that of competitors. all the implementation source codes and datasets of this research are made publicly available at https://github.com/saeedhamdollahi/foodrecnet.",AB_0537
"parental burnout is a growing subject of research, but thus far this research has not examined whether the features of parental burnout fluctuate over time. moreover, parenting and parental burnout are inextricable from their family context. therefore, a critical next step involves examining how parental burnout features temporally unfold and interact with the ever-changing family environment. to do so, we developed an 11-item experience sampling methodology (esm) tool to measure self-reported parental burnout features (specifically emotional exhaustion, emotional distance, and feeling fed up), as well as partner relationship, children's behavior, behavior toward children, social support, and perceived resources. we conducted two two-week periods of esm data collection (one with french-language esm items; n = 9; one with english-language esm items; n=23) and one eight-week data collection with the french-language esm items (n=50). we collected the esm data using formr , an open-source platform, and we provide open access to all materials (including a formr template, allowing free use of the assessment tool), analysis code, and data: https://osf.io/s2yv5/. participants' responses indicated sufficient within-person variability (assessed via intraclass correlation) and support for convergent and discriminant validity (assessed by correlating aggregated esm responses with retrospective questionnaire scores on parental burnout, depression, anxiety, and stress). lastly, we found that the three parental burnout esm items had high between-subject reliability and moderate within-subject reliability. participating parents found the esm survey easy to answer and not burdensome. finally, we discuss how assessing parental burnout over time can help usher parental burnout research and treatment forward.",AB_0537
"gene expression profiling has helped tremendously in the understanding of biological processes and diseases. however, interpreting processed data to gain insights into biological mechanisms remain challenging, especially to the non-bioinformaticians, as many of these data visualization and pathway analysis tools require extensive data formatting. to circumvent these challenges, we developed stages (static and temporal analysis of gene expression studies) that provides an interactive visualisation of omics analysis outputs. users can directly upload data created from excel spreadsheets and use stages to render volcano plots, differentially expressed genes stacked bar charts, pathway enrichment analysis by enrichr and gene set enrichment analysis (gsea) against established pathway databases or customized gene sets, clustergrams and correlation matrices. moreover, stages takes care of excel gene to date misconversions, ensuring that every gene is considered for pathway analysis. output data tables and graphs can be exported, and users can easily customize individual graphs using widgets such as sliders, drop-down menus, text boxes and radio buttons. collectively, stages is an integrative platform for data analysis, data visualisation and pathway analysis, and is freely available at https:// kuanr ongch an- stages- stages-vpgh46. strea mlita pp. com/. in addition, developers can customise or modify the web tool locally based on our existing codes, which is publicly available at https:// github. com/ kuanr ongch an/ stages.",AB_0537
"introductiondata linkage systems have proven to be a powerful tool in support of combating and managing the covid-19 pandemic. however, the interoperability and the reuse of different data sources may pose a number of technical, administrative and data security challenges.methods and analysisthis protocol aims to provide a case study for linking highly sensitive individual-level information. we describe the data linkages between health surveillance records and administrative data sources necessary to investigate social health inequalities and the long-term health impact of covid-19 in belgium. data at the national institute for public health, statistics belgium and intermutualistic agency are used to develop a representative case-cohort study of 1.2 million randomly selected belgians and 4.5 million belgians with a confirmed covid-19 diagnosis (pcr or antigen test), of which 108 211 are covid-19 hospitalised patients (pcr or antigen test). yearly updates are scheduled over a period of 4 years. the data set covers inpandemic and postpandemic health information between july 2020 and january 2026, as well as sociodemographic characteristics, socioeconomic indicators, healthcare use and related costs. two main research questions will be addressed. first, can we identify socioeconomic and sociodemographic risk factors in covid-19 testing, infection, hospitalisations and mortality? second, what is the medium-term and long-term health impact of covid-19 infections and hospitalisations? more specific objectives are (2a) to compare healthcare expenditure during and after a covid-19 infection or hospitalisation; (2b) to investigate long-term health complications or premature mortality after a covid-19 infection or hospitalisation; and (2c) to validate the administrative covid-19 reimbursement nomenclature. the analysis plan includes the calculation of absolute and relative risks using survival analysis methods.ethics and disseminationthis study involves human participants and was approved by ghent university hospital ethics committee: reference b.u.n. 1432020000371 and the belgian information security committee: reference beraadslaging nr. 22/014 van 11 january 2022, available via https://www.ehealth.fgov.be/ehealthplatform/file/view/ax54cwc4fbc33ie1ry5a?filename=22-014-n034-helicon-project.pdf. dissemination activities include peer-reviewed publications, a webinar series and a project website.the pseudonymised data are derived from administrative and health sources. acquiring informed consent would require extra information on the subjects. the research team is prohibited from gaining additional knowledge on the study subjects by the belgian information security committee's interpretation of the belgian privacy framework.ethics and disseminationthis study involves human participants and was approved by ghent university hospital ethics committee: reference b.u.n. 1432020000371 and the belgian information security committee: reference beraadslaging nr. 22/014 van 11 january 2022, available via https://www.ehealth.fgov.be/ehealthplatform/file/view/ax54cwc4fbc33ie1ry5a?filename=22-014-n034-helicon-project.pdf. dissemination activities include peer-reviewed publications, a webinar series and a project website.the pseudonymised data are derived from administrative and health sources. acquiring informed consent would require extra information on the subjects. the research team is prohibited from gaining additional knowledge on the study subjects by the belgian information security committee's interpretation of the belgian privacy framework.",AB_0537
"background: the prediction of potentially pathogenic variant combinations in patients remains a key task in the field of medical genetics for the understanding and detection of oligogenic/multilocus diseases. models tailored towards such cases can help shorten the gap of missing diagnoses and can aid researchers in dealing with the high complexity of the derived data. the predictor varcopp (variant combinations pathogenicity predictor) that was published in 2019 and identified potentially patho-genic variant combinations in gene pairs (bilocus variant combinations), was the first important step in this direction. despite its usefulness and applicability, several issues still remained that hindered a better performance, such as its false positive (fp) rate, the quality of its training set and its complex architecture.results: we present varcopp2.0: the successor of varcopp that is a simplified, faster and more accurate predictive model identifying potentially pathogenic bilocus variant combinations. results from cross-validation and on independent data sets reveal that varcopp2.0 has improved in terms of both sensitivity (95% in cross-validation and 98% during testing) and specificity (5% fp rate). at the same time, its running time shows a significant 150-fold decrease due to the selection of a simpler balanced random forest model. its positive training set now consists of variant combinations that are more con-fidently linked with evidence of pathogenicity, based on the confidence scores present in olida, the oligogenic diseases database (https://olida.ibsquare.be). the improve-ment of its performance is also attributed to a more careful selection of up-to-date features identified via an original wrapper method. we show that the combination of different variant and gene pair features together is important for predictions, highlighting the usefulness of integrating biological information at different levels.conclusions: through its improved performance and faster execution time, var-copp2.0 enables a more accurate analysis of larger data sets linked to oligogenic diseases. users can access the orval platform (https://orval.ibsquare.be) to apply varcopp2.0 on their data.",AB_0537
"peptide-binding proteins play significant roles in various applications such as gene expression, metabolism, signal transmission, dna (deoxyribose nucleic acid) repair, and replication. investigating the binding residues in protein-peptide complexes, especially from their sequence only, is challenging experimentally and computationally. although several computational approaches have been introduced to determine and predict these binding residues, there is still ample room to improve the prediction performance. in this work, we introduce a novel ensemble machine learning-based approach called spppred (sequence-based protein-peptide binding residue prediction) to predict protein-peptide binding residues. first, we extract relevant sequential information and employ genetic programming algorithm for feature construction to find more distinctive features. we then, in the next step, build an ensemble-based machine learning classifier to predict binding residues. the proposed method shows consistent and comparable performance on both ten-fold cross-validation and independent test set. furthermore, spppred yields f-measure (f-m), accuracy(acc), and matthews' correlation coefficient (mcc) of 0.310, 0.949, and 0.230 on the independent test set, respectively, which outperforms other competing methods by approximately up to 9% on the independent test set. spppred is publicly available https://github.com/gtaherzadeh/spppred.git.",AB_0537
"advances in visual perceptual tasks have been mainly driven by the amount, and types, of annotations of large-scale datasets. researchers have focused on fully-supervised settings to train models using offline epoch-based schemes. despite the evident advancements, limitations and cost of manually annotated datasets have hindered further development for event perceptual tasks, such as detection and localization of objects and events in videos. the problem is more apparent in zoological applications due to the scarcity of annotations and length of videos-most videos are atmost ten minutes long. inspired by cognitive theories, we present a self-supervised perceptual prediction framework to tackle the problem of temporal event segmentation by building a stable representation of event-related objects. the approach is simple but effective. we rely on lstm predictions of highlevel features computed by a standard deep learning backbone. for spatial segmentation, the stable representation of the object is used by an attention mechanism to filter the input features before the prediction step. the self-learned attention maps effectively localize the object as a side effect of perceptual prediction. we demonstrate our approach on long videos from continuous wildlife video monitoring, spanning multiple days at 25 fps. we aim to facilitate automated ethogramming by detecting and localizing events without the need for labels. our approach is trained in an online manner on streaming input and requires only a single pass through the video, with no separate training set. given the lack of long and realistic (includes real-world challenges) datasets, we introduce a new wildlife video dataset-nest monitoring of the kagu (a flightless bird from new caledonia)-to benchmark our approach. our dataset features a video from 10 days (over 23 million frames) of continuous monitoring of the kagu in its natural habitat. we annotate every frame with bounding boxes and event labels. additionally, each frame is annotated with time-of-day and illumination conditions. wewill make the dataset, which is the first of its kind, and the code available to the research community. we find that the approach significantly outperforms other selfsupervised, traditional (e.g., optical flow, background subtraction) and nn-based (e.g., pa-dpc, dino, ibot), baselines and performs on par with supervised boundary detection approaches (i.e., pc). at a recall rate of 80%, our best performing model detects one false positive activity every 50min of training. on average, we at least double the performance of selfsupervised approaches for spatial segmentation. additionally, we show that our approach is robust to various environmental conditions (e.g., moving shadows). we also benchmark the framework on other datasets (i.e., kinetics-gebd, tapos) from different domains to demonstrate its generalizability. the data and code are available on our project page: https://aix.eng.usf. edu/ research_automated_ethogramming.html",AB_0537
"deep neural network models are used today in various applications of artificial intelligence, the strength-ening of which, in the face of adversarial attacks is of particular importance. an appropriate solution to adversarial attacks is adversarial training, which reaches a trade-off between robustness and generaliza-tion. this paper introduces a novel framework (layer sustainability analysis (lsa)) for the analysis of layer vulnerability in an arbitrary neural network in the scenario of adversarial attacks. lsa can be a help-ful toolkit to assess deep neural networks and to extend the adversarial training approaches towards improving the sustainability of model layers via layer monitoring and analysis. the lsa framework iden-tifies a list of most vulnerable layers (mvl list) of the given network. the relative error, as a comparison measure, is used to evaluate representation sustainability of each layer against adversarial inputs. the proposed approach for obtaining robust neural networks to fend off adversarial attacks is based on a layer-wise regularization (lr) over lsa proposal(s) for adversarial training (at). this means that the at-lr procedure could be used with any benchmark adversarial attack to reduce the vulnerability of net -work layers and to improve conventional adversarial training approaches. the proposed idea performs well theoretically and experimentally for state-of-the-art multilayer perceptron and convolutional neural network architectures. additionally, a measure named robustness and generalization score or r&g score is defined to better evaluate each adversarially trained model over a variety of significant perturbations. compared with the at-lr and its corresponding base adversarial training, the r&g score on moon, mnist, and cifar-10 benchmark datasets was increased by 56.52%, 75.82%, and 6.54%, respectively for more significant perturbations. the lsa framework is available and published at https://github.com/kha-looei/lsa. (c) 2023 elsevier b.v. all rights reserved.",AB_0537
"funding innovation requires knowledge on previous/on-going research and identification of gaps and synergies among actors, networks and projects, but targeted databases remain scattered, incomplete and scarcely searchable. here we present the bluebio database: a first comprehensive and robust compilation of internationally and nationally funded research projects active in the years 2003-2019 in fisheries, aquaculture, seafood processing and marine biotechnology. based on the previous research projects' database realized in the framework of the cofasp era-net, it was implemented within the era-net cofund bluebio project through a 4-years data collection including 4 surveys and a wide data retrieval. after being integrated, data were harmonised, shared as open and disseminated through a webgis that was key for data entry, update and validation. the database consists of 3,254 georeferenced projects, described by 22 parameters that are clustered into textual and spatial, some directly collected while others deduced. the database is a living archive to inform actors of the blue bioeconomy sector in a period of rapid transformations and research needs and is freely available at: https://doi.org/10.6084/m9.figshare.21507837.v3.",AB_0537
