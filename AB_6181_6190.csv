AB,NO
"motivation: multiple sequence alignment (msa) is a basic step in many bioinformatics pipelines. however, achieving highly accurate alignments on large datasets, especially those with sequence length heterogeneity, is a challenging task. ultra-large multiple sequence alignment using phylogeny-aware profiles (upp) is a method for msa estimation that builds an ensemble of hidden markov models (ehmm) to represent an estimated alignment on the full-length sequences in the input, and then adds the remaining sequences into the alignment using selected hmms in the ensemble. although upp provides good accuracy, it is computationally intensive on large datasets. results: we present upp2, a direct improvement on upp. the main advance is a fast technique for selecting hmms in the ensemble that allows us to achieve the same accuracy as upp but with greatly reduced runtime. we show that upp2 produces more accurate alignments compared to leading msa methods on datasets exhibiting substantial sequence length heterogeneity and is among the most accurate otherwise. availability and implementation: https://github.com/gillichu/sepp. contact: warnow@illinois.edu supplementary information: supplementary data are available at bioinformatics online.",AB_0619
"phylodynamic methods are central to studies of the geographic and demographic history of disease outbreaks. inference under discrete-geographic phylodynamic models-which involve many parameters that must be inferred from minimal information-is inherently sensitive to our prior beliefs about the model parameters. we present an interactive utility, prioritree, to help researchers identify and accommodate prior sensitivity in discrete-geographic inferences. specifically, prioritree provides a suite of functions to generate input files for-and summarize output from-beast analyses for performing robust bayesian inference, data-cloning analyses and assessing the relative and absolute fit of candidate discrete-geographic (prior) models to empirical datasets. availability and implementation: prioritree is distributed as an r package available at https://github.com/jsigao/prioritree, with a comprehensive user manual provided at https://bookdown.org/jsigao/prioritree_manual/. contact: jsigao@ucdavis.edu",AB_0619
"motivation: a recurring challenge in interpreting genomic data is the assessment of results in the context of existing reference databases. with the increasing number of command line and python users, there is a need for tools implementing automated, easy programmatic access to curated reference information stored in a diverse collection of large, public genomic databases. results: gget is a free and open-source command line tool and python package that enables efficient querying of genomic reference databases, such as ensembl. gget consists of a collection of separate but interoperable modules, each designed to facilitate one type of database querying required for genomic data analysis in a single line of code. availability and implementation: the manual and source code are available at https://github.com/pachterlab/gget. contact: lpachter@caltech.edu supplementary information: supplementary data are available at bioinformatics online.",AB_0619
"motivation in the training of predictive models using high-dimensional genomic data, multiple studies' worth of data are often combined to increase sample size and improve generalizability. a drawback of this approach is that there may be different sets of features measured in each study due to variations in expression measurement platform or technology. it is often common practice to work only with the intersection of features measured in common across all studies, which results in the blind discarding of potentially useful feature information that is measured in individual or subsets of studies. results we characterize the loss in predictive performance incurred by using only the intersection of feature information available across all studies when training predictors using gene expression data from microarray and sequencing datasets. we study the properties of linear and polynomial regression for imputing discarded features and demonstrate improvements in the external performance of prediction functions through simulation and in gene expression data collected on breast cancer patients. to improve this process, we propose a pairwise strategy that applies any imputation algorithm to two studies at a time and averages imputed features across pairs. we demonstrate that the pairwise strategy is preferable to first merging all datasets together and imputing any resulting missing features. finally, we provide insights on which subsets of intersected and study-specific features should be used so that missing-feature imputation best promotes cross-study replicability. availability and implementation: the code is available at https://github.com/yujiewuu/pairwise_imputation. contact: patil@bu.edu supplementary information: supplementary information is available at bioinformatics online.",AB_0619
"chromosome conformation capture (3 c) is a method of measuring chromosome topology in terms of loci interaction. the hi-c method is a derivative of 3 c that allows for genome-wide quantification of chromosome interaction. from such interaction data, it is possible to infer the three-dimensional (3d) structure of the underlying chromosome. in this paper, we developed a novel method, hic-gnn, for predicting the 3d structures of chromosomes from hi-c data. hic-gnn is unique from other methods for chromosome structure prediction in that the models learned by hic-gnn can be generalized to data that is distinct from the training data. this aspect of hic-gnn allows models that were trained on one hi-c contact map to be used for inference on entirely different maps. to the authors' knowledge, this generalizing capability is not present in any existing methods. hic-gnn uses a node embedding algorithm and a graph neural network to predict the 3d coordinates of each genomic loci from the corresponding hi-c contact data. unlike other methods, our algorithm allows for the storage of pre-trained parameters, thus enabling prediction on data that is entirely different from the training data. we show that our method can accurately generalize a single model across hi-c resolutions, multiple restriction enzymes, and multiple cell populations while maintaining reconstruction accuracy across three hi-c datasets. our algorithm outperforms the state-of-the-art methods in accuracy of prediction and runtime and introduces a novel method for 3d structure prediction from hi-c data. all our source codes and data are available at https://github.com/oluwadarelab/hic-gnn.(c) 2023 the authors. published by elsevier b.v. on behalf of research network of computational and structural biotechnology. this is an open access article under the cc by license ().",AB_0619
"protein language modeling is a fast-emerging deep learning method in bioinformatics with diverse applications such as structure prediction and protein design. however, application toward estimating sequence conservation for functional site prediction has not been systematically explored. here, we present a method for the alignment-free estimation of sequence conservation using sequence embeddings generated from protein language models. comprehensive benchmarks across publicly available protein language models reveal that esm2 models provide the best performance to computational cost ratio for conservation estimation. applying our method to full-length protein sequences, we demonstrate that embedding-based methods are not sensitive to the order of conserved elements conservation scores can be calculated for multidomain proteins in a single run, without the need to separate individual domains. our method can also identify conserved functional sites within fast-evolving sequence regions (such as domain inserts), which we demonstrate through the identification of conserved phosphorylation motifs in variable insert segments in protein kinases. overall, embedding-based conservation analysis is a broadly applicable method for identifying potential functional sites in any full-length protein sequence and estimating conservation in an alignment-free manner. to run this on your protein sequence of interest, try our scripts at https://github.com/esbgkannan/kibby.",AB_0619
"characterization of gene lists obtained from high-throughput genomic experiments is an essential task to uncover the underlying biological insights. a common strategy is to perform enrichment analyses that utilize standardized biological annotations, such as go and kegg pathways, which attempt to encompass all domains of biology. however, this approach provides generalized, static results that may fail to capture subtleties associated with research questions within a specific domain. thus, there is a need for an application that can provide precise, relevant results by leveraging the latest research. we have therefore developed an interactive web application, macrophage annotation of gene network enrichment tool (magnet), for performing enrichment analyses on gene sets that are specifically relevant to macrophages. using the hypergeometric distribution, magnet assesses the significance of overlapping genes with annotations that were curated from published manuscripts and data repositories. we implemented numerous features that enhance utility and user-friendliness, such as the simultaneous testing of multiple gene sets, different visualization options, option to upload custom datasets, and downloadable outputs. here, we use three example studies compared against our current database of ten publications on mouse macrophages to demonstrate that magnet provides relevant and unique results that complement conventional enrichment analysis tools. although specific to macrophage datasets, we envision magnet will catalyze developments of similar applications in other domains of interest. magnet can be freely accessed at the url https://magnet-winterlab.herokuapp.com. website implemented in python and postgresql, with all major browsers supported. the source code is available at https://github.com/sychen9584/magnet.",AB_0619
"motivation: biological networks can provide a system-level understanding of underlying processes. in many contexts, networks have a high degree of modularity, i.e. they consist of subsets of nodes, often known as subnetworks or modules, which are highly interconnected and may perform separate functions. in order to perform subsequent analyses to investigate the association between the identified module and a variable of interest, a module summarization, that best explains the module's information and reduces dimensionality is often needed. conventional approaches for obtaining network representation typically rely only on the profiles of the nodes within the network while disregarding the inherent network topological information. results: in this article, we propose netshy, a hybrid approach which is capable of reducing the dimension of a network while incorporating topological properties to aid the interpretation of the downstream analyses. in particular, netshy applies principal component analysis (pca) on a combination of the node profiles and the well-known laplacian matrix derived directly from the network similarity matrix to extract a summarization at a subject level. simulation scenarios based on random and empirical networks at varying network sizes and sparsity levels show that netshy outperforms the conventional pca approach applied directly on node profiles, in terms of recovering the true correlation with a phenotype of interest and maintaining a higher amount of explained variation in the data when networks are relatively sparse. the robustness of netshy is also demonstrated by a more consistent correlation with the observed phenotype as the sample size decreases. lastly, a genome-wide association study is performed as an application of a downstream analysis, where netshy summarization scores on the biological networks identify more significant single nucleotide polymorphisms than the conventional network representation. availability and implementation: r code implementation of netshy is available at https://github.com/thaovu1/netshy contact: thao.3.vu@cuanschutz.edu or katerina.kechris@cuanschutz.edu supplementary information: supplementary data are available at bioinformatics online.",AB_0619
"the pmartr (https://github.com/pmartr/pmartr) package was designed for the quality control (qc) and analysis of mass spectrometry data, tailored to specific characteristics of proteomic (isobaric or labeled), metabolomic, and lipidomic data sets. since its initial release, the tool has been expanded to address the needs of its growing userbase and now includes qc and statistics for nuclear magnetic resonance metabolomic data, and leverages the deseq2, edger, and limma-voom r packages for transcriptomic data analyses. these improvements have made progress toward a unified omics processing pipeline for ease of reporting and streamlined statistical purposes. the package's statistics and visualization capabilities have also been expanded by adding support for paired data and by integrating pmartr with the trelliscopejs r package for the quick creation of trellis displays (https:// github.com/hafen/trelliscopejs). here, we present relevant examples of each of these enhancements to pmartr and highlight how each new feature benefits the omics community.",AB_0619
"deep convolutional neural networks (cnns) are broadly considered to be state-of-the-art generic end -to-end image classification systems. however, they are known to underperform when training data are limited and thus require data augmentation strategies that render the method computationally expen-sive and not always effective. rather than using a data augmentation strategy to encode invariances as typically done in machine learning, here we propose to mathematically augment a nearest subspace clas-sification model in sliced-wasserstein space by exploiting certain mathematical properties of the radon cumulative distribution transform (r-cdt), a recently introduced image transform. we demonstrate that for a particular type of learning problem, our mathematical solution has advantages over data augmenta-tion with deep cnns in terms of classification accuracy and computational complexity, and is particularly effective under a limited training data setting. the method is simple, effective, computationally efficient, non-iterative, and requires no parameters to be tuned. python code implementing our method is avail-able at https://github.com/rohdelab/mathematical _ augmentation . our method is integrated as a part of the software package pytranskit, which is available at https://github.com/rohdelab/pytranskit .(c) 2022 elsevier ltd. all rights reserved.",AB_0619
