AB,NO
"motivation federated learning (fl) is gaining traction in various fields as it enables integrative data analysis without sharing sensitive data, such as in healthcare. however, the risk of data leakage caused by malicious attacks must be considered. in this study, we introduce a novel attack algorithm that relies on being able to compute sample means, sample covariances, and construct known linearly independent vectors on the data owner side.results we show that these basic functionalities, which are available in several established fl frameworks, are sufficient to reconstruct privacy-protected data. additionally, the attack algorithm is robust to defense strategies that involve adding random noise. we demonstrate the limitations of existing frameworks and propose potential defense strategies analyzing the implications of using differential privacy. the novel insights presented in this study will aid in the improvement of fl frameworks.availability and implementation the code examples are provided at github (https://github.com/manuhuth/data-leakage-from-covariances.git). the cnsim1 dataset, which we used in the manuscript, is available within the dsdata r package (https://github.com/datashield/dsdata/tree/main/data).",AB_0483
"introduction by 2050, the worldwide percentage of people 65 years and older is assumed to have doubled compared to current numbers. therefore, finding ways of promoting healthy (cognitive) aging is crucial. physical activity is considered an effective approach to counteract not only physical but also cognitive decline. however, the underlying mechanisms that drive the benefits of regular physical activity on cognitive function are not fully understood. this randomized controlled trial aims to analyze the effect of an eight-week standardized physical activity training program in older humans on cognitive, brain, and gut-barrier function as well as the relationship between the resulting changes.methods and analysis one-hundred healthy participants aged 60 to 75 years will be recruited. first, participants will undergo an extensive baseline assessment consisting of neurocognitive tests, functional and structural brain imaging, physical fitness tests, and gut-microbiome profiling. next, participants will be randomized into either a multi-component physical activity group (experimental condition) or a relaxation group (active control condition), with each training lasting 8 weeks and including an equal number and duration of exercises. the whole intervention will be online-based, i.e., participants will find their intervention schedule and all materials needed on the study website. after the intervention phase, participants will have their post-intervention assessment, which consists of the same measures and tests as the baseline assessment. the primary outcome of this study is the change in the cognitive parameter of visual processing speed from baseline to post-measurement, which will on average take place 10 weeks after the randomization. secondary outcomes related to cognitive, brain, and microbiome data will be analyzed exploratory. clinical trial registration: https://drks.de/search/de/trial/drks00028022methods and analysis one-hundred healthy participants aged 60 to 75 years will be recruited. first, participants will undergo an extensive baseline assessment consisting of neurocognitive tests, functional and structural brain imaging, physical fitness tests, and gut-microbiome profiling. next, participants will be randomized into either a multi-component physical activity group (experimental condition) or a relaxation group (active control condition), with each training lasting 8 weeks and including an equal number and duration of exercises. the whole intervention will be online-based, i.e., participants will find their intervention schedule and all materials needed on the study website. after the intervention phase, participants will have their post-intervention assessment, which consists of the same measures and tests as the baseline assessment. the primary outcome of this study is the change in the cognitive parameter of visual processing speed from baseline to post-measurement, which will on average take place 10 weeks after the randomization. secondary outcomes related to cognitive, brain, and microbiome data will be analyzed exploratory.",AB_0483
"the localization of messenger rnas (mrnas) is a frequently observed phenomenon and a crucial aspect of gene expression regulation. it is also a mechanism for targeting proteins to a specific cellular region. moreover, prior research and studies have shown the significance of intracellular rna positioning during embryonic and neural dendrite formation. incorrect rna localization, which can be caused by a variety of factors, such as mutations in trans-regulatory elements, has been linked to the development of certain neuromuscular diseases and cancer. in this study, we introduced nn-rnaloc, a neural network-based method for predicting the cellular location of mrna using novel features extracted from mrna sequence data and protein interaction patterns. in fact, we developed a distance-based subsequence profile for rna sequence representation that is more memory and time-efficient than well-known k-mer sequence representation. combining protein-protein interaction data, which is essential for numerous biological processes, with our novel distance-based subsequence profiles of mrna sequences produces more accurate features. on two benchmark datasets, cefra-seq and rnalocate, the performance of nn-rnaloc is compared to powerful predictive models proposed in previous works (mrnaloc, rnatracker, mloc-mrna, dm3loc, iloc-mrna, and el-rmlocnet), and a ground neural (dnn5-mer) network. compared to the previous methods, nn-rnaloc significantly reduces computation time and also outperforms them in terms of accuracy. this study's source code and datasets are freely accessible at https://github.com/neginbabaiha/nn-rnaloc.",AB_0483
"background: partitioning around medoids (pam) is one of the most widely used and successful clustering method in many fields. one of its key advantages is that it only requires a distance or a dissimilarity between the individuals, and the fact that cluster centers are actual points in the data set means they can be taken as reliable representatives of their classes. however, its wider application is hampered by the large amount of memory needed to store the distance matrix (quadratic on the number of individuals) and also by the high computational cost of computing such distance matrix and, less importantly, by the cost of the clustering algorithm itself. results: therefore, new software has been provided that addresses these issues. this software, provided under gpl license and usable as either an r package or a c++ library, calculates in parallel the distance matrix for different distances/dissimilarities (l-1, l-2, pearson, cosine and weighted euclidean) and also implements a parallel fast version of pam (fastpam1) using any data type to reduce memory usage. moreover, the parallel implementation uses all the cores available in modern computers which greatly reduces the execution time. besides its general application, the software is especially useful for processing data of single cell experiments. it has been tested in problems including clustering of single cell experiments with up to 289,000 cells with the expression of about 29,000 genes per cell. conclusions: comparisons with other current packages in terms of execution time have been made. the method greatly outperforms the available r packages for distance matrix calculation and also improves the packages that implement the pam itself. the software is available as an r package at https://cran.r-project.org/packa ge=scellpam and as c++ libraries at https://github.com/jdmde/jmatlib and https://github.com/jdmde/ppamlib the package is useful for single cell rna-seq studies but it is also applicable in other contexts where clustering of large data sets is required.",AB_0483
"current mechanistic chromatography process modeling methods lack the ability to account for the impact of experimental errors beyond detector noise (e.g. pump delays and variable feed composition) on the uncertainty in calibrated model parameters and the resulting model-predicted chromatograms. this paper presents an uncertainty quantification method that addresses this limitation by determining the probability distribution of parameters in calibrated models, taking into consideration multiple realistic sources of experimental error. the method, which is based on bayes' theorem and utilizes markov chain monte carlo with an ensemble sampler, is demonstrated to be robust and extensible using synthetic and industrial data. the corresponding software is freely available as open-source code at https://github.com/modsim/cadet-match.",AB_0483
"we present pypept, a set of executables and underlying python-language classes to easily create, manipulate, and analyze peptide molecules using the fasta, helm, or recently-developed biln notations. the framework enables the analysis of both pure proteinogenic peptides as well as those with non-natural amino acids, including support to assemble a customizable monomer library, without requiring programming. from line notations, a peptide is transformed into a molecular graph for 2d depiction tasks, the calculation of physicochemical properties, and other systematic analyses or processing pipelines. the package includes a module to rapidly generate approximate peptide conformers by incorporating secondary structure restraints either given by the user or predicted via pypept, and a wrapper tool is also provided to automate the generation and output of 2d and 3d representations of a peptide directly from the line notation. helm and biln notations that include circular, branched, or stapled peptides are fully supported, eliminating errors in structure creation that are prone during manual drawing and connecting. the framework and common workflows followed in pypept are described together with illustrative examples. pypept has been released at: https://github.com/boehringer-ingelheim/pypept.",AB_0483
"we provide a comprehensive study of observable spectra from dark matter pair-annihilation or decay into sterile (right-handed) neutrinos. this occurs, for instance, in neutrino portal dark matter models, where a sterile neutrino acts as the portal between dark matter and the standard model sector. the subsequent decays of right-handed neutrinos produce detectable standard model particles, notably photons, positrons, and neutrinos. we study the phenomenology of models where the right-handed neutrino masses are below the gev scale, as well as models where they are at, or significantly heavier than, the tev scale. in both instances, and for different reasons, the standard tools, including monte carlo simulations, are both inadequate and inaccurate. we present the complete framework to compute the relevant branching ratios for right-handed neutrino decays and the spectra of secondary photons, positrons, and neutrinos for a broad range of dark matter and right-handed neutrino masses. we discuss the general features of such signals, and compare the spectra to standard signals from dark matter annihilation/decay into bottom quarks. additionally, we provide open source code (the code is available at https://github.com/loganamorrison/blackthorn) that can be used to compute such spectra.",AB_0483
"the ontology for avida (ontoavida) aims to develop an integrated vocabulary for the description of avida, the most widely used computational approach for performing experimental evolution using digital organisms-self-replicating computer programs that evolve within a user-defined computational environment. the lack of a clearly defined vocabulary makes some biologists feel reluctant to embrace the field of digital evolution. this integrated framework empowers biologists by equipping them with the necessary tools to explore and analyze the field of digital evolution more effectively. by leveraging the vocabulary of avida, researchers can gain deeper insights into the evolutionary processes and dynamics of digital organisms. in addition, ontoavida allows researchers to make inference based on certain rules and constraints, facilitate the reproducibility of in silico evolution experiments and trace the provenance of the data stored in avidadb-an rdf database containing the genomes, transcriptomes, and phenotypes of more than a million digital organisms. ontoavida is part of the open biological and biomedical ontologies (obo foundry) and is available at http://www.obofoundry.org/ontology/ontoavida.html.",AB_0483
"introductionmultidisciplinary team meetings (mdms), also known as tumor conferences, are a cornerstone of cancer treatments. however, barriers such as incomplete patient information or logistical challenges can postpone tumor board decisions and delay patient treatment, potentially affecting clinical outcomes. therapeutic assistance and decision algorithms for hepatobiliary tumor boards (adboard) aims to reduce this delay by providing automated data extraction and high-quality, evidence-based treatment recommendations.methods and analysiswith the help of natural language processing, relevant patient information will be automatically extracted from electronic medical records and used to complete a classic tumor conference protocol. a machine learning model is trained on retrospective mdm data and clinical guidelines to recommend treatment options for patients in our inclusion criteria. study participants will be randomized to either mdm with adboard (arm a: mdm-ab) or conventional mdm (arm b: mdm-c). the concordance of recommendations of both groups will be compared using interrater reliability. we hypothesize that the therapy recommendations of adboard would be in high agreement with those of the mdm-c, with a cohen's kappa value of & ge; 0.75. furthermore, our secondary hypotheses state that the completeness of patient information presented in mdm is higher when using adboard than without, and the explainability of tumor board protocols in mdm-ab is higher compared to mdm-c as measured by the system causability scale.discussionthe implementation of adboard aims to improve the quality and completeness of the data required for mdm decision-making and to propose therapeutic recommendations that consider current medical evidence and guidelines in a transparent and reproducible manner.ethics and disseminationthe project was approved by the ethics committee of the charite - universitatsmedizin berlin.registration detailsthe study was registered on clinicaltrials.gov (trial identifying number: nct05681949; https://clinicaltrials.gov/study/nct05681949) on 12 january 2023.",AB_0483
"safety is critical for autonomous driving, and one aspect of improving safety is to accurately capture the uncertainties of the perception system, especially knowing the unknown. different from only providing deterministic or probabilistic results, e.g., probabilistic object detection, that only provide partial information for the perception scenario, we propose a complete probabilistic model named gevbev. it interprets the 2d driving space as a probabilistic bird's eye view (bev) map with point-based spatial gaussian distributions, from which one can draw evidence as the parameters for the categorical dirichlet distribution of any new sample point in the continuous driving space. the experimental results show that gevbev not only provides more reliable uncertainty quantification but also outperforms the previous works on the benchmarks opv2v and v2v4real of bev map interpretation for cooperative perception in simulated and real-world driving scenarios, respectively. a critical factor in cooperative perception is the data transmission size through the communication channels. gevbev helps reduce communication overhead by selecting only the most important information to share from the learned uncertainty, reducing the average information communicated by 87% with only a slight performance drop. our code is published at https://github.com/yuanyunshuang/gevbev.",AB_0483
