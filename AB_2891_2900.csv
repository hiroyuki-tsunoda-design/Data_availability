AB,NO
"in recent years, unconstrained iris biometrics has become more prevalent due to its wide range of user applications. however, it also presents numerous challenges to the iris pre-processing task of localization and segmentation (ils). many ils techniques have been proposed to address these challenges, among which the most effective is the cnn-based methods. training the cnn is data-intensive, and most of the existing cnn-based ils approaches do not incorporate iris-specific features that can reduce their data dependence, despite the limited labelled iris data in the available databases. these trained cnn models built upon these databases can be sub-optimal. hence, this paper proposes a guided cnn-based ils approach irisguidenet. irisguidenet involves incorporating novel iris-specific heuristics named iris regularization term (irt), deep supervision technique, and hybrid loss functions in the training pipeline, which guides the network and reduces the model data dependence. a novel iris infusion module (iim) that utilizes the geometrical relationships between the ils outputs to refine the predicted outputs is introduced at network inference. the proposed model is trained and evaluated with various datasets. experimental results show that irisguidenet has outperformed most models across all the database categories. the codes implementation of the proposed irisguidenet will be available at: https://github.com/mohdjawadi/irisguidenet.",AB_0290
"road extraction from remote sensing (rs) images in very high resolution is important for autonomous driving and road planning. compared with large-scale objects, roads are smaller, winding, and likely to be covered by buildings' shadows, causing deep convolutional neural networks (dcnns) to be difficult to identify roads. the letter proposes a semantics-geometry framework (sgnet) with a two-branch backbone, i.e., semantics-dominant branch and geometry-dominant branch. the semantics-dominant branch inputs images to predict dense semantic features, and the geometry-dominant branch takes images to generate sparse boundary features. then, dense semantic features and boundary details generated by two branches are adaptively fused. further, by utilizing affinity between neighborhood pixels, a feature refinement module (frm) is proposed to refine textures and road details. we evaluate the sgnet on the ottawa road dataset. experiments show that the sgnet outperforms other competitors on the road extraction task. codes is available at https://github.com/qiuluyi/sgnet.",AB_0290
"unsupervised domain adaptation (uda) is an approach to minimizing the domain gap. generative methods are common approaches to minimizing the domain gap of aerial images, which improves the performance of the downstream tasks, for example, cross-domain semantic segmentation. for aerial images, the digital surface model (dsm) is usually available in both the source domain and the target domain. depth information in dsm brings external information to generative models. however, little research utilizes it. in this letter, depth-assisted residualgan (drdg) is proposed where depth supervised loss (dsl) and depth cycle consistency loss (dccl) are used to bring depth information into the generative model. experimental results show that drdg reaches state-of-the-art accuracy between generative methods in cross-domain semantic segmentation tasks. source code is available at https://github.com/miemieyanga/residualgan-drdg.",AB_0290
"detecting objects in remote sensing images (rsis) using oriented bounding boxes (obbs) is flourishing but challenging, wherein the design of obb representations is the key to achieving accurate detection. in this article, we focus on two issues that hinder the performance of the two-stage oriented detectors: 1) the notorious boundary discontinuity problem, which would result in significant loss increases in boundary conditions, and 2) the inconsistency in regression schemes between the two stages. we propose a simple and effective bounding box representation by drawing inspiration from the polar coordinate system and integrate it into two detection stages to circumvent the two issues. the first stage specifically initializes four quadrant points as the starting points of the regression for producing high-quality oriented candidates without any postprocessing. in the second stage, the final localization results are refined using the proposed novel bounding box representation, which can fully release the capabilities of the oriented detectors. such consistency brings a good trade-off between accuracy and speed. with only flipping augmentation and single-scale training and testing, our approach with resnet-50-fpn harvests 76.25% map on the dota dataset with a speed of up to 16.5 frames/s, achieving the best accuracy and the fastest speed among the mainstream two-stage oriented detectors. additional results on the dior-r and hrsc2016 datasets also demonstrate the effectiveness and robustness of our method. the source code is publicly available at https://github.com/yanqingyao1994/qpdet.",AB_0290
"since light is scattered and absorbed by water, underwater images have inherent degradation (e.g., hazing, color shift), consequently impeding the development of remotely operated vehicles (rovs). toward this end, we propose a novel method, referred to as best of both worlds (boths). with parameters of only 0.0064 m, boths can be considered a super lightweight neural network for underwater image enhancement. on the whole, it has three levels: structure and detail features; pixel and channel dimensions; high-and low-frequency information. each of these three levels represents best of both worlds. initially, by interacting with structure and detail features, boths can focus on these two aspects at the same time. further, our network can simultaneously consider channel and pixel dimensions through 3-d attention learning, which is more similar to human visual perception. lastly, the proposed model can focus on high-and low-frequency information, through a novel loss function based on the wavelet transforms. upon subsequent analysis and evaluation, boths has shown superior performance compared with state-of-the-art (sota) methods. our models and datasets are publicly available at: https://github.com/perseverancelx/boths.",AB_0290
"a transformer has received a lot of attention in computer vision. because of global self-attention, the computational complexity of transformer is quadratic with the number of tokens, leading to limitations for practical applications. hence, the computational complexity issue can be efficiently resolved by computing the self-attention in groups of smaller fixed-size windows. in this article, we propose a novel pyramid shuffleand-reshuffle transformer (psrt) for the task of multispectral and hyperspectral image fusion (mhif). considering the strong correlation among different patches in remote sensing images and complementary information among patches with high similarity, we design shuffle-and-reshuffle (sar) modules to consider the information interaction among global patches in an efficient manner. besides, using pyramid structures based on window self-attention, the detail extraction is supported. extensive experiments on four widely used benchmark datasets demonstrate the superiority of the proposed psrt with a few parameters compared with several state-of-the-art approaches. the related code is available at https://github.com/dengshangqi/psrthttps://github.com/deng-shangqi/psrt.",AB_0290
"the prediction of drug-target protein interaction (dti) is a crucial task in the development of new drugs in modern medicine. accurately identifying dti through computer simulations can significantly reduce development time and costs. in recent years, many sequence-based dti prediction methods have been proposed, and introducing attention mechanisms has improved their forecasting performance. however, these methods have some shortcomings. for example, inappropriate dataset partitioning during data preprocessing can lead to overly optimistic prediction results. additionally, only single non-covalent intermolecular interactions are considered in the dti simulation, ignoring the complex interactions between their internal atoms and amino acids. in this paper, we propose a network model called mutual-dti that predicts dti based on the interaction properties of sequences and a transformer model. we use multi-head attention to extract the long-distance interdependent features of the sequence and introduce a module to extract the sequence's mutual interaction features in mining complex reaction processes of atoms and amino acids. we evaluate the experiments on two benchmark datasets, and the results show that mutual-dti outperforms the latest baseline significantly. in addition, we conduct ablation experiments on a label-inversion dataset that is split more rigorously. the results show that there is a significant improvement in the evaluation metrics after introducing the extracted sequence interaction feature module. this suggests that mutual-dti may contribute to modern medical drug development research. the experimental results show the effectiveness of our approach. the code for mutual-dti can be downloaded from https://github.com/a610lab/mutual-dti.",AB_0290
"hashing for localization (hfl) is an effective method for fast localizing specific scenes in a large-scale remote sensing image. key to its efficiency arises from a comprehensive deep hashing network that generates representational binary hash codes for image patches cropped from the remote sensing image. on the other hand, this article will investigate the problem of encrypting the remote sensing image against the hfl task. we refer to the new task as encrypting hashing against localization (ehal). we characterize the ehal task in term of two cues: 1) an encrypted image patch is supposed to appear as visually similar to its original image patch as possible and 2) the hash code generated by the deep hashing network for the encrypted image patch is supposed to be not close to its original class but close to a different class. following the two cues, we develop an encrypted patch generator, which is trained in an adversarial fashion. based on the encrypted patch generator, we propose two remote sensing image encryption frameworks that can cause nonlocalization and mislocalization to the hfl task separately. experiments validates the effectiveness of our method. reproducible executions are given at https://github.com/jingpenghan/ehal.",AB_0290
"deep unfolding networks have obtained satisfactory performance in the pansharpening task owing to their sufficient interpretability. inspired by the back-projection (bp) mechanism, we propose a bp-driven model, spatial-spectral dual back-project network (s2dbpn), to fuse the low spatial resolution multi spectral (lr ms) and the high spatial resolution panchromatic (pan) images by exploiting the bp in spatial and spectral domains. specifically, the proposed s2dbpn is made up of a spatial bp network, a spectral bp network, and a reconstruction network. in the spatial bp network, spatial down-and up projection modules are derived from bp, which is responsible for the projection of the lr ms image into the spatial domain. by analogy with the spatial bp, we reformulate the degradation between high spatial resolution multispectral (hr ms) and pan images as spectral down-and up-projections. then, the spectral bp network is constructed for the projection of the pan image along the channel dimension. finally, the features from spatial and spectral bp networks are integrated to produce the desired hr ms image through the reconstruction network. compared to the state-of-the-art methods, extensive experiments on quickbird, geoeye-1, and worldview-2 datasets demonstrate that our (sdbpn)-d-2 produces better hr ms images in terms of qualitative and quantitative evaluation metrics. the code of s2dbpn is released at: https://github.com/rsmagneto/s2dbpn.",AB_0290
"recently, due to the powerful capability at modeling the long-range relationships, transformer-based methods have been widely explored in many research areas, including hyperspectral image (hsi) classification. however, because of lots of trainable parameters and the lack of inductive bias, it is difficult to train a transformer-based hsi classifier, especially when the number of training samples is limited. to address this issue, in this study, spectral-spatial masked transformer (ss-mtr) is explored for hsi classification, which uses a two-stage training strategy. in the first stage, ss-mtr pretrains a vanilla transformer via reconstruction from masked hsi inputs, which embeds the local inductive bias into the transformer. in the second stage, the well pretrained transformer is cooperated with a fully connected layer and is then fine-tuned for the hsi classification. furthermore, in order to incorporate discriminative feature learning into the ss-mtr, three ss-mtr-based methods, including contrastive ss-mtr (c-ss-mtr), supervised ss-mtr (s-ss-mtr), and supervised c-ss-mtr (sc-ss-mtr), are proposed by adding extra branches for specific tasks in parallel with the existing reconstruction task. specifically, the proposed c-ss-mtr adds a contrastive loss, which brings instance discriminability. besides, the proposed s-ss-mtr builds an extra classification branch for embracing interclass discriminability and intraclass similarity. moreover, the proposed sc-ss-mtr combines c-ss-mtr and s-ss-mtr for better generalization. the proposed ss-mtr, c-ss-mtr, s-ss-mtr, and sc-ss-mtr are tested on three popular hyperspectral datasets (i.e., indian pines, pavia university, and houston). the obtained results reveal that the proposed models achieve competitive results compared with the state-of-the-art hsi classification methods. the code is available at https://github.com/mengduanjinghua/ss-mtr.",AB_0290
