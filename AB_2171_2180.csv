AB,NO
"recent studies have shown great promise in unsupervised representation learning (url) for multivariate time series, because url has the capability in learning generalizable representation for many downstream tasks without using inaccessible labels. however, existing approaches usually adopt the models originally designed for other domains (e.g., computer vision) to encode the time series data and rely on strong assumptions to design learning objectives, which limits their ability to perform well. to deal with these problems, we propose a novel url framework for multivariate time series by learning time-series-specific shapelet-based representation through a popular contrasting learning paradigm. to the best of our knowledge, this is the first work that explores the shapelet-based embedding in the unsupervised general-purpose representation learning. a unified shapelet-based encoder and a novel learning objective with multi-grained contrasting and multi-scale alignment are particularly designed to achieve our goal, and a data augmentation library is employed to improve the generalization. we conduct extensive experiments using tens of real-world datasets to assess the representation quality on many downstream tasks, including classification, clustering, and anomaly detection. the results demonstrate the superiority of our method against not only url competitors, but also techniques specially designed for downstream tasks. our code has been made publicly available at https://github.com/real2fish/csl.",AB_0218
"automatic and accurate polyp segmentation is significant for diagnosis and treatment of colorectal cancer. this is a challenging task due to the polyp's shape and size diversity. recently, various deep convolutional neural networks have been developed for polyp segmentation. however, most state-of-the-art methods have suffered from a poor performance in the segmentation of smaller, flat, or noisy polyp objects. in the paper, we propose a novel deep context attention network (dcanet) for accurate polyp segmentation based on an encoder-decoder framework. resnet34 is adopted as the encoder, and five functional modules are introduced to improve the performance. specifically, the improved local context attention module (lcam) and global context module (gcm) are exploited to efficiently extract the local multi-scale and global multi-receptive-field context information, respectively. then, an enhanced feature fusion module (ffm) is devised to effectively select and aggregate context features through spatial-channel attention. finally, equipped with elaborately designed multi-attention modules (mam), new decoder and supervision blocks are developed to accurately predict polyp regions via powerful channel-spatial-channel attention. extensive experiments are conducted on the kvasir-seg and endoscene benchmark datasets. the results demonstrate that the proposed network achieves superior performance compared to other state-of-the-art models. the source code will be available at https://github.com/zakaudd/dcanet.",AB_0218
"motivation accurate disease risk prediction is an essential step in the modern quest for precision medicine. while high-dimensional multi-omics data have provided unprecedented data resources for prediction studies, their high-dimensionality and complex inter/intra-relationships have posed significant analytical challenges.results we proposed a two-step bayesian linear mixed model framework (tblmm) for risk prediction analysis on multi-omics data. tblmm models the predictive effects from multi-omics data using a hybrid of the sparsity regression and linear mixed model with multiple random effects. it can resemble the shape of the true effect size distributions and accounts for non-linear, including interaction effects, among multi-omics data via kernel fusion. it infers its parameters via a computationally efficient variational bayes algorithm. through extensive simulation studies and the prediction analyses on the positron emission tomography imaging outcomes using data obtained from the alzheimer's disease neuroimaging initiative, we have demonstrated that tblmm can consistently outperform the existing method in predicting the risk of complex traits.availability and implementation the corresponding r package is available on github (https://github.com/yaluwen/tblmm).",AB_0218
"motivation: quantitative determination of protein thermodynamic stability is a critical step in protein and drug design. reliable prediction of protein stability changes caused by point variations contributes to developing-related fields. over the past decades, dozens of structure-based and sequence-based methods have been proposed, showing good prediction performance. despite the impressive progress, it is necessary to explore wild-type and variant protein representations to address the problem of how to represent the protein stability change in view of global sequence. with the development of structure prediction using learning-based methods, protein language models (plms) have shown accurate and high-quality predictions of protein structure. because plm captures the atomic-level structural information, it can help to understand how single-point variations cause functional changes. results: here, we proposed thplm, a sequence-based deep learning model for stability change prediction using meta's esm-2. with esm-2 and a simple convolutional neural network, thplm achieved comparable or even better performance than most methods, including sequencebased and structure-based methods. furthermore, the experimental results indicate that the plm's ability to generate representations of sequence can effectively improve the ability of protein function prediction. availability and implementation: the source code of thplm and the testing data can be accessible through the following links: https://github. com/fppgroup/thplm.",AB_0218
"motivation multiple sequence alignment (msa) is one of the hotspots of current research and is commonly used in sequence analysis scenarios. however, there is no lasting solution for msa because it is a nondeterministic polynomially complete problem, and the existing methods still have room to improve the accuracy.results we propose deep reinforcement learning with positional encoding and self-attention for msa, based on deep reinforcement learning, to enhance the accuracy of the alignment specifically, inspired by the translation technique in natural language processing, we introduce self-attention and positional encoding to improve accuracy and reliability. firstly, positional encoding encodes the position of the sequence to prevent the loss of nucleotide position information. secondly, the self-attention model is used to extract the key features of the sequence. then input the features into a multi-layer perceptron, which can calculate the insertion position of the gap according to the features. in addition, a novel reinforcement learning environment is designed to convert the classic progressive alignment into progressive column alignment, gradually generating each column's sub-alignment. finally, merge the sub-alignment into the complete alignment. extensive experiments based on several datasets validate our method's effectiveness for msa, outperforming some state-of-the-art methods in terms of the sum-of-pairs and column scores.availability and implementation the process is implemented in python and available as open-source software from https://github.com/zhanglab312/dpamsa.",AB_0218
"motivation: reconstruction of 3d structure models is of great importance for the study of chromosome function. software tools for this task are highly needed. results: we present a novel reconstruction algorithm, called evrc, which utilizes co-clustering coefficients and error-vector resultant for chromosome 3d structure reconstruction. as an update of our previous evr algorithm, evrc now can deal with both single and multiple chromosomes in structure modeling. to evaluate the effectiveness and accuracy of the evrc algorithm, we applied it to simulation datasets and real hi-c datasets. the results show that the reconstructed structures have high similarity to the original/real structures, indicating the effectiveness and robustness of the evrc algorithm. furthermore, we applied the algorithm to the 3d conformation reconstruction of the wild-type and mutant arabidopsis thaliana chromosomes and demonstrated the differences in structural characteristics between different chromosomes. we also accurately showed the conformational change in the centromere region of the mutant compared with the wild-type of arabidopsis chromosome 1. our evrc algorithm is a valuable software tool for the field of chromatin structure reconstruction, and holds great promise for advancing our understanding on the chromosome functions. availability and implementation: the software is available at https://github.com/mbglab/evrc.",AB_0218
"we present finestyle, a novel framework for motion style transfer that generates expressive human animations with specific styles for virtual reality and vision fields. it incorporates semantic awareness, which improves motion representation and allows for precise and stylish animation generation. existing methods for motion style transfer have all failed to consider the semantic meaning behind the motion, resulting in limited controls over the generated human animations. to improve, finestyle introduces a new cross-modality fusion module called dual interactive-flow fusion (diff). as the first attempt, diff integrates motion style features and semantic flows, producing semantic-aware style codes for fine-grained motion style transfer. finestyle uses an innovative two-stage semantic guidance approach that leverages semantic clues to enhance the discriminative power of both semantic and style features. at an early stage, a semantic-guided encoder introduces distinct semantic clues into the style flow. then, at a fine stage, both flows are further fused interactively, selecting the matched and critical clues from both flows. extensive experiments demonstrate that finestyle outperforms state-of-the-art methods in visual quality and controllability. by considering the semantic meaning behind motion style patterns, finestyle allows for more precise control over motion styles. source code and model are available on https://github.com/xingliangjin/fine-style.git.",AB_0218
"on many popular social websites, images are usually associated with some meta-data such as textual tags, which involve semantic information relevant to the image and can be used to supervise the representation learning for image retrieval. however, these user-provided tags are usually polluted by noise, therefore the main challenge lies in mining the potential useful information from those noisy tags. many previous works simply treat different tags equally to generate supervision, which will inevitably distract the network learning. to this end, we propose a new framework, termed as weakly supervised hashing with reconstructive cross-modal attention (wshrca), to learn compact visual-semantic representation with more reliable supervision for retrieval task. specifically, for each image-tag pair, the weak supervision from tags is refined by cross-modal attention, which takes image feature as query to aggregate the most content-relevant tags. therefore, tags with relevant content will be more prominent while noisy tags will be suppressed, which provides more accurate supervisory information. to improve the effectiveness of hash learning, the image embedding in wshrca is reconstructed from hash code, which is further optimized by cross-modal constraint and explicitly improves hash learning. the experiments on two widely-used datasets demonstrate the effectiveness of our proposed method for weakly-supervised image retrieval. the code is available at https://github.com/duyc168/weakly-supervised-hashing.",AB_0218
"text-to-image generation aims to generate images from text descriptions. its main challenge lies in two aspects: (1) semantic consistency, i.e., the generated images should be semantically consistent with the input text; and (2) visual reality, i.e., the generated images should look like real images. to ensure text-image consistency, existing works mainly learn to establish the cross-modal representations via a text encoder and image encoder. however, due to the limited representation capability of the fixed-length embeddings and the flexibility of the free-form text descriptions, the learned text-to-image model is incapable of maintaining the semantic consistency between image local regions and fine-grained descriptions. as a result, the generated images sometimes miss some fine-grained attributes of the generated object, such as the color or shape of a part of the object. to address this issue, this paper proposes a local feature refinement based generative adversarial network (lfr-gan), which first divides the text into some independent fine-grained attributes and generates an initial image, then refines the image details based on these attributes. the main contributions are three-fold: (1) an attribute modeling approach is proposed to model the fine-grained text descriptions by mapping them into representations of independent attributes, which provides more fine-grained details for image generation. (2) a local feature refinement approach is proposed to enable the generated image to form a complete reflection of the fine-grained attributes contained in the text description. (3) a multi-stage generation approach is proposed to realize the fine-grained manipulation of complex images progressively, which aims to improve the performance of the refinement and generate photo-realistic images. extensive experiments on the cub and oxford102 datasets show the effectiveness of our lfr-gan approach in both text-to-image generation and text-guided image manipulation tasks. our lfr-gan approach shows superior performance compared to the state-of-the-art methods. the codes will be released at https://github.com/pku-icst-mipl/lfr-gan_tomm2023.",AB_0218
"the way of constructing a robust feature pyramid is crucial for object detection. however, existing feature pyramid methods, which aggregate multi-level features by using element-wise sum or concatenation, are inefficient to construct a robust feature pyramid. the reason is that these methods cannot be effective in discriminating the relevant semantics of objects. in this article, we propose a complementary feature pyramid network (cfpn) to aggregate multi-level features selectively and efficiently by exploring complementary information betweenmulti-level features. specifically, a spatial complementary module (scm) and a channel complementary module (ccm) are designed and embedded in cfpn to enhance useful information and suppress irrelevant information during feature fusions along spatial and channel dimensions, respectively. cfpn is a generic feature extractor, as evidenced by its seamless integration into single-stage, two-stage, and end-to-end object detectors. experiments conducted on the coco and pascal voc datasets demonstrate that integrating our cfpn into retinanet, faster rcnn, cascade rcnn, and sparse rcnn obtains consistent performance improvements with negligible overheads. code and models are available at: https://github.com/ viplab- cqu/cfpn.",AB_0218
