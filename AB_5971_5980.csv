AB,NO
"motivation neoantigens, tumor-specific protein fragments, are invaluable in cancer immunotherapy due to their ability to serve as targets for the immune system. computational prediction of these neoantigens from sequencing data often requires multiple algorithms and sophisticated workflows, which are currently restricted to specific types of variants, such as single-nucleotide variants or insertions/deletions. nevertheless, other sources of neoantigens are often overlooked.results we introduce scanneo2 an improved and fully automated bioinformatics pipeline designed for high-throughput neoantigen prediction from raw sequencing data. unlike its predecessor, scanneo2 integrates multiple sources of somatic variants, including canonical- and exitron-splicing, gene fusion events, and various somatic variants. our benchmark results demonstrate that scanneo2 accurately identifies neoantigens, providing a comprehensive and more efficient solution for neoantigen prediction.availability and implementation scanneo2 is freely available at https://github.com/ylab-hi/scanneo2/ and is accompanied by instruction and application data.",AB_0598
"backgroundthe pubmed archive contains more than 34 million articles; consequently, it is becoming increasingly difficult for a biomedical researcher to keep up-to-date with different knowledge domains. computationally efficient and interpretable tools are needed to help researchers find and understand associations between biomedical concepts. the goal of literature-based discovery (lbd) is to connect concepts in isolated literature domains that would normally go undiscovered. this usually takes the form of an a-b-c relationship, where a and c terms are linked through a b term intermediate. here we describe serial kinderminer (skim), an lbd algorithm for finding statistically significant links between an a term and one or more c terms through some b term intermediate(s). the development of skim is motivated by the observation that there are only a few lbd tools that provide a functional web interface, and that the available tools are limited in one or more of the following ways: (1) they identify a relationship but not the type of relationship, (2) they do not allow the user to provide their own lists of b or c terms, hindering flexibility, (3) they do not allow for querying thousands of c terms (which is crucial if, for instance, the user wants to query connections between a disease and the thousands of available drugs), or (4) they are specific for a particular biomedical domain (such as cancer). we provide an open-source tool and web interface that improves on all of these issues.resultswe demonstrate skim's ability to discover useful a-b-c linkages in three control experiments: classic lbd discoveries, drug repurposing, and finding associations related to cancer. furthermore, we supplement skim with a knowledge graph built with transformer machine-learning models to aid in interpreting the relationships between terms found by skim. finally, we provide a simple and intuitive open-source web interface (https://skim.morgridge.org) with comprehensive lists of drugs, diseases, phenotypes, and symptoms so that anyone can easily perform skim searches.conclusionsskim is a simple algorithm that can perform lbd searches to discover relationships between arbitrary user-defined concepts. skim is generalized for any domain, can perform searches with many thousands of c term concepts, and moves beyond the simple identification of an existence of a relationship; many relationships are given relationship type labels from our knowledge graph.",AB_0598
"motivation pairwise sequence alignment is a heavy computational burden, particularly in the context of third-generation sequencing technologies. this issue is commonly addressed by approximately estimating sequence similarities using a hash-based method such as minhash. in minhash, all k-mers in a read are hashed and the minimum hash value, the min-hash, is stored. pairwise similarities can then be estimated by counting the number of min-hash matches between a pair of reads, across many distinct hash functions. the choice of the parameter k controls an important tradeoff in the task of identifying alignments: larger k-values give greater confidence in the identification of alignments (high precision) but can lead to many missing alignments (low recall), particularly in the presence of significant noise.results in this work, we introduce lexichash, a new similarity estimation method that is effectively independent of the choice of k and attains the high precision of large-k and the high sensitivity of small-k minhash. lexichash is a variant of minhash with a carefully designed hash function. when estimating the similarity between two reads, instead of simply checking whether min-hashes match (as in standard minhash), one checks how lexicographically similar the lexichash min-hashes are. in our experiments on 40 pacbio datasets, the area under the precision-recall curves obtained by lexichash had an average improvement of 20.9% over minhash. additionally, the lexichash framework lends itself naturally to an efficient search of the largest alignments, yielding an o(n) time algorithm, and circumventing the seemingly fundamental o(n2) scaling associated with pairwise similarity search.availability and implementation lexichash is available on github at https://github.com/gcgreenberg/lexichash.",AB_0598
"motivation: double-stranded rnas (dsrnas) are potent triggers of innate immune responses upon recognition by cytosolic dsrna sensor proteins. identification of endogenous dsrnas helps to better understand the dsrnaome and its relevance to innate immunity related to human diseases. results: here, we report dsrid (double-stranded rna identifier), a machine-learning-based method to predict dsrna regions in silico, leveraging the power of long-read rna-sequencing (rna-seq) and molecular traits of dsrnas. using models trained with pacbio long-read rna-seq data derived from alzheimer's disease (ad) brain, we show that our approach is highly accurate in predicting dsrna regions in multiple datasets. applied to an ad cohort sequenced by the encode consortium, we characterize the global dsrna profile with potentially distinct expression patterns between ad and controls. together, we show that dsrid provides an effective approach to capture global dsrna profiles using long-read rna-seq data. availability and implementation: software implementation of dsrid, and genomic coordinates of regions predicted by dsrid in all samples are available at the github repository: https://github.com/gxiaolab/dsrid.",AB_0598
"advances in computational tools for atomic model building are leading to accurate models of large molecular assemblies seen in electron microscopy, often at challenging resolutions of 3-4 & aring;. we describe new methods in the ucsf chimerax molecular modeling package that take advantage of machine-learning structure predictions, provide likelihood-based fitting in maps, and compute per-residue scores to identify modeling errors. additional model-building tools assist analysis of mutations, post-translational modifica-tions, and interactions with ligands. we present the latest chimerax model-building capabilities, including several community-developed extensions. chimerax is available free of charge for noncommercial use at https://www. rbvi.ucsf.edu/chimerax.",AB_0598
"database peptide search is the primary computational technique for identifying peptides from the mass spectrometry (ms) data. graphical processing units (gpu) computing is now ubiquitous in the current-generation of high-performance computing (hpc) systems, yet its application in the database peptide search domain remains limited. part of the reason is the use of sub-optimal algorithms in the existing gpu-accelerated methods resulting in significantly inefficient hardware utilization. in this paper, we design and implement a new-age cpu-gpu hpc framework, called gicops, for efficient and complete gpu-acceleration of the modern database peptide search algorithms on supercomputers. our experimentation shows that the gicops exhibits between 1.2 to 5x speed improvement over its cpu-only predecessor, hicops, and over 10x improvement over several existing gpu-based database search algorithms for sufficiently large experiment sizes. we further assess and optimize the performance of our framework using the roofline model and report near-optimal results for several metrics including computations per second, occupancy rate, memory workload, branch efficiency and shared memory performance. finally, the cpu-gpu methods and optimizations proposed in our work for complex integer- and memory-bounded algorithmic pipelines can also be extended to accelerate the existing and future peptide identification algorithms. gicops is now integrated with our umbrella hpc framework hicops and is available at: https://github.com/pcdslab/gicops.",AB_0598
"the expanding catalog of genome-wide association studies (gwas) provides biological insights across a variety of species, but identifying the causal variants behind these associations remains a significant challenge. experimental validation is both labor-intensive and costly, highlighting the need for accurate, scalable computational methods to predict the effects of genetic variants across the entire genome. inspired by recent progress in natural language processing, unsupervised pretraining on large protein sequence databases has proven successful in extracting complex information related to proteins. these models showcase their ability to learn variant effects in coding regions using an unsupervised approach. expanding on this idea, we here introduce the genomic pre-trained network (gpn), a model designed to learn genome-wide variant effects through unsupervised pretraining on genomic dna sequences. our model also successfully learns gene structure and dna motifs without any supervision. to demonstrate its utility, we train gpn on unaligned reference genomes of arabidopsis thaliana and seven related species within the brassicales order and evaluate its ability to predict the functional impact of genetic variants in a. thaliana by utilizing allele frequencies from the 1001 genomes project and a comprehensive database of gwas. notably, gpn outperforms predictors based on popular conservation scores such as phylop and phastcons. our predictions for a. thaliana can be visualized as sequence logos in the ucsc genome browser (https://genome.ucsc.edu/s/gbenegas/gpn-arabidopsis). we provide code (https://github.com/songlab-cal/gpn) to train gpn for any given species using its dna sequence alone, enabling unsupervised prediction of variant effects across the entire genome.",AB_0598
"a growing interest in aptamer research, as evidenced by the increase in aptamer publications over the years, has led to calls for a go-to site for aptamer information. a comprehensive, publicly available aptamer dataset, which may be a repository for aptamer data, standardize aptamer reporting, and generate opportunities to expand current research in the field, could meet such a demand. there have been several attempts to create aptamer databases; however, most have been abandoned or removed entirely from public view. inspired by previous efforts, we have published the utexas aptamer database, https://sites.utexas.edu/aptamerdatabase, which includes a publicly available aptamer dataset and a searchable database containing a subset of all aptamer data collected to date (1990-2022). the dataset contains aptamer sequences, binding and selection information. the information is regularly reviewed internally to ensure accuracy and consistency across all entries. to support the continued curation and review of aptamer sequence information, we have implemented sustaining mechanisms, including researcher training protocols, an aptamer submission form, data stored separately from the database platform, and a growing team of researchers committed to updating the database. currently, the utexas aptamer database is the largest in terms of the number of aptamer sequences with 1,443 internally reviewed aptamer records. graphical abstract",AB_0598
"emerging crispr-cas9 technology permits synthetic lethality (sl) screening of large number of gene pairs from gene combination double knockout (cdko) experiments. however, the poor integration and annotation of cdko sl data in current sl databases limit their utility, and diverse methods of calculating sl scores prohibit their comparison. to overcome these shortcomings, we have developed sl knowledge base (slkb) that incorporates data of 11 cdko experiments in 22 cell lines, 16,059 sl gene pairs and 264,424 non-sl gene pairs. additionally, within slkb, we have implemented five sl calculation methods: median score with and without background control normalization (median-b/nb), sgrna-derived score (sgrna-b/nb), horlbeck score, gemini score and mageck score. the five scores have demonstrated a mere 1.21% overlap among their top 10% sl gene pairs, reflecting high diversity. users can browse sl networks and assess the impact of scoring methods using venn diagrams. the sl network generated from all data in slkb shows a greater likelihood of sl gene pair connectivity with other sl gene pairs than non-sl pairs. comparison of sl networks between two cell lines demonstrated greater likelihood to share sl hub genes than sl gene pairs. slkb website and pipeline can be freely accessed at https://slkb.osubmi.org and https://slkb.docs.osubmi.org/, respectively. graphical abstract",AB_0598
"motivation genome-wide association studies (gwas) benefit from the increasing availability of genomic data and cross-institution collaborations. however, sharing data across institutional boundaries jeopardizes medical data confidentiality and patient privacy. while modern cryptographic techniques provide formal secure guarantees, the substantial communication and computational overheads hinder the practical application of large-scale collaborative gwas.results this work introduces an efficient framework for conducting collaborative gwas on distributed datasets, maintaining data privacy without compromising the accuracy of the results. we propose a novel two-step strategy aimed at reducing communication and computational overheads, and we employ iterative and sampling techniques to ensure accurate results. we instantiate our approach using logistic regression, a commonly used statistical method for identifying associations between genetic markers and the phenotype of interest. we evaluate our proposed methods using two real genomic datasets and demonstrate their robustness in the presence of between-study heterogeneity and skewed phenotype distributions using a variety of experimental settings. the empirical results show the efficiency and applicability of the proposed method and the promise for its application for large-scale collaborative gwas.availability and implementation the source code and data are available at https://github.com/amioamo/tds.",AB_0598
