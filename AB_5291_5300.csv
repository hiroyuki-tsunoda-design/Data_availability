AB,NO
"background: genomic variations may cause deleterious effects on protein functionality and perturb biological processes. elucidating the effects of variations is critical for developing novel treatment strategies for diseases of genetic origin. computational approaches have been aiding the work in this field by modeling and analyzing the mutational landscape. however, new approaches are required, especially for accurate representation and datacentric analysis of sequence variations. method: in this study, we propose ascaris (annotation and structure-based representation of single amino acid variations), a method for the featurization (i.e., quantitative representation) of single amino acid variations (savs), which could be used for a variety of purposes, such as predicting their functional effects or building multi-omics-based integrative models. ascaris utilizes the direct and spatial correspondence between the location of the sav on the sequence/structure and 30 different types of positional feature annotations (e.g., active/lipidation/glycosylation sites; calcium/metal/dna binding, inter/transmembrane regions, etc.), along with structural features and physicochemical properties. the main novelty of this method lies in constructing reusable numerical representations of savs via functional annotations. results: we statistically analyzed the relationship between these features and the consequences of variations and found that each carries information in this regard. to investigate potential applications of ascaris, we trained variant effect prediction models that utilize our sav representations as input. we carried out an ablation study and a comparison against the state-of-the-art methods and observed that ascaris has a competing and complementary performance against widely-used predictors. ascaris can be used alone or in combination with other approaches to represent savs from a functional perspective. ascaris is available as a programmatic tool at https://github.com/hubiodatalab/ascaris and as a web-service at https://huggingface.co/spaces/hubiodatalab/ascaris.",AB_0530
"backgrounddrug repurposing is an approach that holds promise for identifying new therapeutic uses for existing drugs. recently, knowledge graphs have emerged as significant tools for addressing the challenges of drug repurposing. however, there are still major issues with constructing and embedding knowledge graphs.resultsthis study proposes a two-step method called drugrep-hesiagraph to address these challenges. the method integrates the drug-disease knowledge graph with the application of a heterogeneous siamese neural network. in the first step, a drug-disease knowledge graph named ddkg-v1 is constructed by defining new relationship types, and then numerical vector representations for the nodes are created using the distributional learning method. in the second step, a heterogeneous siamese neural network called hesianet is applied to enrich the embedding of drugs and diseases by bringing them closer in a new unified latent space. then, it predicts potential drug candidates for diseases. drugrep-hesiagraph achieves impressive performance metrics, including an auc-roc of 91.16%, an auc-pr of 90.32%, an accuracy of 84.63%, a bs of 0.119, and an mcc of 69.31%.conclusionwe demonstrate the effectiveness of the proposed method in identifying potential drugs for covid-19 as a case study. in addition, this study shows the role of dipeptidyl peptidase 4 (dpp-4) as a potential receptor for sars-cov-2 and the effectiveness of dpp-4 inhibitors in facing covid-19. this highlights the practical application of the model in addressing real-world challenges in the field of drug repurposing. the code and data for drugrep-hesiagraph are publicly available at https://github.com/cbrc-lab/drugrep-hesiagraph.",AB_0530
"backgroundshotgun metagenome sequencing data obtained from a host environment will usually be contaminated with sequences from the host organism. host sequences should be removed before further analysis to avoid biases, reduce downstream computational load, or ensure privacy in the case of a human host. the tools that we identified, as designed specifically to perform host contamination sequence removal, were either outdated, not maintained, or complicated to use. consequently, we have developed hocort, a fast and user-friendly tool that implements several methods for optimised host sequence removal. we have evaluated the speed and accuracy of these methods.resultshocort is an open-source command-line tool for host contamination removal. it is designed to be easy to install and use, offering a one-step option for genome indexing. hocort employs a variety of well-known mapping, classification, and alignment methods to classify reads. the user can select the underlying classification method and its parameters, allowing adaptation to different scenarios. based on our investigation of various methods and parameters using synthetic human gut and oral microbiomes, and on assessment of publicly available data, we provide recommendations for typical datasets with short and long reads.conclusionsto decontaminate a human gut microbiome with short reads using hocort, we found the optimal combination of speed and accuracy with biobloom, bowtie2 in end-to-end mode, and hisat2. kraken2 consistently demonstrated the highest speed, albeit with a trade-off in accuracy. the same applies to an oral microbiome, but here bowtie2 was notably slower than the other tools. for long reads, the detection of human host reads is more difficult. in this case, a combination of kraken2 and minimap2 achieved the highest accuracy and detected 59% of human reads. in comparison to the dedicated deconseq tool, hocort using bowtie2 in end-to-end mode proved considerably faster and slightly more accurate. hocort is available as a bioconda package, and the source code can be accessed at https://github.com/ignasrum/hocort along with the documentation. it is released under the mit licence and is compatible with linux and macos (except for the biobloom module).",AB_0530
"hsp70 are ubiquitous, versatile molecular chaperones that cyclically interact with substrate protein(s). the initial step requires synergistic interaction of a substrate and a j-domain protein (jdp) cochaperone, via its j-domain, with hsp70 to stimulate hydrolysis of its bound atp. this hydrolysis drives conformational changes in hsp70 that stabilize substrate binding. however, because of the transient nature of substrate and jdp interactions, this key step is not well understood. here we leverage a well characterized hsp70 system specialized for ironsulfur cluster biogenesis, which like many systems, has a jdp that binds substrate on its own. utilizing an atpase-deficient hsp70 variant, we isolated a hsp70-jdp-substrate tripartite complex. complex formation and stability depended on residues previously identified as essential for bipartite interactions: jdp-substrate, hsp70-substrate and j-domain-hsp70. computational docking based on the established j-domain-hsp70(atp) interaction placed the substrate close to its predicted position in the peptide-binding cleft, with the jdp having the same architecture as when in a bipartite com-plex with substrate. together, our results indicate that the structurally rigid jdp-substrate complex recruits hsp70(atp) via precise positioning of j-domain and substrate at their respective interaction sites - resulting in functionally high affinity (i.e., avidity). the exceptionally high avidity observed for this specialized system may be unusual because of the rigid architecture of its jdp and the additional jdp-hsp70 interaction site uncovered in this study. however, functionally important avidity driven by jdp-substrate interactions is likely sufficient to explain synergistic atpase stimulation and efficient substrate trapping in many hsp70 systems.(c) 2023 the author(s). published by elsevier ltd. this is an open access article under the cc by-nc-nd license (http://crea-tivecommons.org/licenses/by-nc-nd/4.0/).",AB_0530
"the high-dimensional datasets in various domains, such as text categorization, information retrieval and bioinformatics, have highlighted the importance of feature selection in data mining. despite the numerous existing approaches to feature selection, there is still a need for further research in this field. in this paper, we propose an evolutionary filter feature selection approach that can be used for both single-and multi-objective scenarios by introducing an objective function inspired by neighborhood component analysis (nca)-based method and then integrating it into the differential evolution framework. the proposed approach applicable to two scenarios aims to identify an optimal feature subset through an evolutionary search process that maximizes class separation while minimizing the dimensionality. through comprehensive experimental studies conducted on diverse datasets, the results show that the proposed approach outperforms recently proposed evolutionary information-theoretic, rough set-based and state-of-the-art feature selection approaches in both scenarios. notably, this study is the first to integrate an nca-based strategy into an evolutionary feature selection approach. furthermore, you can access the source code of this approach at https://github.com/ ehancer06/denca this link.",AB_0530
"single-base substitution (sbs) mutational signatures have become standard practice in cancer genomics. in lieu of de novo signature extraction, reference signature assignment allows users to estimate the activities of pre-established sbs signatures within individual malignancies. several tools have been developed for this purpose, each with differing methodologies. however, due to a lack of standardization, there may be inter-tool variability in signature assignment. we deeply characterized three assignment strategies and five sbs signature assignment tools. we observed that assignment strategy choice can significantly influence results and interpretations. despite varying recommendations by tools, refit performed best by reducing overfitting and maximizing reconstruction of the original mutational spectra. even after uniform application of refit, tools varied remarkably in signature assignments both qualitatively (jaccard index = 0.38-0.83) and quantitatively (kendall tau-b = 0.18-0.76). this phenomenon was exacerbated for 'flat' signatures such as the homologous recombination deficiency signature sbs3. an ensemble approach (ensemblefit), which leverages output from all five tools, increased sbs3 assignment accuracy in brca1/2-deficient breast carcinomas. after generating synthetic mutational profiles for thousands of pan-cancer tumors, ensemblefit reduced signature activity assignment error 15.9-24.7% on average using catalogue of somatic mutations in cancer and non-standard reference signature sets. we have also released the ensemblefit web portal (https://www.ensemblefit.pittlabgenomics.com) for users to generate or download ensemble-based sbs signature assignments using any strategy and combination of tools. overall, we show that signature assignment heterogeneity across tools and strategies is non-negligible and propose a viable, ensemble solution.",AB_0530
"neural architecture search (nas) benchmarks significantly improved the capability of developing and comparing nas methods while at the same time drastically reduced the computational over-head by providing meta-information of trained neural networks. however, tabular benchmarks have several drawbacks that can hinder fair comparisons and provide unreliable results. these usually focus on a small pool of operations in heavily constrained search spaces - usually cell -based neural networks with pre-defined outer-skeletons. in this work, we conducted an empirical analysis of the widely used nas-bench-101, nas-bench-201 and transnas-bench-101 bench-marks in terms of their generability and how different operations influence the performance of the generated architectures. we found that only a subset of the operation pool is required to generate architectures close to the upper-bound of the performance range. more, the performance distribution is negatively skewed, with many architectures clustered near the upper accuracy bound. further experiments revealed that convolution layers have the highest impact on the architecture's performance and that specific combinations of operations favor top-scoring architectures. overall, our results demonstrate the need for benchmarks with greater operation diversity and less constrained search spaces. we provide suggestions for improving future benchmark design and evaluation of nas methods when using existing benchmarks. the code used to conduct the evaluations is available at https://github .com /vascolopes /nas-benchmark-evaluation.",AB_0530
"backgroundwe decided to conduct this study with the aim of investigating the effects of n-acetylcysteine (nac) on obesity complications and senescence of visceral adipose tissue in obese adults.methods and analysisthe present study was conducted as a randomized clinical trial (rct) (clinical trial registry number: irct20220727055563n1) on 40 obese adults candidates for bariatric surgery, who were randomly assigned to receive 600 mg of nac (n = 20) or placebo as a control (n = 20) for 4 weeks. during bariatric surgery, visceral adipose tissue was used to examine gene expression and senescence cells using sa-beta-gal.resultsour findings showed that intervention with nac significantly reduces sa-beta-gal activity (as a marker of senescence) and expression of p16 and interleukin 6 (il-6) genes in the visceral adipose tissue compared to placebo in obese adults for 4 weeks. in addition, our findings showed the potential and beneficial effect of nac administration on reducing the levels of inflammatory factors including il-6 and high-sensitivity c-reactive protein (hs-crp), as well as the level of fasting blood sugar (fbs), homeostatic model assessment of insulin resistance (homa-ir), and insulin compared to placebo after adjusting for confounders. no significant effect was indicated on anthropometric factors and lipid profile.conclusionfindings showed that nac, in addition to having a potential beneficial effect on reducing some of the complications caused by obesity, seems to have synolytic/senomorphic potential as well.clinical trial registration[https://clinicaltrials.gov/], identifier [irct20220727055563n1].",AB_0530
"deep neural networks are known to be vulnerable to adversarial perturbations. the amount of these perturbations are generally quantified using cp metrics, such as c0, c2 and c infinity. however, even when the measured perturbations are small, they tend to be noticeable by human observers since cp distance metrics are not representative of human perception. on the other hand, humans are less sensitive to changes in colorspace. in addition, pixel shifts in a constrained neighborhood are hard to notice. motivated by these observations, we propose a method that creates adversarial examples by applying spatial transformations, which creates adversarial examples by changing the pixel locations independently to chrominance channels of perceptual colorspaces such as ycbcr and cielab, instead of making an additive perturbation or manipulating pixel values directly. in a targeted white-box attack setting, the proposed method is able to obtain competitive fooling rates with very high confidence. the experimental evaluations show that the proposed method has favorable results in terms of approximate perceptual distance between benign and adversarially generated images. the source code is publicly available at https://github.com/ayberkydn/stadv-torch.",AB_0530
"the discovery of low-coverage (i.e. uncovered) regions containing clinically significant variants, especially when they are related to the patient's clinical phenotype, is critical for whole-exome sequencing (wes) based clinical diagnosis. therefore, it is essential to develop tools to identify the existence of clinically important variants in low-coverage regions. here, we introduce a desktop application, namely devour (deleterious variants on uncovered regions), that analyzes read alignments for wes experiments, identifies genomic regions with no or low-coverage (read depth < 5) and then annotates known variants in the low-coverage regions using clinical variant annotation databases. as a proof of concept, devour was used to analyze a total of 28 samples from a publicly available hirschsprung disease-related wes project (ncbi bioproject: https://ww. ncbi.nlm.nih.gov/bioproject/?term=prjeb19327), revealing the potential existence of 98 disease-associated variants in low-coverage regions. devour is available from https://github.com/projectdevour/devour under the mit license.",AB_0530
