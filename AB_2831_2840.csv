AB,NO
"the overwhelming majority of models for remote-sensing image (rsi) scene classification generally require the weights pretrained on natural images for initialization before formal training. however, differences in imaging mechanisms lead to huge discrepancies between natural images and rsis, and the strong visual representation learned from massive natural images limits the performance of models when inferencing rsis. to address this issue, the well-established self-supervised contrastive learning paradigm in the natural image field is introduced to the rsi field. we propose a contrastive learning method based on multiscale hard features (mhcl), which aims to use finite rsis to learn sufficient visual representations in an unsupervised contrastive manner, thus providing a powerful upstream pretrained model for fine-tuning downstream scene classification task. multilevel features extracted by intermediate layers of each encoder's backbone are first gathered and then a hard features transformation method (hft) is proposed to create hard positive features and diverse queues that save hard negatives, thereby enriching the finite scene information in small-scale rsis. furthermore, we redesign the multiscale hard features joint contrastive loss to boost the model to explore sufficient invariant representations by additionally pulling hard positive pairs closer and pushing hard negative pairs farther away in the embedding space. extensive experiments demonstrate that the upstream pretraining model generated by mhcl achieves competitive transferred performance on three popular scene classification datasets, outperforming the traditional model pretrained on imagenet and models pretrained by other state-of-the-art contrastive learning methods. our code will be released at: https://github.com/benesakitam/mhcl.",AB_0284
"as a content management technique, remote sensing (rs) scene classification (rssc) always attracts researchers' attention. in the past decades, many successful methods have been proposed. nevertheless, their prerequisite is that there are large labeled datasets, which is a strict demand in practice. to resolve this contradiction, developing rssc models with the help of few-shot learning (fsl) has become popular. due to lacking prior knowledge, most of the existing few-shot rssc models pay attention to the learning algorithm. however, they do not attach importance to the complex contents within rs scenes and the intricate interclass/intraclass relations between rs scenes. this would influence their performance negatively. in this article, we propose a new few-shot rssc model named multipretext-task prototypes guided dynamic contrastive learning network (mpcl-net). mpcl-net consists of a multipretext tasks generation submodule, a deep feature learning submodule, and a joint optimization submodule. first, two rs-oriented pretext tasks are constructed under the self-supervised learning (ssl) framework in the multipretext tasks generation submodule, which aims to explore multiscale and rotation-invariant information from rs scenes. second, a simple convolutional neural network (cnn) is developed in the deep feature learning submodule to transform the rs scenes into visual features. third, three loss functions are formulated and integrated into the joint optimization submodule. their goals are to fully capture the diverse land covers within rs scenes and compact/separate the intraclass/interclass samples with limited supervision. finally, our mpcl-net can be trained in a meta way. the positive results counted on the three public rs scene datasets confirm that our mpcl-net is helpful to rssc tasks under the few-shot scenario. our source codes are available at https://github.com/tangxu-group/remote-sensing-images-classification/tree/main/mpcl.",AB_0284
"object detection in aerial images has received increasing attention for its wide applications. however, it is still a challenging task when dealing with difficult cases, such as the large variations of object sizes, the complex backgrounds in the large-scale views, as well as small targets packed in dense. in this regard, we propose a self-adaptive object detection network for aerial images based on feature enhancement, including the region crop module with soft-attention (rcp), feature enhancement module (fet), self-adaptive feature extraction module (sae). first, rcp module with soft-attention is explored to roughly crop the dense subregion and sparse subregion into patches according to the variance of feature maps for the following feature extraction and detection. second, the fet module is proposed to acquire more semantic details by feature enhancement, which makes up the information loss during downsampling, especially for small objects in dense regions. finally, th sae module is explored to effectively identify multiple target regions and single target regions in the dense patches. the similarity of adjacent dense areas in dense patches is calculated, and the search range is gradually narrowed by continuously merging the areas with the largest similarity. the teacher-network and student-network are used to extract features for multiple target regions and single target regions, respectively. the proposed design improves the accuracy of real-time detection under the drone's perspective. a large number of experiments and comprehensive evaluations on the visdrone2019-det dataset have shown the effectiveness and adaptability of the proposed method. our source codes have been available at https://github.com/zhaokai152.",AB_0284
"the capacity of satellites to supply high-resolution imaging has promoted the fine-grained object detection task in remote sensing images. however, this type of object detection is challenging due to low interclass feature differences in objects. to address this issue, we propose a prototypical contrastive learning-based detector (pcldet) for fine-grained object detection in remote sensing images. the pcldet first introduces the prototype to learn the fine-grained objects' features and then adopts contrastive learning to compare the target and the learned features, thus improving the differentiability of the fine-grained object. specifically, we first introduce the prototype, which represents the feature centers of each class, and then construct a prototype bank to store the feature prototypes of each class. then, we introduce contrastive learning to extract the discriminative features by maximizing the interclass distance and minimizing the intraclass distance. furthermore, we propose the protocl loss as a part of the model optimization, which enables more representative prototypes to be learned. finally, to address the long-tail problem in the remote sensing fine-grained object detection dataset, we propose a new proposal sampler, the class-balanced sampler (cbs) that can sample each class equally. extensive experiments demonstrate that our method can achieve the state-of-the-art performance on a commonly used aerial fine-grained object dataset (fair1m) and aerial fine-grained ship dataset (ofsd) while maintaining high efficiency. the code will be available at https://github.com/g-naughty/pcldet.",AB_0284
"bone age assessment is of great significance to genetic diagnosis and endocrine diseases. traditional bone age diagnosis mainly relies on experienced radiologists to examine the regions of interest in hand radiography, but it is time-consuming and may even lead to a vast error between the diagnosis result and the reference. the existing computer-aided methods predict bone age based on general regions of interest but do not explore specific regions of interest in hand radiography. this paper aims to solve such problems by performing bone age prediction on the articular surface and epiphysis from hand radiography using deep convolutional neural networks. the articular surface and epiphysis datasets are established from the radiological society of north america (rsna) pediatric bone age challenge, where the specific feature regions of the articular surface and epiphysis are manually segmented from hand radiography. five convolutional neural networks, i.e., resnet50, senet, densenet-121, efficientnet-b4, and cspnet, are employed to improve the accuracy and efficiency of bone age diagnosis in clinical applications. experiments show that the best-performing model can yield a mean absolute error (mae) of 7.34 months on the proposed articular surface and epiphysis datasets, which is more accurate and fast than the radiologists. the project is available at https://github.com/yameideng/baanet/, and the annotated dataset is also published at https://doi.org/10.5281/zenodo.7947923.",AB_0284
"dna-binding proteins (dbps) play a critical role in the development of drugs for treating genetic diseases and in dna biology research. it is essential for predicting dna-binding proteins more accurately and efficiently. in this paper, a laplacian local kernel alignment-based restricted kernel machine (laplka-rkm) is proposed to predict dbps. in detail, we first extract features from the protein sequence using six methods. second, the radial basis function (rbf) kernel function is utilized to construct pre-defined kernel metrics. then, these metrics are combined linearly by weights calculated by laplka. finally, the fused kernel is input to rkm for training and prediction. independent tests and leave-one-out cross-validation were used to validate the performance of our method on a small dataset and two large datasets. importantly, we built an online platform to represent our model, which is now freely accessible via http://8.130.69.121:8082/.",AB_0284
"cross-domain ship detection tries to identify synthetic aperture radar (sar) ships by adapting knowledge from labeled optical images, without labor-intensive annotations. in practical applications, a few (e.g., one or three samples) labeled sar samples are available, which provides additional supervision for sar ships. however, the existing cross-domain methods ignore the sar supervision (a few labeled and unlabeled sar images), which limits their performances in a practical and under-investigated task: semisupervised cross-domain ship detection (scsd). in this article, a dual-teacher framework is proposed to address the mutual interference between optical supervision and sar supervision. first, both optical and sar supervision are decomposed into two subtasks: cross-domain task and semisupervised task. then, both cross-domain tasks and semisupervised tasks can be learned interactively in two individual teacher-student models. the teacher-student models generate pseudo-labels on unlabeled sar images by a teacher network and fine-tune the student network. finally, the dual-teacher framework retrains two teacher-student models in cotraining strategies. both cross-domain datasets and semisupervised datasets are exploited to jointly improve the pseudo-label quality. the effectiveness of the dual-teacher framework has been fully experimentally demonstrated. the code is available at https://github.com/xiangtaozheng/dualteacher.",AB_0284
"the accurate matching of multisource, multitemporal remote sensing images is challenging because of significant nonlinear intensity differences (nids) and severe geometric distortions. to address these problems, we developed a robust image matching method: oriented filter-based matching (ofm). ofm is insensitive to nids while exhibiting scale and rotational invariance. first, salient feature points with multiscale attributes were detected in the gaussian-scale space of the input images. then, the images were convoluted using multioriented filters, and unified feature maps were constructed by the extraction of orientation indices using effective data pooling operations. the constructed feature maps were highly resistant to nids. five filters were integrated into the ofm framework to investigate their applicabilities in different application scenarios. next, a novel rotation-invariant feature descriptor was constructed, using a dominant direction determination approach and a descriptor-grouping strategy. the dominant direction determination approach enables accurate dominant direction estimation, whereas the descriptor-grouping strategy improves the stability of the method under different rotational angles. finally, brute-force matching was implemented to obtain initial matches; an improved mismatch elimination method was used to identify reliable putative matches. to evaluate the performance of ofm, we created a large dataset comprising 4427 pairs of multitemporal optical-optical, optical-synthetic aperture radar (sar), optical-infrared, and optical-depth images. ofm outperformed state-of-the-art methods in terms of a number of correct matches (ncm), recall, inlier ratio, root mean square error (rmse), and success rate (sr). our implementation is publicly available at https://github.com/zhongli-fan/ofm.",AB_0284
"vision transformers (vits) have been trending in image classification tasks due to their promising performance when compared with convolutional neural networks (cnns). as a result, many researchers have tried to incorporate vits in hyperspectral image (hsi) classification tasks. to achieve satisfactory performance, close to that of cnns, transformers need fewer parameters. vits and other similar transformers use an external classification (cls) token, which is randomly initialized and often fails to generalize well, whereas other sources of multimodal datasets, such as light detection and ranging (lidar), offer the potential to improve these models by means of a cls. in this article, we introduce a new multimodal fusion transformer (mft) network, which comprises a multihead cross-patch attention (mcrosspa) for hsi land-cover classification. our mcrosspa utilizes other sources of complementary information in addition to the hsi in the transformer encoder to achieve better generalization. the concept of tokenization is used to generate cls and hsi patch tokens, helping to learn a distinctive representation in a reduced and hierarchical feature space. extensive experiments are carried out on widely used benchmark datasets, i.e., the university of houston (uh), trento, university of southern mississippi gulfpark (muufl), and augsburg. we compare the results of the proposed mft model with other state-of-the-art transformers, classical cnns, and conventional classifiers models. the superior performance achieved by the proposed model is due to the use of mcrosspa. the source code will be made available publicly at https://github.com/ankurderia/mft.",AB_0284
"dense medium-resolution images play an important role in time-series geoscience applications. however, due to technical limitations, remote sensing imaging systems inevitably trade off temporal frequency and spatial swaths, resulting in difficulties to acquire images simultaneously with high spatial and temporal resolution. to overcome this limitation, under the framework of residual learning, we propose a cross-attention-based adaptive weighting fusion network (cafe) for modis-landsat spatiotemporal fusion to generate dense medium-resolution images. based on the cross-attention mechanism, we propose multichannel separated cross-attention (msca) and full-feature joint cross-attention (fjca) blocks to enhance spatial resolution and retain spectral signatures from the perspectives of band-wise processing and full-feature joint processing, respectively. the adaptive temporal difference weighting mechanism (atdwm) is proposed to improve the ability to capture dynamic land surface changes. besides, we employ an adaptive fusion loss function to constrain the network training. experimental results indicate that the developed method is superior to several existing algorithms in terms of visual evaluation and quantitative evaluation and it can generate high-quality fusion results in scenarios of both subtle and dramatic temporal changes. codes are available at https://github.com/liupenglin/cafe.",AB_0284
