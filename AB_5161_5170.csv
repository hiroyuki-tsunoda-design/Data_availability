AB,NO
"the goal of medicinal chemistry is to improve on existing drug molecules or to create new ones for use in medicine. this is frequently accomplished by lead optimization, which entails creating similar but slightly modified versions of existing molecules. generative models that use various representations of molecules, such as smiles codes and molecular graphs, have been developed to aid in the search for hits in the unexplored chemical space. in this study, an autoencoder architecture was trained on chemical smiles from the chembl database to generate 157 analogues of vandetanib by introducing noise to its latent representation. the distribution of the autoencoder's latent space was controlled by varying batch sizes during the reconstruction of chemical smiles. virtual screening and molecular dynamics simulations were conducted, and it was found that at least two analogues had a higher binding affinity than the control compound, demonstrating the potential of this approach for lead optimization. this architecture has a small number of parameters and has the potential to generate a wide variety of molecules. the model is implemented in google colaboratory notebook to be explored by scientific community via https://colab.research.google.com/drive/1bphw7_-_vv11dbk6s9jge0bsx0k_-qih? usp=sharing.",AB_0517
"indian himalayan metagenome database (ihm-db) is a web-based database consisting of information on metagenomic datasets from various databases and publications that are specifically reported from the indian himalayan region (ihr). the online interface allows users to view or download the dataset-specific information for the respective states, category-wise, or according to the hypervariable region. the ihm-db also provides an opportunity for the users to access the metagenomic publications from the ihr as well as upload their microbiome information to the website. additionally, an open-source 16s rrna amplicon-based automated bioinformatics pipeline, autoqii2, allows users to analyze the single-end and paired-end raw reads. autoqii2 provides an automated approach for performing analysis such as quality check, adapter and chimera removal and exploits the latest ribosomal database project classifier for taxonomic assignments. the source code of the autoqii2 pipeline is available at https://gitlab.com/khatriabhi2319/autoqii2.",AB_0517
"as biological sequence databases continue growing, so do the insight that they promise to shed on the shape of the genetic diversity of life. however, to fulfil this promise the software must remain usable, be able to accommodate a large amount of data and allow use of modern high performance computing infrastructure. in this study we present a reimplementation as well as an extension of a technique using indicator vectors to compute and visualize similarities between sets of nucleotide sequences. we have a flexible and easy to use python program relying on standard and open-source libraries. our tool allows analysis of very large complement of sequences using code parallelization, as well as by providing routines to split a computational task in smaller and manageable subtasks whose results are then merged. this implementation also facilitates adding new sequences into an indicator vector based representation without re-computing the whole set. the efficient synthesis of data into knowledge is no trivial matter given the size and rapid growth of biological sequence databases. based on previous results regarding the properties of indicator vectors, the open-source approach proposed here efficiently and flexibly supports comparative analysis of genetic diversity at a large scale. our software is freely available at: https://github.com/ wandrilled/pykleebarcode.",AB_0517
"human-robot handover is a key capability of service robots, such as those used to perform routine logistical tasks for healthcare workers. recent algorithms have achieved tremendous advances in object-agnostic end-to-end planar grasping with up to six degrees of freedom (dof); however, compiling the requisite datasets is simply not feasible in many situations and many users consider the use of camera feeds invasive. this letter presents an end-to-end control system for the visual grasping of unseen objects with 6-dof without infringing on the privacy or personal space of human counterparts. in experiments, the proposed fed-hanet system trained using the federated learning framework achieved accuracy close to that of centralized non-privacy-preserving systems, while outperforming baseline methods that rely on fine-tuning. we also explores the use of a depth-only method and compares its performance to a state-of-the-art method, but ultimately emphasizes the importance of using rgb inputs for better grasp success. the practical applicability of the proposed system in a robotic system was assessed in a user study involving 12 participants. the dataset for training and all pretrained models are available at https://arg-nctu.github.io/projects/fed-hanet.html.",AB_0517
"robust slam in large-scale environments requires fault resilience and awareness at multiple stages, from sensing and odometry estimation to loop closure. in this work, we present tbv (trust but verify) radar slam, a method for radar slam that introspectively verifies loop closure candidates. tbv radar slam achieves a high correct-loop-retrieval rate by combining multiple place-recognition techniques: tightly coupled place similarity and odometry uncertainty search, creating loop descriptors from origin-shifted scans, and delaying loop selection until after verification. robustness to false constraints is achieved by carefully verifying and selecting the most likely ones from multiple loop constraints. importantly, the verification and selection are carried out after registration when additional sources of loop evidence can easily be computed. we integrate our loop retrieval and verification method with a robust odometry pipeline within a pose graph framework. by evaluation on public benchmarks we found that tbv radar slam achieves 65% lower error than the previous state of the art. we also show that it generalizes across environments without needing to change any parameters. we provide the open-source implementation at https://github.com/dan11003/tbv_slam_public",AB_0517
"the popularity of egocentric cameras and their always-on nature has lead to the abundance of day long first-person videos. the highly redundant nature of these videos and extreme camera-shakes make them difficult to watch from beginning to end. these videos require efficient summarization tools for consumption. however, traditional summarization techniques developed for static surveillance videos or highly curated sports videos and movies are either not suitable or simply do not scale for such hours long videos in the wild. on the other hand, specialized summarization techniques developed for egocentric videos limit their focus to important objects and people. this paper presents a novel unsupervised reinforcement learning framework to summarize egocentric videos both in terms of length and the content. the proposed framework facilitates incorporating various prior preferences such as faces, places, or scene diversity and interactive user choice in terms of including or excluding the particular type of content. this approach can also be adapted to generate summaries of various lengths, making it possible to view even 1-minute summaries of one's entire day. when using the facial saliency-based reward, we show that our approach generates summaries focusing on social interactions, similar to the current state-of-the-art (sota). the quantitative comparisons on the benchmark disney dataset show that our method achieves significant improvement in relaxed f-score (rfs) (29.60 compared to 19.21 from sota), bleu score (0.68 compared to 0.67 from sota), average human ranking (ahr), and unique events covered. finally, we show that our technique can be applied to summarize traditional, short, hand-held videos as well, where we improve the sota f-score on benchmark summe and tvsum datasets from 41.4 to 46.40 and 57.6 to 58.3 respectively. we also provide a pytorch implementation and a web demo at https://pravin74.github.io/int-sum/index.html.",AB_0517
"a new species of leptus, l. baspinari sp. nov., is described and illustrated from larvae collected via pitfall traps (off-host) from akcaova (seferler) reservoir, gokbel mountain, aydin province, turkiye. the new species belongs to phalangii species group and killingtoni species subgroup. leptus dubius paoli and l. pouryayevalii hakimitabar, saboori & fadaei are reported for the first time from turkiye, and l. dubius paoli is redescribed and illustrated based on turkish specimens. new metric data are given for l. pouryayevalii. keys to killingtoni, torresianus, dubius, and hospeticus species subgroups are presented, and definitions of dubius, bogoriacus and pasopaicus species subgroups are corrected.http://www.zoobank.org/urn:lsid:zoobank.org:pub:3bad8491-32e8-4d1f-b827-71f8613c540ahttp://www.zoobank.org/urn:lsid:zoobank.org:act:532672b4-56b4-4cf3-9784-f44958d111bf",AB_0517
"allotetraploid cotton plants gossypium hirsutum and gossypium barbadense have been widely cultivated for their natural, renewable textile fibres. even though ncrnas in domesticated cotton species have been ex-tensively studied, systematic identification and annotation of lncrnas and mirnas expressed in various tissues and developmental stages under various biological contexts are limited. this influences the com-prehension of their functions and future research on these cotton species. here, we report high confidence lncrnas and mirna collection from g. hirsutum accession and g. barbadense accession using large-scale rna-seq and small rna-seq datasets incorporated into a user-friendly database, concratlas. this database provides a wide range and depth of lncrna and mirna annotation based on the systematic integration of extensive annotations such as expression patterns derived from transcriptome data analysis in thousands of samples, as well as multi-omics annotations. we assume this comprehensive resource will accelerate evolutionary and functional studies in ncrnas and inform future breeding programs for cotton improve-ment. concratlas is accessible at http://www.nipgr.ac.in/concratlas/.(c) 2023 the author(s). published by elsevier b.v. on behalf of research network of computational and structural biotechnology. this is an open access article under the cc by-nc-nd license ().",AB_0517
"background: interest in sensory rooms or so-called calm rooms in psychiatric inpatient care has increased significantly. in a hospital setting, their purpose is to introduce a relaxing environment to increase well-being as well as to decrease anxiety and aggressive behaviors. calm rooms can also be used as a tool to provide self-help through a convenient environment for the patients and, at the same time, strengthen the therapeutic relationship between the patient and the professional. recent developments in virtual reality (vr) have made virtual calm rooms possible, but these have not yet been evaluated in psychiatric inpatient care. objective: this study aimed to compare the effects of vr and physical calm rooms on self-reported well-being and physiological markers of arousal. methods: the study was conducted in 2 inpatient psychiatric wards specializing in bipolar disorder from march 2019 to february 2021. patients who were already admitted were asked if they were interested in using a calm room and willing to provide ratings. this study relied on the quasi-randomized allocation of patients to the wards, which either had a physical or vr calm room. self-assessment scales (montgomery-asberg depression rating scale-self assessment [madrs-s], beck anxiety scale, and clinical global impression) were used to determine the participants' baseline level of depressive and anxiety symptoms before their use of the physical or vr calm room. the study determined the state of well-being measured using an 11-point visual analog scale (vas) as well as arousal measured by blood pressure (systolic and diastolic) and heart rate before and after the use of the calm rooms. the primary end point was self-reported well-being using the vas. results: a total of 60 participants were included-40 used the vr calm room and 20 used the physical calm room. the mean age of participants was 39 years and the majority were women (35/60, 58%). analysis of vas measurement showed improved well-being at the group level from before to after the intervention (p<.05), with no statistically significant difference in effects between the 2 different interventions. effects were not moderated by baseline depression levels (dichotomized as madrs-s >20 or <= 20) despite an overall difference in reported well-being between subgroups. conclusions: although the power in this study was low, the findings of this first study indicate comparable effects with respect to well-being and arousal of a vr calm room and a physical calm room. this suggests that a vr calm room can be a viable alternative when the use of a physical calm room is not an option for logistic or other reasons.trial registration: clinicaltrials.gov nct03918954; https://clinicaltrials.gov/ct2/show/nct03918954(j med internet res 2023;25:e42365) doi: 10.2196/42365",AB_0517
"airwriting recognition refers to the problem of identification of letters written in space with movement of the finger. it can be seen as a special case of dynamic gesture recognition wherein the set of gestures are letters in a particular language. surface electromyography (semg) is a non-invasive approach used to capture electrical signals generated as a result of contraction and relaxation of the muscles. semg has been widely adopted for gesture recognition applications. unlike static gestures, dynamic gestures are user-friendly and can be used as a method for input with applications in human computer interaction. there has been limited work in recognition of dynamic gestures such as airwriting, using semg signals and forms the core of the current work. in this work, a multi-loss minimization framework for semg based airwriting recognition is proposed. the proposed framework aims at learning a feature embedding vector that minimizes the triplet loss, while simultaneously learning the parameters of a classifier head to recognize corresponding alphabets. the proposed method is validated on a dataset recorded in the lab comprising of semg signals from 50 participants writing english uppercase alphabets. the effect of different variations of triplet loss, triplet mining strategies and feature embedding dimension is also presented. the best-achieved accuracy was 81.26% and 65.62% in user-dependent and independent scenarios respectively by using semihard positive and hard negative triplet mining. the code for our implementation will be made available at https://github.com/ayushayt/tripceair",AB_0517
