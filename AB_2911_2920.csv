AB,NO
"remote sensing scene classification (rssc) is a fundamental but challenging task in the discipline of remote sensing (rs). significant recent advancements have been achieved in rssc utilizing convolution neural networks. the increasing amount of rs images has resulted in two tough problems: intraclass diversity and interclass similarity. existing approaches cannot effectively concentrate on both global and local key features simultaneously. therefore, in this letter, we propose a dual-branch global-local attention network (dbga-net) to solve this problem. specifically, effective complementary features are first extracted from two distinct models. following that, it was designed that a global-local attention module, which concurrently focuses on both the entire image's global features and local pertinent parts within it, would be necessary to successfully extract valid information from rs images. in the end, the fusion module efficiently combines the extracted complementary features to yield more comprehensive scene information. to verify the effectiveness of dbga-net, experiments are conducted on three scene classification datasets, 99.86%, 97.60%, and 96.06% experimental results are obtained, respectively, with significant classification performance of the proposed method compared with the state-of-the-art (sota) method. our code and images are available at https://github.com/zhouyao1020/dbganet.",AB_0292
"the purpose of panchromatic (pan) sharpening, i.e., pansharpening, is to fuse a low spatial resolution multispectral (lrms) image with a high spatial resolution pan image, aiming to obtain a high spatial resolution multispectral (hrms) image. pansharpening models based on variational optimization consist of a spectral fidelity term, a spatial fidelity term, and a regularization term. most of the methods assume that the existing pan image and the homologous hrms image satisfy the global or local linear relationship, which could be far from the real case, thus causing suboptimal performance. inspired by the nonlinear mapping ability of machine learning (ml) techniques, we propose a novel spatial fidelity term with learnable nonlinear mapping (lnm-sf), which trains an implicit functional operator via a specifically designed convolutional neural network (cnn) and efficiently constructs the nonlinear relationship between the known pan and the latent hrms images. relying upon the above description of the spatial fidelity term, a new variational model with a learnable nonlinear mapping in the spatial fidelity term for pansharpening, named lnm-ps, is simply integrated by the conventional spectral fidelity term into the proposed lnm-sf. to effectively solve the resulting optimization problem, we develop an alternating direction method of multipliers (admm)-based algorithm with the fast iterative shrinkage-thresholding algorithm (fista) as an inner solver. extensive numerical experiments on different datasets, assessing the performance both at reduced resolution and full resolution, show the superiority of the proposed lnm-ps method. the code is available at https://github.com/liangjiandeng/-lnm-ps.",AB_0292
"deep learning, especially deep neural networks (dnns), has been widely and successfully adopted in many critical applications for its high effectiveness and efficiency. the rapid development of dnns has benefited from the existence of some high-quality datasets (e. g., imagenet), which allow researchers and developers to easily verify the performance of their methods. currently, almost all existing released datasets require that they can only be adopted for academic or educational purposes rather than commercial purposes without permission. however, there is still no good way to ensure that. in this paper, we formulate the protection of released datasets as verifying whether they are adopted for training a (suspicious) third-party model, where defenders can only query the model while having no information about its parameters and training details. based on this formulation, we propose to embed external patterns via backdoor watermarking for the ownership verification to protect them. our method contains two main parts, including dataset watermarking and dataset verification. specifically, we exploit poison-only backdoor attacks (e. g., badnets) for dataset watermarking and design a hypothesis-test-guided method for dataset verification. we also provide some theoretical analyses of our methods. experiments on multiple benchmark datasets of different tasks are conducted, which verify the effectiveness of our method. the code for reproducing main experiments is available at https://github.com/thuyimingli/dvbw.",AB_0292
"for the abundant spectral and spatial information recorded in hyperspectral images (hsis), fully exploring spectral-spatial relationships has attracted widespread attention in the hsi classification (hsic) community. however, there are still some intractable obstructs. for one thing, in the patch-based processing pattern, some spatial neighbor pixels are often inconsistent with the central pixel in land-cover class. for another thing, linear and nonlinear correlations between different spectral bands are vital yet tough for representing and excavating. to overcome these mentioned issues, an adaptive mask sampling and manifold to the euclidean subspace learning (ams-m2esl) framework is proposed for hsic. specifically, an adaptive mask-based intrapatch sampling (amips) module is first formulated for intrapatch sampling in an adaptive mask manner based on central spectral vector-oriented spatial relationships. subsequently, based on the distance covariance descriptor, a dual-channel distance covariance representation (dc-dcr) module is proposed for modeling unified spectral-spatial feature representations and exploring spectral-spatial relationships, especially linear and nonlinear interdependence in the spectral domain. furthermore, considering that the distance covariance matrix lies on the symmetric positive definite (spd) manifold, we implement an m2esl module respecting the riemannian geometry of the spd manifold for high-level spectral-spatial feature learning. additionally, we introduce an approximate matrix square-root (asqrt) layer for efficient euclidean subspace projection. extensive experimental results on three popular hsi datasets with limited training samples demonstrate the superior performance of the proposed method compared with other state-of-the-art methods. the source code is available at https://github.com/lms-07/ams-m2esl.",AB_0292
"target fine-grained classification has been the research hotspot in remote sensing image interpretation, which has received general attention in application fields. one challenge of the fine-grained classification task is to learn the most discriminative feature using the deep convolutional neural network (dcnn). at present, many works of fine-grained image classification obtain target features by optimizing the feature extraction and enhancement, which are not accurate enough in remote sensing images. in this article, we propose an essential feature mining network (efm-net) based on dcnn to address this issue. its major motivation is to obtain the essential feature, which is fine enough to distinguish between similar instances. the proposed pipeline includes the miner for purifying the essential feature and the refiner for data augmentation. these two modules can work in a mutually reinforcing way and extract the essential feature of targets. we evaluate efm-net on two public fine-grained classification datasets in remote sensing, fgsc-23 and fgscr-42, and our aircraft-16. the results show that the proposed method consistently outperforms existing alternatives. we have released our source code in github https://github.com/jacyi/efm-net-pytorch.git.",AB_0292
"recently, semantic segmentation technology has been a research hotspot in optical remote sensing urban use classification. however, because of coupled semantic relations in very high-resolution and complex urban scenes, a more effective semantic description for pixelwise urban use interpretation has become a challenge. then, aiming to set up a more effective semantic description, the effective receptive field (erf) is analyzed in general convolutional neural networks. the unreasonable erf distribution in the stacked convolutional layers of the encoder would lead to a large amound of small erfs and fewer not large enough erfs that form a naive semantic description in decoder. therefore, in this article, a novel full semantic constructed network (fscnet) is proposed to improve the naive semantic description and set up an effective semantic description. first, to avoid noise from shallow feature layers, a residual refinement convolution is designed to optimize the full-scale skip connections based on the u-shaped encoder-decoder. second, an interscale fusion module is newly designed for multiscale feature fusion, which can generate three initial semantic modalities that are prepared for redefining the full semantic description. third, a multiscale local context spatial attention module and boundary supervision are designed for an initial shallow semantic modality to capture the pure boundary information, and then, pyramid spatial pooling is employed for an initial deep semantic modality to further enlarge the erf and obtain more abstract global information. next, a self-calibration convolution combined with the atrous spatial pyramid pooling is designed to rectify and enrich an initial middle semantic modality, which can improve the naive semantic description and bridge the semantic gap between the redefined shallow and deep semantic modalities to advance the full semantic feature fusion. finally, extensive experiments are carried out on three benchmarks (e.g., isprs vaihingen, potsdam, and dlrsd), and comparative results show that the proposed fscnet can get remarkable performance compared to state-of-the-art (sota) methods. besides, the code is available at https://github.com/doriscv/fscnet.",AB_0292
"remote-sensing (rs) images with high spatial and temporal resolutions play a significant role in monitoring periodic landscape changes for earth observation science. to enrich rs images, spatiotemporal fusion (stf) is considered a promising approach. the key challenge in the current stf-based methods is the requirement for large-scale data. in this work, we propose a deep-learning-based method called spatiotemporal fusion multilayer perceptron (stfmlp) to tackle this challenge. first, our method focuses on the given data in the manner of transductive learning. second, we propose a designed multilayer perceptron (mlp) model to capture the time dependency and consistency among the input images. consequently, stfmlp is capable of simultaneously achieving more accurate fusion and requiring a small-scale of data. we conduct extensive experiments on two widely adopted public datasets, namely coleambally irrigation area (cia) and the lower gwydir catchment (lgc). the experimental results demonstrate that the proposed method outperforms the state-of-the-art methods effectively. code, trained model, and cropped images are available online (https://github.com/luhailaing-max/stfmlp-master).",AB_0292
"deep learning methods are popular for hyperspectral and multispectral image (hsi-msi) fusion to obtain a high-resolution hsi. however, most of them are unsatisfactory due to limited generalization ability and poor interpretability. this article proposes a highly interpretable deep hsi-msi fusion method based on probabilistic matrix factorization (pmf) under the bayesian framework. in the proposed method, an hsi is factorized into two matrices, namely, the gaussian-prior-regularized spectral matrix and the deep-prior-regularized abundance matrix. then, we split the optimization process into two meaningful iterative updating steps: updating the spectral matrix based on least-squares estimation and updating the abundance matrix based on a convolutional neural network (cnn)-based gaussian denoiser for 2-d gray images. to improve the generalization ability, we provide solutions for selections of hyperparameters, cnn-based denoiser architecture, and training strategy. using the given solutions, the proposed fusion method can be trained with 2-d images once and then used to fuse different types of hsi and msi excellently. experiments on three datasets demonstrate that the proposed fusion method has good fusion performance and high generalization ability compared with other state-of-the-art methods. the source code will be available at https://github.com/kevinbhlin/.",AB_0292
"single-frame infrared small target (sirst) detection has been a challenging task due to a lack of inherent characteristics, imprecise bounding box regression, a scarcity of real-world datasets, and sensitive localization evaluation. in this article, we propose a comprehensive solution to these challenges. first, we find that the existing anchor-free label assignment method is prone to mislabeling small targets as background, leading to their omission by detectors. to overcome this issue, we propose an all-scale pseudobox-based label assignment scheme that relaxes the constraints on the scale and decouples the spatial assignment from the size of the ground-truth target. second, motivated by the structured prior of feature pyramids, we introduce the one-stage cascade refinement network (oscar), which uses the high-level head as soft proposal for the low-level refinement head. this allows oscar to process the same target in a cascade coarse-to-fine manner. finally, we present a new research benchmark for infrared small target detection, consisting of the sirst-v2 dataset of real-world, high-resolution single-frame targets, the normalized contrast evaluation metric, and the deepinfrared toolkit for detection. we conduct extensive ablation studies to evaluate the components of oscar and compare its performance to state-of-the-art model- and data-driven methods on the sirst-v2 benchmark. our results demonstrate that a top-down cascade refinement framework can improve the accuracy of infrared small target detection without sacrificing efficiency. the deepinfrared toolkit, dataset, and trained models are available at https://github.com/yimiandai/open-deepinfrared.",AB_0292
"for semantic segmentation of remote sensing images, convolutional neural networks (cnns) have proven to be powerful tools. however, the existing cnn-based methods have the problems of feature information loss, serious interference by clutter information, and ignoring the correlation between different scale features. to solve these problems, this article proposes a novel hidden feature-guided semantic segmentation network (hfgnet) for remote sensing images, which achieves accurate semantic segmentation by hierarchically extracting and fusing valuable feature information. specifically, the hidden feature extraction module (hfe-m) is introduced to suppress the salient feature representation to mine more valuable hidden features. meanwhile, the multifeature interactive fusion module (mif-m) establishes the correlation between different features to achieve hierarchical feature fusion. the multiscale feature calibration module (msfc) is constructed to enhance the diversity and refinement representation of hierarchical fusion features. besides, the local-channel attention mechanism (lca-m) is designed to improve the feature perception capability of the object region and suppress background information interference. we conducted extensive experiments on the widely used isprs 2-d semantic labeling dataset and the 15-class gaofen image dataset. experimental results demonstrate that the proposed hfgnet has advantages over several state-of-the-art methods. the source code and models are available at https://github.com/darkseid-arch/rs-hfgnet.",AB_0292
