AB,NO
"field boundaries are at the core of many agricultural applications and are a key enabler for the operational monitoring of agricultural production to support food security. recent scientific progress in deep learning methods has highlighted the capacity to extract field boundaries from satellite and aerial images with a clear improvement from object-based image analysis (e.g. multiresolution segmentation) or conventional filters (e.g. sobel filters). however, these methods need labels to be trained on. so far, no standard data set exists to easily and robustly benchmark models and progress the state of the art. the absence of such benchmark data further impedes proper comparison against existing methods. besides, there is no consensus on which evaluation metrics should be reported (both at the pixel and field levels). as a result, it is currently impossible to compare and benchmark new and existing methods. to fill these gaps, we introduce ai4boundaries, a data set of images and labels readily usable to train and compare models on field boundary detection. ai4boundaries includes two specific data sets: (i) a 10 m sentinel-2 monthly composites for large-scale analyses in retrospect and (ii) a 1 m orthophoto data set for regional-scale analyses, such as the automatic extraction of geospatial aid application (gsaa). all labels have been sourced from gsaa data that have been made openly available (austria, catalonia, france, luxembourg, the netherlands, slovenia, and sweden) for 2019, representing 14.8 m parcels covering 376 k km2. data were selected following a stratified random sampling drawn based on two landscape fragmentation metrics, the perimeter/area ratio and the area covered by parcels, thus considering the diversity of the agricultural landscapes. the resulting ai4boundaries dataset consists of 7831 samples of 256 by 256 pixels for the 10 m sentinel-2 dataset and of 512 by 512 pixels for the 1 m aerial orthophoto. both datasets are provided with the corresponding vector ground-truth parcel delineation (2.5 m parcels covering 47 105 km(2)), and with a raster version already pre-processed and ready to use. besides providing this open dataset to foster computer vision developments of parcel delineation methods, we discuss the perspectives and limitations of the dataset for various types of applications in the agriculture domain and consider possible further improvements. the data are available on the jrc open data catalogue: http://data.europa.eu/89h/0e79ce5d-e4c8-4721-8773-59a4acf2c9c9 .",AB_0413
"cysteine is a common amino acid with a thiol group that plays a pivotal role in a variety of scenarios in redox biochemistry. in contrast, selenocysteine, the 21st amino acid, is only present in 25 human proteins. classical force-field parameters for cysteine and selenocysteine are still scarce. in this context, we present a methodology to obtain lennard-jones parameters for cysteine and selenocysteine in different physiologically relevant oxidation and protonation states. the new force field parameters obtained in this work are available at https://github.com/ malbecc/amber-parameters-database. the parameters were adjusted to reproduce water radial distribution functions obtained by density functional theory ab initio molecular dynamics. we validated the results by evaluating the impact of the choice of parameters on the structure and dynamics in classical molecular dynamics simulations of representative proteins containing catalytic cysteine/selenocysteine residues. there are significant changes in protein structure and dynamics depending on the parameters choice, specifically affecting the residues close to the catalytic sites.",AB_0413
"multi-view stereo (mvs) algorithms rely on common photometric consistency measures and, therefore, in cases of low-textured surfaces tend to generate unreliable depth estimates or lack completeness due to matching ambiguities. such textureless areas often imply dominant planar structures, typically occurring in man-made scenes. to support depth estimation in scenarios where challenging surfaces are present, we propose an extended patchmatch pipeline using an adaptive accumulated matching cost calculation based on estimated prior plane hypotheses and the local textureness. plane priors are detected in the object space and guided by quadtree structures in order to generate depth and normal hypothesis for every pixel, supporting, in this way, the propagation of more reliable depth estimates across the image. experiments on the eth3d high-resolution dataset and on custom real-world scenes demonstrate that our approach can favor the reconstruction of problematic regions by adding small complexity while preserving fine details in rich textured regions, achieving thus competitive results compared to state-of-the-art methods. the source code of the developed method is available at https://github.com/3dom-fbk/openmvs.",AB_0413
"we report an implementation of the hadron-hadron (pp and p (p) over bar) collision mode to the monte carlo event generator renesance - the code that was previously developed for e(+)e(-) collisions. the described extension of renesance currently contains neutral and charged current drell-yan processes pp[p (p) over bar] -> zx -> l(+) l(-) x, pp[p (p) over bar] -> w+ x -> l(+) nu x-l and pp[p (p) over bar] -> w- x -> l(-) (nu) over bar x-l. we take into account complete one-loop electroweak (ew) and one-loop qcd corrections to these processes. the calculation is based on the sanc (support for analytic and numeric calculations for experiments at colliders) modules. the generator is constructed in such a way that new processes can be easily added. the paper contains a theoretical description of the sanc approach, numerical validations and a manual. program summary program title: renesanceversion 1.3.0 cpc library link to program files: https://doi.org/10.17632/wp36f7t3ft.2 licensing provisions: gplv3 programming language: fortran 77/90, c, c++ external routines: root (https://root.cern.ch), lhapdf (https://lhapdf.hepforge.org) journal reference of previous version: comput. phys. commun. 256 (2020) 107445 does the new version supersede the previous version?: yes. reasons for the new version: implementation of the hadron-hadron collision mode. summary of revisions: added support of the pp and p (p) over bar collision modes. implemented neutral and charged current drell-yan processes. nature of problem: theoretical calculations at next-to-leading order in perturbation theory allow to compute higher precision amplitudes for standard model processes and decays. proper treatments of uv divergences and ir singularities are performed. solution method: numerical integration of the precomputed differential expressions for cross sections of certain processes implemented assancmodules[1,2]. additional comments including restrictions and unusual features: renesancehomepage https://renesance.hepforge.org. the sanc modules and codes also available at http://sanc.jinr.ru. the list of processes in the hadron-hadron collision mode is limited to pp[p (p) over bar] -> zx -> l(+) l(-) x, pp[(p) over bar] -> w+x -> l(+) nu x-l and pp[(p) over bar] -> w- x -> l(+)(nu) over bar x-l. (c) 2022 elsevier b.v. all rights reserved.",AB_0413
"having a prediction model for air quality at a low computational cost can be useful for research, forecasting, regulatory, and monitoring applications. this is of particular importance for latin america, where rapid urbanization has imposed increasing stress on the air quality of almost all cities. in recent years, machine learning techniques have been increasingly accepted as a useful tool for air quality forecasting. out of these, random forest has proven to be an approach that is both well-performing and computationally efficient while still providing key components reflecting the nonlinear relationships among emissions, chemical reactions, and meteorological effects. in this work, we employed the random forest methodology to build and test a forecasting model for the city of buenos aires. we used this model to study the deep decline in most pollutants during the lockdown imposed by the covid-19 (coronavirus disease 2019) pandemic by analyzing the effects of the change in emissions, while taking into account the changes in the meteorology, using two different approaches. first, we built random forest models trained with the data from before the beginning of the lockdown periods. we used the data to make predictions of the business-as-usual scenario during the lockdown periods and estimated the changes in concentrations by comparing the model results with the observations. this allowed us to assess the combined effects of the particular weather conditions and the reduction in emissions during the period when restrictions were in place. second, we used random forest with meteorological normalization to compare the observational data from the lockdown periods with the data from the same dates in 2019, thus decoupling the effects of the meteorology from short-term emission changes. this allowed us to analyze the general effect that restrictions similar to those imposed during the pandemic could have on pollutant concentrations, and this information could be useful to design mitigation strategies. the results during testing showed that the model captured the observed hourly variations and the diurnal cycles of these pollutants with a normalized mean bias of less than 6 % and pearson correlation coefficients of the diurnal variations between 0.64 and 0.91 for all the pollutants considered. based on the random forest results, we estimated that the lockdown implied relative changes in concentration of up to - 45 % for co, -75 % for no, -46 % for no2, -12 % for so2, and -33 % for pm10 during the strictest mobility restrictions. o3 had a positive relative change in concentration (up to an 80 %) that is consistent with the response in a volatile-organic compound-limited chemical regime to the decline in nox emissions. the relative changes estimated using the meteorological normalization technique show mostly smaller changes than those obtained by the random forest predictive model. the relative changes were up to -26 % for co, up to -47 % for no, -36 % for no2, -20 % for pm10, and up to 27 % for o3. so2 is the only species that had a larger relative change when the meteorology was normalized (up to 20 %). this points out the need for accounting not only for differences in emissions but also in meteorological variables in order to evaluate the lockdown effects on air quality. the findings of this study may be valuable for formulating emission control strategies that do not disregard their implication on secondary pollutants. we believe that the model itself can also be a valuable contribution to a forecasting system in the city and that the general methodology could also be easily applied to other latin american cities as well. we also provide the first o3 and so2 observational dataset in more that a decade for a residential area in buenos aires, and it is openly available at https://doi.org/10.17632/h9y4hb8sf8.1 (diaz resquin et al., 2021).",AB_0413
"objectives:<bold> </bold>to identify and prioritise the top 10 research questions for psoriatic arthritis (psa). methods:<bold> </bold>the british psoriatic arthritis consortium (britpact) formed a priority setting partnership (psp) comprising of people living with psa, carers and clinicians, supported by the james lind alliance (jla). this psp followed the established three-stage jla process:first, an online survey of people living with psa, carers, and clinicians to identify psa questions, asking, what do you think are the most important unanswered questions in psoriatic arthritis research? . the questions were checked against existing evidence to establish true uncertainties and grouped as indicative questions reflecting the overarching themes. then a second online survey ranked the true uncertainties by importance. finally, a workshop including people living with psa and clinician stakeholders finalised the top 10 research priorities. results:<bold> </bold>the initial survey attracted 317 respondents (69% people living with psa, 15% carers), with 988 questions. this generated 46 indicative questions. in the second survey, 422 respondents (78% people living with psa, 4% carers) prioritised these. eighteen questions were taken forward to the final online workshop. the top unanswered psa research question was what is the best strategy for managing patients with psoriatic arthritis including non-drug and drug treatments? . other top 10 priorities covered diagnosis, prognosis, outcome assessment, flares, comorbidities and other aspects of treatment (https://www.jla.nihr.ac.uk). conclusion:<bold> </bold>the top 10 priorities will guide psa research and enable psa researchers and those who fund research to know the most important questions for people living with psa.",AB_0413
"leaf area is a key structural characteristic of forest canopies because of the role of leaves in controlling many biological and physical processes occurring at the biosphere-atmosphere transition. high pulse density airborne laser scanning (als) holds promise to provide spatially resolved and accurate estimates of plant area density (pad) in forested landscapes, a key step in understanding forest functioning: phenology, carbon uptake, transpiration, radiative balance etc. inconsistencies between different als sensors is a barrier to generating globally harmonised pad estimates. the basic assumption on which pad estimation is based is that light attenuation is proportional to vegetation area density. this study shows that the recorded extinction strongly depends on target detectability which is influenced by laser characteristics (power, sensitivity, wavelength). three different airborne laser scanners were flown over a wet tropical forest at the paracou research station in french guiana. different sensors, flight heights and transmitted power levels were compared. light attenuation was retrieved with an open source ray-tracing code (http://amapvox.org). direct comparison revealed marked differences (upto 25% difference in profile-averaged light attenuation rate and 50% difference at particular heights) that could only be explained by differences in scanner characteristics. we show how bias which may occur under various acquisition conditions can generally be mitigated by a sensor intercalibration. alignment of light weight lidar attenuation profiles to als reference attenuation profiles is not always satisfactory and we discuss what are the likely sources of discrepancies. neglecting the dependency of apparent light attenuation on scanner properties may lead to biases in estimated vegetation density commensurate to those affecting light attenuation estimates. applying intercalibration procedures supports estimation of plant area density independent of acquisition characteristics.",AB_0413
"electrophilicity (e) is one of the most important parameters to understand the reactivity of an organic molecule. although the theoretical electrophilicity index (omega) has been associated with e in a small homologous series, the use of w to predict e in a structurally heterogeneous set of compounds is not a trivial task. in this study, a robust ensemble model is created using mayr's database of reactivity parameters. a combination of topological and quantum mechanical descriptors and different machine learning algorithms are employed for the model's development. the predictability of the model is assessed using different statistical parameters, and its validation is examined, including a training/test partition, an applicability domain, and a y- scrambling test. the global ensemble model presents a q5-fold2 of 0.909 and a qext2 of 0.912, demonstrating an excellent predictability performance of e values and showing that w is not a good descriptor for the prediction of e, especially for the case of neutral compounds. electropredictor, a noncommercial python application (https://github.com/mmoreno1/electropredictor), is developed to predict e. qm9, a well-known large dataset containing 133885 neutral molecules, is used to perform a virtual screening (94.0% coverage). finally, the 10 most electrophilic molecules are analyzed as possible new mayr's electrophiles, which have not yet been experimentally tested. this study confirms the necessity to build an ensemble model using nonlinear machine learning algorithms, topographic descriptors, and separating molecules into charged and neutral compounds to predict e with precision.",AB_0413
"file fragment type identification is an important step in file carving and data recovery. machine learning techniques, especially neural networks, have been utilized for this problem, some with very promising results. this paper presents a novel neural network architecture for identifying file fragment types using a combination of byte embeddings as well as recurrent and convolutional elements. the corresponding classification model, bytercnn, has been trained on the publicly available file fragment fifty dataset and evaluated in closed-set and open-set recognition settings using fifty and other available file fragment datasets. evaluation results have demonstrated that bytercnn can compete with state-of-the-art models described in literature in terms of classification accuracy, with 71.1% average accuracy on 512-byte fragments and 83.9% average accuracy on 4,096-byte fragments from the fifty dataset. when evaluated on other publicly available datasets in closed-set and open-set recognition settings, bytercnn performs similarly or slightly better than the fifty classification model. obtained results overall suggest that bytercnn is a competitive file fragment classification model, but they also reveal that there is still plenty of space for further improving file type identification methods using more complex datasets or in open-set recognition settings. bytercnn is publicly available at https://github.com/kristian-fer/bytercnn.",AB_0413
"believing that biometrics trends are moving to distant and contactless mode, in-air signature verification is nowadays considered as one of the principal users biometric identification in contactless mode allowing users identification by drawing their handwritten signature in the air. in-air signature verification is used in many applications like access control and forensic analysis. in this regard, we propose a novel system for in-air signature verification using beta stroke segmentation. the beta-elliptical approach and the fuzzy perceptual detector are used for features extraction. the proposed system defines a specific data acquisition protocol and uses preprocessing steps to prepare data. finally, the verification phase is done based on dynamic time warping. to evaluate our proposed system, we have created two in-air signature datasets with and without the use of a transparent glass plate, which we make publicly available at https://ieee-dataport.org/documents/air-signature-databases, termed respectively in-air signature dataset (ias dataset) and in-air signature dataset using glass plate (iasgp dataset). our verification system demonstrates promising outcomes, yielding an equal error rate (eer) of 1.25% when applied to the ias dataset and an eer of 2.00% when applied to the iasgp dataset in the skilled-forgery scenario. extensive evaluations were conducted on both the 3dairsig and the deepairsig datasets. the results confirm that the proposed system has a good performance compared to existing in-air signature verification systems for both skilled-forgery and random-forgery scenarios.",AB_0413
