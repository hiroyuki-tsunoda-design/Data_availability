AB,NO
"the ramsar convention of 1971 encourages wetland preservation, but it is unclear how climate change will affect wetland extent and related biodiversity. due to the use of the self-attention mechanism, vision transformers (vits) gain better modeling of global contextual information and become a powerful alternative to convolutional neural networks (cnns). however, vits require enormous training datasets to activate their image classification power, and gathering training samples for remote sensing applications is typically costly. as such, in this study, we develop a deep learning algorithm called (wetmapformer), which effectively utilizes both cnns and vision transformer architectures for precise mapping of wetlands in three pilot sites around the albert county, york county, and grand bay-westfield located in new brunswick, canada. the wetmapformer utilizes local window attention (lwa) rather than the conventional self-attention mechanism for improving the capability of feature generalization in a local area by substantially reducing the computational cost of vanilla vits. we extensively evaluated the robustness of the proposed wetmapformer with sentinel-1 and sentinel-2 satellite data and compared it with the various cnns and vision transformer models which include vit, swin transformer, hybridsn, coatnet, a multimodel network, and resnet, respectively. the proposed wetmapformer achieves f-1 scores of 0.94, 0.94, 0.96, 0.97, 0.97, 0.97, and 1 for the recognition of aquatic bed, freshwater marsh, shrub wetland, bog, fen, forested wetland, and water, respectively. as compared to other vision transformers, the wetmapformer limits receptive fields while adjusting translational invariance and equivariance characteristics. the codes will be made available publicly at https://github.com/aj1365/ wetmapformer.",AB_0426
"background: the spectrum of mutations in a collection of cancer genomes can be described by a mixture of a few mutational signatures. the mutational signatures can be found using non-negative matrix factorization (nmf). to extract the mutational signatures we have to assume a distribution for the observed mutational counts and a number of mutational signatures. in most applications, the mutational counts are assumed to be poisson distributed, and the rank is chosen by comparing the fit of several models with the same underlying distribution and different values for the rank using classical model selection procedures. however, the counts are often overdispersed, and thus the negative binomial distribution is more appropriate. results: we propose a negative binomial nmf with a patient specific dispersion parameter to capture the variation across patients and derive the corresponding update rules for parameter estimation. we also introduce a novel model selection procedure inspired by cross-validation to determine the number of signatures. using simulations, we study the influence of the distributional assumption on our method together with other classical model selection procedures. we also present a simulation study with a method comparison where we show that state-of-the-art methods are highly overestimating the number of signatures when overdispersion is present. we apply our proposed analysis on a wide range of simulated data and on two real data sets from breast and prostate cancer patients. on the real data we describe a residual analysis to investigate and validate the model choice. conclusions: with our results on simulated and real data we show that our model selection procedure is more robust at determining the correct number of signatures under model misspecification. we also show that our model selection procedure is more accurate than the available methods in the literature for finding the true number of signatures. lastly, the residual analysis clearly emphasizes the overdispersion in the mutational count data. the code for our model selection procedure and negative binomial nmf is available in the r package sigmos and can be found at https://github. com/martapelizzola/sigmos.",AB_0426
"microorganisms produce small bioactive compounds as part of their secondary or specialised metabolism. often, such metabolites have antimicrobial, anticancer, antifungal, antiviral or other bio-activities and thus play an important role for applications in medicine and agriculture. in the past decade, genome mining has become a widely-used method to explore, access, and analyse the available biodiversity of these compounds. since 2011, the 'antibiotics and secondary metabolite analysis shell-antismash' (https://antismash.secondarymetabolites.org/) has supported researchers in their microbial genome mining tasks, both as a free to use web server and as a standalone tool under an osi-approved open source licence. it is currently the most widely used tool for detecting and characterising biosynthetic gene clusters (bgcs) in archaea, bacteria, and fungi. here, we present the updated version 7 of antismash. antismash 7 increases the number of supported cluster types from 71 to 81, as well as containing improvements in the areas of chemical structure prediction, enzymatic assembly-line visualisation and gene cluster regulation.",AB_0426
"molecular interactions that modulate catalytic pro-cesses occur mainly in cavities throughout the molecular surface. such interactions occur with spe-cific small molecules due to geometric and physico-chemical complementarity with the receptor. in this scenario, we present kvfinder-web, an open-source web-based application of parkvfinder software for cavity detection and characterization of biomolec-ular structures. the kvfinder-web has two inde-pendent components: a restful web service and a web graphical portal. our web service, kvfinder-web service, handles client requests, manages accepted jobs, and performs cavity detection and characterization on accepted jobs. our graphical web portal, kvfinder-web portal, provides a simple and straightforward page for cavity analysis, which customizes detection parameters, submits jobs to the web service component, and displays cavities and characterizations. we provide a publicly available kvfinder-web at https://kvfinder-web.cnpem.br, run-ning in a cloud environment as docker containers. further, this deployment type allows kvfinder-web components to be configured locally and customized according to user demand. hence, users may run jobs on a locally configured service or our public kvfinder-web.",AB_0426
"the cellular immune system, which is a critical component of human immunity, uses t cell receptors (tcrs) to recognize antigenic proteins in the form of peptides presented by major histocompatibility complex (mhc) proteins. accurate definition of the structural basis of tcrs and their engagement of peptide-mhcs can provide major insights into normal and aberrant immunity, and can help guide the design of vaccines and immunotherapeutics. given the limited amount of experimentally determined tcr-peptide-mhc structures and the vast amount of tcrs within each individual as well as antigenic targets, accurate computational modeling approaches are needed. here, we report a major update to our web server, tcrmodel, which was originally developed to model unbound tcrs from sequence, to now model tcr-peptide-mhc complexes from sequence, utilizing several adaptations of alphafold. this method, named tcrmodel2, allows users to submit sequences through an easy-to-use interface and shows similar or greater accuracy than alphafold and other methods to model tcr-peptide-mhc complexes based on benchmarking. it can generate models of complexes in 15 minutes, and output models are provided with confidence scores and an integrated molecular viewer. tcrmodel2 is available at https://tcrmodel.ibbr.umd.edu.",AB_0426
"the human thalamus is a highly connected brain structure, which is key for the control of numerous functions and is involved in several neurological disorders. recently, neuroimaging studies have increasingly focused on the volume and connectivity of the specific nuclei comprising this structure, rather than looking at the thalamus as a whole. however, accurate identification of cytoarchitectonically designed histological nuclei on standard in vivo structural mri is hampered by the lack of image contrast that can be used to distinguish nuclei from each other and from surrounding white matter tracts. while diffusion mri may offer such contrast, it has lower resolution and lacks some boundaries visible in structural imaging. in this work, we present a bayesian segmen-tation algorithm for the thalamus. this algorithm combines prior information from a probabilistic atlas with likelihood models for both structural and diffusion mri, allowing segmentation of 25 thalamic labels per hemi-sphere informed by both modalities. we present an improved probabilistic atlas, incorporating thalamic nuclei identified from histology and 45 white matter tracts surrounding the thalamus identified in ultra-high gradi-ent strength diffusion imaging. we present a family of likelihood models for diffusion tensor imaging, ensuring compatibility with the vast majority of neuroimaging datasets that include diffusion mri data. the use of these diffusion likelihood models greatly improves identification of nuclear groups versus segmentation based solely on structural mri. dice comparison of 5 manually identifiable groups of nuclei to ground truth segmentations show improvements of up to 10 percentage points. additionally, our chosen model shows a high degree of re-liability, with median test-retest dice scores above 0.85 for four out of five nuclei groups, whilst also offering improved detection of differential thalamic involvement in alzheimer's disease (auroc 81.98%). the probabilis-tic atlas and segmentation tool will be made publicly available as part of the neuroimaging package freesurfer ( https://freesurfer.net/fswiki/thalamicnucleidti ).",AB_0426
"methods for teaching motion skills to robots focus on training for a single skill at a time. robots capable of learning from demonstration can considerably benefit from the added ability to learn new movement skills without forgetting what was learned in the past. to this end, we propose an approach for continual learning from demonstration using hypernetworks and neural ordinary differential equation solvers. we empirically demonstrate the effectiveness of this approach in remembering long sequences of trajectory learning tasks without the need to store any data from past demonstrations. our results show that hypernetworks outperform other state-of-the-art continual learning approaches for learning from demonstration. in our experiments, we use the popular lasa benchmark, and two new datasets of kinesthetic demonstrations collected with a real robot that we introduce in this paper called the helloworld and robotasks datasets. we evaluate our approach on a physical robot and demonstrate its effectiveness in learning real-world robotic tasks involving changing positions as well as orientations. we report both trajectory error metrics and continual learning metrics, and we propose two new continual learning metrics. our code, along with the newly collected datasets, is available at https://github.com/sayantanauddy/clfd. (c) 2023 the author(s). published by elsevier b.v. this is an open access article under the cc by license ().",AB_0426
"in addition to vaccines, the world health organization sees novel medications as an urgent matter to fight the ongoing covid-19 pandemic. one possible strategy is to identify target proteins, for which a perturbation by an existing compound is likely to benefit covid-19 patients. in order to contribute to this effort, we present guiltytargets-covid-19 (https:// guilt ytarg ets- covid. eu/), a machine learning supported web tool to identify novel candidate drug targets. using six bulk and three single cell rna-seq datasets, together with a lung tissue specific protein-protein interaction network, we demonstrate that guiltytargets-covid-19 is capable of (i) prioritizing meaningful target candidates and assessing their druggability, (ii) unraveling their linkage to known disease mechanisms, (iii) mapping ligands from the chembl database to the identified targets, and (iv) pointing out potential side effects in the case that the mapped ligands correspond to approved drugs. our example analyses identified 4 potential drug targets from the datasets: akt3 from both the bulk and single cell rna-seq data as well as akt2, mlkl, and mapk11 in the single cell experiments. altogether, we believe that our web tool will facilitate future target identification and drug development for covid-19, notably in a cell type and tissue specific manner.",AB_0426
"bayesian parameter inference is an essential tool in modern cosmology, and typically requires the calculation of 105-106 theoretical models for each inference of model parameters for a given dataset combination. computing these models by solving the linearised einstein-boltzmann system usually takes tens of cpu core-seconds per model, making the entire process very computationally expensive.in this paper we present connect, a neural network framework emulating class computations as an easy-to-use plug-in for the popular sampler montepython. connect uses an iteratively trained neural network which emulates the observables usually computed by class. the training data is generated using class, but using a novel algorithm for generating favourable points in parameter space for training data, the required number of class-evaluations can be reduced by two orders of magnitude compared to a traditional inference run. once connect has been trained for a given model, no additional training is required for different dataset combinations, making connect many orders of magnitude faster than class (and making the inference process entirely dominated by the speed of the likelihood calculation). for the models investigated in this paper we find that cosmological parameter infer-ence run with connect produces posteriors which differ from the posteriors derived us-ing class by typically less than 0.01-0.1 standard deviations for all parameters. we also stress that the training data can be produced in parallel, making efficient use of all avail-able compute resources. the connect code is publicly available for download on github (https://github.com/aarhuscosmology/connect_public).",AB_0426
"digital scans of analogue photographic film typically contain artefacts such as dust and scratches. automated removal of these is an important part of preservation and dissemination of photographs of historical and cultural importance. while state-of-the-art deep learning models have shown impressive results in general image inpainting and denoising, film artefact removal is an understudied problem. it has particularly challenging requirements, due to the complex nature of analogue damage, the high resolution of film scans, and potential ambiguities in the restoration. there are no publicly available high-quality datasets of real-world analogue film damage for training and evaluation, making quantitative studies impossible. we address the lack of ground-truth data for evaluation by collecting a dataset of 4k damaged analogue film scans paired with manually-restored versions produced by a human expert, allowing quantitative evaluation of restoration performance. we have made the dataset available at https://doi.org/10.6084/m9.figshare.21803304. we construct a larger synthetic dataset of damaged images with paired clean versions using a statistical model of artefact shape and occurrence learnt from real, heavily-damaged images. we carefully validate the realism of the simulated damage via a human perceptual study, showing that even expert users find our synthetic damage indistinguishable from real. in addition, we demonstrate that training with our synthetically damaged dataset leads to improved artefact segmentation performance when compared to previously proposed synthetic analogue damage overlays. the synthetically damaged dataset can be found at https://doi.org/10.6084/m9.figshare.21815844, and the annotated authentic artefacts along with the resulting statistical damage model at https://github.com/daniela997/filmdamagesimulator. finally, we use these datasets to train and analyse the performance of eight state-of-the-art image restoration methods on high-resolution scans. we compare both methods which directly perform the restoration task on scans with artefacts, and methods which require a damage mask to be provided for the inpainting of artefacts. we modify the methods to process the inputs in a patch-wise fashion to operate on original high resolution film scans.",AB_0426
