AB,NO
"semantic segmentation is a key technique involved in automatic interpretation of high-resolution remote sensing (hrs) imagery and has drawn much attention in the remote sensing community. deep convolutional neural networks (dcnns) have been successfully applied to the hrs imagery semantic segmentation task due to their hierarchical representation ability. however, the heavy dependence on a large number of training data with dense annotation and the sensitiveness to the variation of data distribution severely restrict the potential application of dcnns for the semantic segmentation of hrs imagery. this study proposes a novel unsupervised domain adaptation semantic segmentation network (memoryadaptnet) for the semantic segmentation of hrs imagery. memoryadaptnet constructs an output space adversarial learning scheme to bridge the domain distribution discrepancy between the source domain and the target domain and to narrow the influence of domain shift. specifically, we embed an invariant feature memory module to store invariant domain-level prototype information because the features obtained from adversarial learning only tend to represent the variant feature of current limited inputs. this module is integrated by a category attention-driven invariant domain-level memory aggregation module to current pseudo-invariant feature for further augmenting the representations. an entropy-based pseudo label filtering strategy is used to update the memory module with high-confident pseudo-invariant feature of current target images. extensive experiments under three cross-domain tasks indicate that our proposed memoryadaptnet is remarkably superior to the state-of-the-art methods. our code is available at https://github.com/rs-csu/memoryadaptnet-master.",AB_0293
"deep hashing has shown promising performance in large-scale image retrieval. the hashing process utilizes deep neural networks (dnns) to embed images into compact continuous latent codes, then map them into binary codes by hashing function for efficient retrieval. recent approaches perform metric loss and quantization loss to supervise the two procedures that cluster samples with the same categories and alleviate semantic information loss after binarization in the end-to-end training framework. however, we observe the incompatible conflict that the optimal cluster positions are not identical to the ideal hash positions because of the different objectives of the two loss terms, which lead to severe ambiguity and error-hashing after the binarization process. to address the problem, we borrow the theory of minimum-distance bounds for binary linear codes to design the inflection point that depends on the hash bit length and category numbers and thereby propose hashing-guided hinge function (hhf) to explicitly enforce the termination of metric loss to prevent the negative pairs unlimited alienated. such modification is proven effective and essential for training, which contributes to proper intra- and inter-distances for clusters and better hash positions for accurate image retrieval simultaneously. extensive experiments in cifar-10, cifar-100, imagenet, and ms-coco justify that hhf consistently outperforms existing techniques and is robust and flexible to transplant into other methods. code is available at https://github.com/jerryxu0129/hhf.",AB_0293
"pansharpening tasks are the fusion of a low-resolution multispectral (lrms) image with a high-resolution panchromatic (pan) image to generate a high-resolution multispectral (hrms) image. recently, the pansharpening method based on deep learning (dl) has received widespread attention because of its powerful fitting ability and efficient feature extraction. since there is currently no method to make full use of different levels of feature information of pan images to deeply fuse with ms images, we propose a new end-to-end deeply coupled feedback network to achieve high-quality image fusion at the feature level and this network named pscf-net. first, features are extracted from pan images and ms images by different feature extraction blocks. then, these features are deeply fused through two subnetworks composed of coupled feedback blocks, which can achieve high-quality fusion of features of different levels and images through coupling and feedback mechanisms. finally, the feature maps of the two subnetworks are output as the final hrms image through a channel integration layer. to make full use of the spatial information of pan images and the spectral information of lrms images, the extracted features include the features of ms images and the low- and high-level features of pan images, and the low-level features of pan images are injected with spectral information before being input to the subnetwork. at training time, we use smoothl1 combined with structural similarity as the loss function in the network, and we experiment on the ikonos and worldview-2 datasets, respectively. the experimental results of reduced- and full-scale show that the deeply coupled feedback network we propose is superior to some of the current popular traditional methods and dl-based methods. source code is available at https://github.com/ahu-dsp/pscf-net.",AB_0293
"deep learning (dl) has been a powerful tool for hyperspectral image (hsi) classification. however, it is still an open issue to effectively learn highly discriminative features from hsi, due to the high-dimensionality and complex spectral-spatial characteristics. to settle this issue, we propose a new band-grouping guided multi-attention module for the performance promotion of spectral-spatial feature learning. first, based on the fact of high relevance between adjacent spectral bands and low dependencies across long-range ones, all the spectral bands are adaptively divided into multiple nonoverlapping groups where relevant bands are included. the advantage is to reduce the spectral dimension and data complexity when processing and analyzing each group. then, a multi-attention mechanism, which not only explores the intragroup salient information but also propagates the intergroup difference information, is embedded into the convolutional neural networks (cnns) to learn group-specific spectral-spatial features. by emphasizing useful spectral/spatial information and squeezing useless information with attention mechanism, the severability of learned features is enhanced. based on this module, a spectral-spatial classification network is built, named by grouped multi-attention network (gma-net). the gma-net contains a two-branch architecture, i.e., pixelwise spectral feature learning and patchwise spectral-spatial feature learning. via fusing the features from two branches, the complementary and discriminative features provided by pixelwise and patchwise learning manner can be integrated to further boost the classification performance. experimental results demonstrate that the proposed method is superior than several state-of-the-art approaches. codes are available at: https://github.com/luting-hnu.",AB_0293
"this letter presents a cross-learning network (i.e., clcformer) integrating fine-grained spatial details within long-range global contexts based upon convolutional neural networks (cnns) and transformer, for semantic segmentation of very high-resolution (vhr) remote-sensing images. more specifically, clcformer comprises two parallel encoders, derived from the cnn and transformer, and a cnn decoder. the encoders are backboned on swinv2 and efficientnet-b3, from which the extracted semantic features are aggregated at multiple levels using a bilateral feature fusion module (biffm). first, we used attention gate (atg) modules to enhance feature representation, improving segmentation results for objects with various shapes and sizes. second, we used an attention residual (atr) module to refine spatial features's learning, alleviating boundary blurring of occluded objects. finally, we developed a new strategy, called auxiliary supervise strategy (ass), for model optimization to further improve segmentation performance. our method was tested on the whu, inria, and potsdam datasets, and compared with cnn-based and transformer-based methods. results showed that our method achieved state-of-the-art performance on the whu building dataset (92.31% iou), inria building dataset (83.71% iou), and potsdam dataset (80.27% miou). we concluded that clcformer is a flexible, robust, and effective method for the semantic segmentation of vhr images. the codes of the proposed model are available at https://github.com/long123524/clcformer.",AB_0293
"to solve the problems of slow detection speed and poor robustness of existing infrared (ir) small target detection methods in complex environments, a lightweight detection model miniir-net is proposed in this letter. in the miniir-net model, to reduce the number of parameters required for model fitting, a multiscale target context feature extraction (tcve) module is proposed to enrich the feature expression of the target. in addition, to improve the feature mapping capability of miniir-net, a feature mapping upsampling network by fusing the deep and shallow features is designed. in the process of feature mapping upsampling, the network uses target features with different depths to make up for the loss of target features caused by pooling. it is proven by the experiment that the proposed miniir-net network is superior to the existing detection methods in detection speed, accuracy and robustness in a complex environment. the model size of miniir-net is at least 1/260 of the current detection model, and the detection accuracy is improved by at least 5%. the source code of this article can be obtained at https://github.com/yangzhen1252/miniir-net.",AB_0293
"the 5-methylcytosine (5mc) in the promoter region plays a significant role in biological processes and diseases. a few high-throughput sequencing technologies and traditional machine learning algorithms are often used by researchers to detect 5mc modification sites. however, high -throughput identification is laborious, time-consuming and expensive; moreover, the machine learning algorithms are not so advanced. therefore, there is an urgent need to develop a more efficient computational approach to replace those traditional methods. since deep learning algorithms are more popular and have powerful computational advantages, we constructed a novel prediction model, called dga-5mc, to identify 5mc modification sites in promoter regions by using a deep learning algorithm based on an improved densely connected convolutional network (densenet) and the bidirectional gru approach. furthermore, we added a self-attention module to evaluate the importance of various 5mc features. the deep learning-based dga-5mc model algorithm automatically handles large proportions of unbalanced data for both positive and negative samples, highlighting the model's reliability and superiority. so far as the authors are aware, this is the first time that the combination of an improved densenet and bidirectional gru methods has been used to predict the 5mc modification sites in promoter regions. it can be seen that the dga-5mc model, after using a combination of one-hot coding, nucleotide chemical property coding and nucleotide density coding, performed well in terms of sensitivity, specificity, accuracy, the matthews correlation coefficient (mcc), area under the curve and gmean in the independent test dataset: 90.19%, 92.74%, 92.54%, 64.64%, 96.43% and 91.46%, respectively. in addition, all datasets and source codes for the dga-5mc model are freely accessible at https://github.com/lulukoss/dga-5mc.",AB_0293
"in this article, we introduce a new approach to address the challenge of generalization in hyperspectral anomaly detection (ad). our method eliminates the need for adjusting parameters or retraining on new test scenes as required by most existing methods. employing an image-level training paradigm, we achieve a general anomaly enhancement network for hyperspectral ad that only needs to be trained once. trained on a set of anomaly-free hyperspectral images with random masks, our network can learn the spatial context characteristics between anomalies and backgrounds in an unsupervised way. in addition, a plug-and-play model selection module is proposed to search for a spatial-spectral transform domain that is more suitable for ad tasks than the original data. to establish a unified benchmark to comprehensively evaluate our method and existing methods, we develop a large-scale hyperspectral ad dataset (had100) that includes 100 real test scenes with diverse anomaly targets. in comparison experiments, we combine our network with a parameter-free detector and achieve the optimal balance between detection accuracy and inference speed among state-of-the-art ad methods. experimental results also show that our method still achieves competitive performance when the training and test sets are captured by different sensor devices. our code is available at https://github.com/zhaoxuli123/aetnet.",AB_0293
"salient object detection (sod) is a binary pixelwise classification to distinguish objects in an image and also has attracted many research interests in the optical remote sensing images (rsis). the existing state-of-the-art method exploits the full encoder-decoder architecture to predict salient objects in the optical rsis, suffering from the problem of unsmooth edges and incomplete structures. to address these problems, in this article, we propose a boundary-aware network (banet) with two-stage partial decoders sharing the same encoders for sod in rsis. specifically, a boundary-aware partial decoder (bad) is introduced at the first stage to focus on learning clear edges of salient objects. to solve the pixel-imbalance problem between boundary and background, an edge-aware loss is proposed to guide learning the bad network. the resulting features are then used in turn to enhance high-level features. afterward, the structure-aware partial decoder (sad) is further introduced at the second stage to improve the structure integrity of salient objects. to alleviate the problem of incomplete structures, the structural-similarity loss is further proposed to supervise learning the sad network. in a consequence, our proposed banet can predict salient objects with clear edges and complete structure, while reducing model parameters due to the discardment of low-level features. besides, training a deep neural network requires a large amount of images, and the current benchmark datasets for optical rsis are not large enough. therefore, we also create a large-scale challenging dataset for sod in rsis. extensive experiments demonstrate that our proposed banet outperforms previous rsi sod models on all the existing benchmark datasets and our new presented dataset available at https://github.com/qingpingzheng/rsisod.",AB_0293
"deep convolutional neural networks (cnns) have achieved much success in remote sensing image change detection (cd) but still suffer from two main problems. first, the existing multiscale feature fusion methods often use redundant feature extraction and fusion strategies, which often lead to high computational costs and memory usage. second, the regular attention mechanism in cd is difficult to model spatial-spectral features and generate 3-d attention weights at the same time, ignoring the cooperation between spatial features and spectral features. to address the above issues, an efficient ultralightweight spatial-spectral feature cooperation network (ussfc-net) is proposed for cd in this article. the proposed ussfc-net has two main advantages. first, a multiscale decoupled convolution (msdconv) is designed, which is clearly different from the popular atrous spatial pyramid pooling (aspp) module and its variants since it can flexibly capture the multiscale features of changed objects using cyclic multiscale convolution. meanwhile, the design of msdconv can greatly reduce the number of parameters and computational redundancy. second, an efficient spatial-spectral feature cooperation (ssfc) strategy is introduced to obtain richer features. the ssfc differs from the existing 2-d attention mechanisms since it learns 3-d spatial-spectral attention weights without adding any parameters. the experiments on three datasets for remote sensing image cd demonstrate that the proposed ussfc-net achieves better cd accuracy than most cnns-based methods and requires lower computational costs and fewer parameters, even it is superior to some transformer-based methods. the code is available at https://github.com/sust-reynole/ussfc-net.",AB_0293
