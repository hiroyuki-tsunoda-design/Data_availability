AB,NO
"background: reproducible approaches are needed to bring ai/ml for medical image analysis closer to the bedside. investigators wishing to shadow test cross-sectional medical imaging segmentation algorithms on new studies in real-time will benefit from simple tools that integrate pacs with on-premises image processing, allowing visualization of dicom-compatible segmentation results and volumetric data at the radiology workstation. purpose: in this work, we develop and release a simple containerized and easily deployable pipeline for shadow testing of segmentation algorithms within the clinical workflow. methods: our end-to-end automated pipeline has two major components- 1. a router/listener and anonymizer and an ohif web viewer backstopped by a dcm4chee dicom query/retrieve archive deployed in the virtual infrastructure of our secure hospital intranet, and 2. an on-premises single gpu workstation host for dicom/nifti conversion steps, and image processing. dicom images are visualized in ohif along with their segmentation masks and associated volumetry measurements (in ml) using dicom seg and structured report (sr) elements. since nnu-net has emerged as a widely-used out-of-the-box method for training segmentation models with state-of-the-art performance, feasibility of our pipleine is demonstrated by recording clock times for a traumatic pelvic hematoma nnu-net model. results: mean total clock time from pacs send by user to completion of transfer to the dcm4chee query/retrieve archive was 5 min 32 s (+/- sd of 1 min 26 s). this compares favorably to the report turnaround times for whole-body ct exams, which often exceed 30 min, and illustrates feasibility in the clinical setting where quantitative results would be expected prior to report sign-off. inference times accounted for most of the total clock time, ranging from 2 min 41 s to 8 min 27 s. all other virtual and on-premises host steps combined ranged from a minimum of 34 s to a maximum of 48 s. conclusion: the software worked seamlessly with an existing pacs and could be used for deployment of dl models within the radiology workflow for prospective testing on newly scanned patients. once configured, the pipeline is executed through one command using a single shell script. the code is made publicly available through an open-source license at https://github.com/vastc/, and includes a readme file providing pipeline config instructions for host names, series filter, other parameters, and citation instructions for this work.",AB_0599
"single-particle cryo-electron tomography is an emerging technique capable of determining the structure of proteins imaged within the native context of cells at molecular resolution. while high-throughput techniques for sample preparation and tilt-series acquisition are beginning to provide sufficient data to allow structural studies of proteins at physiological concentrations, the complex data analysis pipeline and the demanding storage and computational requirements pose major barriers for the development and broader adoption of this technology. here, we present a scalable, end-to-end framework for single-particle cryo-electron tomography data analysis from on-the-fly pre-processing of tilt series to high-resolution refinement and classification, which allows efficient analysis and visualization of datasets with hundreds of tilt series and hundreds of thousands of particles. we validate our approach using in vitro and cellular datasets, demonstrating its effectiveness at achieving high-resolution and revealing conformational heterogeneity in situ. the framework is made available through an intuitive and easy-to-use computer application, nextpyp (http://nextpyp.app). nextpyp is a turn-key framework for single-particle cryo-electron tomography that streamlines complex data analysis pipelines, from pre-processing of tilt series to high-resolution refinement, for efficient analysis and visualization of large datasets.",AB_0599
"pangenomes are replacing single reference genomes as the definitive representation of dna sequence within a species or clade. pangenome analysis predominantly leverages graph-based methods that require computationally intensive multiple genome alignments, do not scale to highly complex eukaryotic genomes, limit their scope to identifying structural variants (svs), or incur bias by relying on a reference genome. here, we present pankmer, a toolkit designed for reference-free analysis of pangenome datasets consisting of dozens to thousands of individual genomes. pankmer decomposes a set of input genomes into a table of observed k-mers and their presence-absence values in each genome. these are stored in an efficient k-mer index data format that encodes snps, indels, and svs. it also includes functions for downstream analysis of the k-mer index, such as calculating sequence similarity statistics between individuals at whole-genome or local scales. for example, k-mers can be anchored in any individual genome to quantify sequence variability or conservation at a specific locus. this facilitates workflows with various biological applications, e.g. identifying cases of hybridization between plant species. pankmer provides researchers with a valuable and convenient means to explore the full scope of genetic variation in a population, without reference bias. availability and implementation: pankmer is implemented as a python package with components written in rust, released under a bsd license. the source code is available from the python package index (pypi) at https://pypi.org/project/pankmer/ as well as gitlab at https://gitlab. com/salk-tm/pankmer. full documentation is available at https://salk-tm.gitlab.io/pankmer/.",AB_0599
"backgroundguided by self-determination theory (sdt), the purpose of this study was to determine changes in the 16-week moderate-to-vigorous physical activity (mvpa) trajectory of underserved adolescents who participated in the connect through play afterschool program intervention and the effects of changes in participating adolescents' intrinsic and autonomous extrinsic motivations on their mvpa trajectory over the 16-week intervention.methodsa subsample of 113 adolescents (56.64% female; 61.06% african american; average age = 11.29) provided complete data throughout the 16-week intervention were examined. adolescents' objective daily mvpa was measured using 7- day accelerometer data. changes in adolescents' intrinsic motivation and autonomous extrinsic motivation were assessed using subscales from the intrinsic motivation inventory [1] and the treatment self-regulation questionnaire [2] respectively. a hierarchical linear model was built and tested to address the research aims.resultsthe results of hierarchical linear models showed that, on average, youth daily mvpa increased 6.36 minutes in each 8-week period. intrinsic motivation change, but not autonomous extrinsic motivation, was a positive and significant level-2 predictor of daily mvpa changes.conclusionthe findings provide significant evidence suggesting a benefit of integrating sdt-based approaches and further suggest that nurturing intrinsic motivation can be an effective approach to supporting youth daily mvpa in under-resourced afterschool programs.trial registrationconnect through play: a staff-based physical activity intervention for middle school youth (connect). https://clinicaltrials.gov/ct2/show/nct03732144. registered november 6th, 2018.",AB_0599
"the pacbio high-fidelity (hifi) sequencing technology produces long reads of >99% in accuracy. it has enabled the development of a new generation of de novo sequence assemblers, which all have sequencing error correction (ec) as the first step. as hifi is a new data type, this critical step has not been evaluated before. here, we introduced hifieval, a new command-line tool for measuring over- and under-corrections produced by ec algorithms. we assessed the accuracy of the ec components of existing hifi assemblers on the chm13 and the hg002 datasets and further investigated the performance of ec methods in challenging regions such as homopolymer regions, centromeric regions, and segmental duplications. hifieval will help hifi assemblers to improve ec and assembly quality in the long run. availability and implementation: the source code is available at https://github.com/magspho/hifieval.",AB_0599
"microplastics (<5 mm) pollution is a growing problem affecting coastal communities, marine ecosystems, aquatic life, and human health. the widespread occurrence of marine microplastics, and the need to curb its threats, require expansive, and continuous monitoring. while microplastic research has increased in recent years and generated significant volumes of data, there is a lack of a robust, open access, and long-term aggregation of this data. the national oceanic and atmospheric administration (noaa) national centers for environmental information (ncei) now provides a global open access to marine microplastics data on an easily discoverable and accessible gis web map and data portal (https://www.ncei.noaa.gov/products/microplastics). the objective of this data portal is to develop a repository where microplastics data are aggregated, archived, and served in a user friendly, consistent, and reliable manner. this work contributes to ncei's efforts towards data standardization, integration, harmonization, and interoperability among national and international collaborators for monitoring global marine microplastics. this paper describes the noaa ncei global marine microplastics database, its creation, quality control procedures, and future directions.",AB_0599
"proteolysis-targeting chimera (protac) and other targeted protein degradation (tpd) molecules that induce degradation by the ubiquitin-proteasome system (ups) offer new opportunities to engage targets that remain challenging to be inhibited by conventional small molecules. one fundamental element in the degradation process is the e3 ligase. however, less than 2% amongst hundreds of e3 ligases in the human genome have been engaged in current studies in the tpd field, calling for the recruiting of additional ones to further enhance the therapeutic potential of tpd. to accelerate the development of protacs utilizing under-explored e3 ligases, we systematically characterize e3 ligases from seven different aspects, including chemical ligandability, expression patterns, protein-protein interactions (ppi), structure availability, functional essentiality, cellular location, and ppi interface by analyzing 30 large-scale data sets. our analysis uncovers several e3 ligases as promising extant protacs. in total, combining confidence score, ligandability, expression pattern, and ppi, we identified 76 e3 ligases as protac-interacting candidates. we develop a user-friendly and flexible web portal (https://hanlaboratory.com/e3atlas/) aimed at assisting researchers to rapidly identify e3 ligases with promising tpd activities against specifically desired targets, facilitating the development of these therapies in cancer and beyond. proteolysis-targeting chimeras (protacs) offer new avenues for drug development. here the authors investigate e3 ligases-key to protac function-and identify candidate targets for cancer drivers such as kras and egfr.",AB_0599
"the alevin-fry ecosystem provides a robust and growing suite of programs for single-cell data processing. however, as new single-cell technologies are introduced, as the community continues to adjust best practices for data processing, and as the alevin-fry ecosystem itself expands and grows, it is becoming increasingly important to manage the complexity of alevin-fry's single-cell preprocessing workflows while retaining the performance and flexibility that make these tools enticing. we introduce simpleaf, a program that simplifies the processing of single-cell data using tools from the alevin-fry ecosystem, and adds new functionality and capabilities, while retaining the flexibility and performance of the underlying tools. availability and implementation simpleaf is written in rust and released under a bsd 3-clause license. it is freely available from its github repository https://github.com/combine-lab/simpleaf, and via bioconda. documentation for simpleaf is available at https://simpleaf.readthedocs.io/en/latest/ and tutorials for simpleaf that have been developed can be accessed at https://combine-lab.github.io/alevin-fry-tutorials.",AB_0599
"motivation biomedical and healthcare domains generate vast amounts of complex data that can be challenging to analyze using machine learning tools, especially for researchers without computer science training.results aliro is an open-source software package designed to automate machine learning analysis through a clean web interface. by infusing the power of large language models, the user can interact with their data by seamlessly retrieving and executing code pulled from the large language model, accelerating automated discovery of new insights from data. aliro includes a pre-trained machine learning recommendation system that can assist the user to automate the selection of machine learning algorithms and its hyperparameters and provides visualization of the evaluated model and data.availability and implementation aliro is deployed by running its custom docker containers. aliro is available as open-source from github at: https://github.com/epistasislab/aliro.",AB_0599
"this paper presents a federated learning (fl) approach to train deep learning models for classifying age-related macular degeneration (amd) using optical coherence tomography image data. we employ the use of residual network and vision transformer encoders for the normal vs. amd binary classification, integrating four unique domain adaptation techniques to address domain shift issues caused by heterogeneous data distribution in different institutions. experimental results indicate that fl strategies can achieve competitive performance similar to centralized models even though each local model has access to a portion of the training data. notably, the adaptive personalization fl strategy stood out in our fl evaluations, consistently delivering high performance across all tests due to its additional local model. furthermore, the study provides valuable insights into the efficacy of simpler architectures in image classification tasks, particularly in scenarios where data privacy and decentralization are critical using both encoders. it suggests future exploration into deeper models and other fl strategies for a more nuanced understanding of these models' performance. data and code are available at https://github.com/qiaiuncc/fl_uncc_qiai.",AB_0599
