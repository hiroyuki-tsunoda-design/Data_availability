AB,NO
"in face antispoofing, it is desirable to have multimodal images to demonstrate liveness cues from various perspectives. however, in most face recognition scenarios, only a single modality, namely visible lighting (vis) facial images is available. this paper first investigates the possibility of generating polarized (polar) images from vis cameras without changing the existing recognition devices to improve the accuracy and robustness of presentation attack detection (pad) in face biometrics. a novel multimodal face antispoofing framework is proposed based on the machine-learning relationship between vis and polar images of genuine faces. specifically, a dual-modal central differential convolutional network (cdcn) is developed to capture the inherent spoofing features between the vis and the generated polar modalities. quantitative and qualitative experimental results show that our proposed framework not only generates realistic polar face images but also improves the state-of-the-art face anti-spoofing results on the vis modal database (i.e. casia-surf). moreover, a polar face database, casia-polar, has been constructed and will be shared with the public at https://biometrics.idealtest.org to inspire future applications within the biometric anti-spoofing field.",AB_0277
"deep learning has become a popular method for studying the semantic segmentation of high-resolution remote sensing images (hrrsis). existing methods have adopted convolutional neural networks (cnns) to achieve better segmentation accuracy of hrrsis, and the success of these models often depends on the model complexity and parameter quantity. however, the deployment of these models on equipment with limited resources is a significant challenge. to solve this problem, a lightweight student network framework-a graph attention guidance network (gagnet) with knowledge distillation (kd), called gagnet-s*-is proposed in this study, which distills knowledge from pretrained large teacher network (gagnet-t) and builds reliable weak labels to optimize untrained student network (gagnet-s). inspired by the graph convolution network, this study designs a graph convolution module called the attention-graph decoder (agd), which combines attention mechanisms with graph convolution to optimize image features and improve segmentation accuracy in the semantic segmentation task of hrrsis. in addition, a dense cross-decoder (dcd) was designed for multiscale dense fusion, which utilizes rich semantic information in the high-level features to guide and refine the low-level features from the bottom up. extensive experiments showed that gagnet-s* (gagnet-s with kd) achieved excellent segmentation performance on two widely used datasets: potsdam and vaihingen. the code and models are available at https://github.com/f8aomn/gagnet-kd.",AB_0277
"for hyperspectral image classification (hic) tasks, most uncertainty-based active learning (al) methods only consider the uncertainty, without considering the diversity of actively selected samples and the budget of expert labeling. in this article, we propose a collaborative al (cal) framework to address this problem. the proposed framework consists of two well-designed base classifiers and an ingenious cal scheme that takes into account both the uncertainty and diversity of actively selected samples and the cost of expert annotation. specifically, getting benefit from the ability of capsule networks (capsnets) to accurately identify and locate features, we design two improved capsnets. for these two networks, we call the first one capsule vision transformer (capsvit), which introduces vision transformer (vit) into the capsnet to learn the global relationship between the capsule features. we call the second one capsule glom (capsglom); the basic structure of this network is derived from the glom system proposed by geoffrey hinton; and we learn from the way capsnet constructs the primary capsules to improve its implementation details. capsvit and capsglom are used as the two base classifiers in the proposed cal framework to select the most informative samples according to the cal scheme under the premise of fully considering the cost of expert annotation. experimental results on four benchmark hyperspectral image datasets show that our proposed cal framework can achieve satisfactory classification results. at the same time, compared with other advanced deep models, our proposed capsvit and capsglom are also competitive in the supervised hic tasks. the source code is available online (https://github.com/swiftest/cal).",AB_0277
"fusing a low-resolution hyperspectral image (lrhsi) with an auxiliary high-resolution multispectral image (hrmsi) is a burgeoning technique to realize hyperspectral image super-resolution (hsi-sr), in which learning-based methods have dominated the mainstream direction. however, the underutilization of degradation models and strong dependence on large-scale training triplets severely impede their applicability and performance. considering these issues, we reformulate the fusion task as a spectral mapping problem and hence propose an unsupervised model-guided coarse-to-fine (c2f) fusion network. specifically, degradation knowledge learning (dkl) is first performed to fully excavate latent model information, which will serve as guidance for better mapping learning. following that, a c2f fusion network is constructed with a multiscale attentional fusion (msaf) module in the head and a c2f structure in the tail. the former is deployed to achieve a more informative compression, and the latter is adopted to capture the spectral relationship, including a spectral degradation-guided (sdg) subnetwork for group-by-group coarse reconstruction and a refinement subnetwork for intergroup correlation and dependencies. finally, high-resolution hsi can be recovered via established spectral mapping. extensive experiments on simulated and real datasets verify the superiority of our proposed method. the code is available at https://github.com/jiaxinlicas/umc2ff_grsl.",AB_0277
"deep learning-based hyperspectral image (hsi) classification and object detection techniques have gained significant attention due to their vital role in image content analysis, interpretation, and broader hsi applications. however, current hyperspectral object detection approaches predominantly emphasize spectral or spatial information, overlooking the valuable complementary relationship between these two aspects. in this study, we present a novel spectral-spatial aggregation (s2adet) object detector that effectively harnesses the rich spectral and spatial complementary information inherent in the hsi. s2adet comprises a hyperspectral information decoupling (hid) module, a two-stream feature extraction network, and a one-stage detection head. the hid module processes hyperspectral data by aggregating spectral and spatial information via band selection and principal components analysis, consequently reducing redundancy. based on the acquired spectral and spatial aggregation information, we propose a feature aggregation two-stream network for interacting spectral-spatial features. furthermore, to address the limitations of existing databases, we annotate an extensive dataset, designated as hod3k, containing 3242 hsis captured across diverse real-world scenes, and encompassing three object classes. these images possess a resolution of 512 x 256 pixels and cover 16 bands ranging from 470 to 620 nm. comprehensive experiments on two datasets demonstrate that s2adet surpasses existing state-of-the-art methods, achieving robust, and reliable results. the demo code and dataset of this work are publicly available at https://github.com/hexiao-cs/s2adet.",AB_0277
"robust feature matching for multimodal remote-sensing images remains challenging due to the significant nonlinear radiation difference (nrd) caused by modality variations. in this letter, we present a novel feature-matching method for multimodal remote-sensing images, called robust deep feature matching (rdfm), which exploits only deep features extracted by a pretrained visual geometry group (vgg) network to achieve competitive performance. it is shown that template matching of these pretrained features is robust to nrd for various multimodal remote-sensing images, and no additional training is required to improve the matching performance. to extract as many correspondences as possible, we use dense template matching to obtain point correspondences and introduce a 4-d convolution-based implementation of dense template matching for the sake of computational efficiency. rdfm consists of two main steps. first, enormous coarse correspondences are extracted by applying dense template matching at the deep layer of the pretrained network, and then a coarse-to-fine hierarchical refinement is performed to obtain high-quality correspondences. to verify the effectiveness of rdfm, six different types of multimodal image datasets are used in our experiments, including day-night, depth-optical, infrared-optical, map-optical, optical-optical, and sar-optical datasets. the comprehensive experimental results show that rdfm can overcome the problem caused by nrd and achieves a better performance than the state-of-the-art methods for multimodal remote-sensing image matching. the code of rdfm is publicly available at https://github.com/fans2017/rdfm.",AB_0277
"spatiotemporal satellite image fusion (stif) has been widely applied in land surface monitoring to generate high spatial and high temporal reflectance images from satellite sensors. this article proposed a new unmixing-based spatiotemporal fusion method that is composed of a self-trained random forest machine learning regression (r), low resolution endmember estimation (e), high resolution surface reflectance image reconstruction (r), and residual compensation (c), that is, rerc. rerc uses a self-trained random forest to train and predict the relationship between spectra and the corresponding class fractions. this process is flexible without any ancillary training dataset, and does not possess the limitations of linear spectral unmixing, which requires the number of endmembers to be no more than the number of spectral bands. the running time of the random forest regression is about similar to 1% of the running time of the linear mixture model. in addition, rerc adopts a spectral reflectance residual compensation approach to refine the fused image to make full use of the information from the low resolution image. rerc was assessed in the fusion of a prediction time moderate resolution imaging spectroradiometer (modis) with a landsat image using two benchmark datasets, and was assessed in fusing images with different numbers of spectral bands by fusing a known time landsat image (seven bands used) with a known time very-high-resolution planetscope image (four spectral bands). rerc was assessed in the fusion of modis-landsat imagery in large areas at the national scale for the republic of ireland and france. the code is available at https://www.researchgate.net/profile/xiao_li52.",AB_0277
"in multimodal data fusion and land-cover interpretation tasks, the fusion interpretability between hyperspectral image (hsi) and light detection and ranging (lidar) data is always nontrivial to be clarified. furthermore, the heterogeneous sample and distribution variances of these two remote sensing (rs) modalities impede the joint classification performance. in this article, a hyperspectral intrinsic image decomposition guided data fusion network (hi(2)d(2)fnet) is proposed. generally, classic hyperspectral intrinsic image decomposition (hiid) performs well in image enhancement and shadow removal. it decomposes one hsi into one reflectance component and one shading component. inspired by the core mechanism of hiid, our motivation is to preliminarily exploit its potential for multimodal rs data fusion and explore the inherent modality connection between hsi and lidar data from the intrinsic perspective. specifically, compared with existing techniques, hi(2)d(2)fnet is capable of fusing the horizontal geometry information in the shading component with the vertical geometry information in the lidar data from both sample and distribution perspectives in the spatial domain. the generated cross-modal geometry feature contributes to guiding the reflectance stream optimization. this unique fusion framework connects both the modalities with respect to geometry information and enhances the specific fusion interpretability. the decomposition and fusion modules in hi(2)d(2)fnet are optimized simultaneously in a novel alternative optimization pattern. furthermore, several unique cross-modal constraints in terms of prior rs properties are presented. experiments conducted on three widely available datasets prove the superiority of hi(2)d(2)fnet over state-of-the-art techniques. the source codes will be available at https://github.com/geoywb/hi2d2fnet.",AB_0277
"hyperspectral image (hsi) denoising is a challenging task, not only because it is unavoidably contaminated by severe mixed noises, but also because of its hard-to-recover spatial-spectral structure. since it has been found that hsi has low-rank property, low-rank models have received extensive attention in dealing with the hsi denoising task. however, these models either use nuclear norm, which can only obtain suboptimal solutions, or require some predefined information that is difficult to determine. to address these issues, in this letter, we propose a new hsi denoising model based on nonconvex fraction function, which has excellent performance in removing mixed noises. specifically, the proposed model can capture the rank information of hsi automatically, which allows it to separate clean hsi from noises more accurately. then, an iterative optimization algorithm is developed by exploiting the framework of the augmented lagrange multiplier (alm). meanwhile, the subproblems at each iteration can be solved by the proximal operator with a closed-form solution. besides, the convergence of the proposed algorithm is also provided theoretically. extensive experiments implemented with simulated and real datasets demonstrate that our proposed model performs better than state-of-the-art models in hsi denoising. matlab code is available at https://github.com/wangzhi-swu/hsi-denosing.",AB_0277
"aerial object tracking has recently shown great potential in the field of remote sensing. however, small objects with limited feature information pose a huge challenge to aerial trackers. despite significant improvements, most trackers still struggle to capture enough discriminative features and overcome background disturbances. in this work, we propose an efficient aerial tracker (smalltrack) based on the siamese network to improve the discrimination of small objects. it consists of two effective modules, namely the wavelet pooling layer (wpl) and graph enhanced module (gem). first, wpl decomposes the input into four subbands via wavelet domain learning and fully utilizes the high- and low-frequency information in the subbands to preserve the discriminative features of small objects. second, gem embeds the pixels on the classification responses as nodes in graph learning through graph neural networks (gnns), which naturally mines the similarity between pixels. based on the pixel-level modulation constructed from graph theory, gem enhances the understanding of small objects and highlights them in the classification responses. the proposed tracker achieves leading performance on five aerial benchmarks, while maintaining a high running speed of 72.5 frames/s. besides, real-world tests on an aerial platform have proven the effectiveness of smalltrack. the code and models are available at https://github.com/xyl-507/smalltrack.",AB_0277
