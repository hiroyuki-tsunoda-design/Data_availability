AB,NO
"the staple of human intelligence is the capability of acquiring knowledge in a continuous fashion. in stark contrast, deep networks forget catastrophically and, for this reason, the sub-field of class-incremental continual learning fosters methods that learn a sequence of tasks incrementally, blending sequentially-gained knowledge into a comprehensive prediction. this work aims at assessing and overcoming the pitfalls of our previous proposal dark experience replay (der), a simple and effective approach that combines rehearsal and knowledge distillation. inspired by the way our minds constantly rewrite past recollections and set expectations for the future, we endow our model with the abilities to i) revise its replay memory to welcome novel information regarding past data ii) pave the way for learning yet unseen classes. we show that the application of these strategies leads to remarkable improvements; indeed, the resulting method - termed extended-der (x-der) - outperforms the state of the art on both standard benchmarks (such as cifar-100 and miniimagenet) and a novel one here introduced. to gain a better understanding, we further provide extensive ablation studies that corroborate and extend the findings of our previous research (e.g., the value of knowledge distillation and flatter minima in continual learning setups). we make our results fully reproducible; the codebase is available at https://github.com/aimagelab/mammoth.",AB_0551
"this paper introduces vhr-pro_it (very high-resolution projections for italy), an open access hourly climate projection with a resolution of ?2.2 km (i.e., convection permitting scale) up to 2050, covering the italian peninsula and some neighbouring areas. vhr-pro_it is produced within the highlander project (https://highlanderproject.eu/) by dynamically downscaling the italy8km-cm climate projection (spatial resolution ?8 km; output frequency = 6 h; driven cmip5 gcm = cmcc-cm) with the regional climate model cosmo-clm under the ipcc rcp4.5 and rcp8.5 scenarios. it covers the 60-year period 1989-2050. vhr-pro_it is intended for research purposes in the field of climate studies. for example, it may be included in the ongoing activities to clarify the added value of running climate simulation at the convection-permitting scale.",AB_0551
"background: high-dimensional prediction considers data with more variables than samples. generic research goals are to find the best predictor or to select variables. results may be improved by exploiting prior information in the form of co-data, providing complementary data not on the samples, but on the variables. we consider adaptive ridge penalised generalised linear and cox models, in which the variablespecific ridge penalties are adapted to the co- data to give a priori more weight to more important variables. the r-package ecpc originally accommodated various and possibly multiple co-data sources, including categorical co-data, i.e. groups of variables, and continuous co-data. continuous co- data, however, were handled by adaptive discretisation, potentially inefficiently modelling and losing information. as continuous co-data such as external p values or correlations often arise in practice, more generic co-data models are needed. results: here, we present an extension to the method and software for generic co-data models, particularly for continuous co- data. at the basis lies a classical linear regression model, regressing prior variance weights on the co-data. co-data variables are then estimated with empirical bayes moment estimation. after placing the estimation procedure in the classical regression framework, extension to generalised additive and shape constrained co-data models is straightforward. besides, we show how ridge penalties may be transformed to elastic net penalties. in simulation studies we first compare various co- data models for continuous co-data from the extension to the original method. secondly, we compare variable selection performance to other variable selection methods. the extension is faster than the original method and shows improved prediction and variable selection performance for non-linear co-data relations. moreover, we demonstrate use of the package in several genomics examples throughout the paper. conclusions: the r-package ecpc accommodates linear, generalised additive and shape constrained additive co-data models for the purpose of improved highdimensional prediction and variable selection. the extended version of the package as presented here (version number 3.1.1 and higher) is available on (https://cran.r-project. org/web/packages/ecpc/).",AB_0551
"deep learning is a popular approach for approximating the solutions to partial differential equations (pdes) over different material parameters and boundary conditions. however, no work has yet been reported on learning pde solutions over changing shapes of the underlying domain. we present a framework to train neural networks (nn) and physics-informed neural networks (pinns) to learn the solutions to pdes defined over varying freeform domains. this is made possible through our adoption of a parametric non-uniform rational b-spline (nurbs) representation of the underlying physical shape. distinct physical domains are mapped to a common parametric space via nurbs parameterization. in our approach, we formulate nns and pinns that learn the solutions to pdes as a function of the shape of the domain itself through shape parameters. under this formulation, the loss function is based on an unchanging parametric domain that maps to a variable physical domain. residual computation in pinns is made possible through the jacobian of the mapping. numerical results show that our networks can be trained to predict the solutions to a pde defined over an entire set of shapes. we focus on the linear elasticity pde and show how we can build a surrogate model that is able to predict displacements and stresses over a variety of freeform domains. to assess the efficacy of all networks in this work, data efficiency, network accuracy, and the capacity of networks to extrapolate are considered and compared between nns and pinns. the comparison includes cases where little training data is available. transfer learning and applications to shape optimization are analyzed as well. a selection of the used codes and datasets is provided at https://github.com/fmezzadri/shape_parameterized.git. (c) 2023 elsevier ltd. all rights reserved.",AB_0551
"in this paper, we address the problem of multi-modal retrieval of fashion products. state-of-the-art (sota) works proposed in literature use vision-and-language transformers to assign similarity scores to joint text-image pairs, then used for sorting the results during a retrieval phase. however, this approach is inefficient since it requires coupling a query with every record in the dataset and computing a forward pass for each sample at runtime, precluding scalability to large-scale datasets. we thus propose a solution that overcomes the above limitation by combining transformers and deep metric learning to create a latent space where texts and images are separately embedded, and their spatial proximity trans-lates into semantic similarity. our architecture does not use convolutional neural networks to process images, allowing us to test different levels of image-processing details and metric learning losses. we vastly improve retrieval accuracy results on the fashiongen benchmark (+18.71% and +9.22% rank@1 on image-to-text and text-to-image, respectively) while being up to 512x faster. finally, we analyze the speed-up obtainable by different approximate nearest neighbor retrieval strategies-an optimization precluded to current sota contributions. we release our solution as a web application available at https://disi-unibo-nlp.github.io/projects/fashion_retrieval/.(c) 2023 elsevier b.v. all rights reserved.",AB_0551
"determination of the crystal system and space group is the first step of crystal structure analysis. often this turns out to be a bottleneck in the material characterization workflow for polycrystalline compounds, thus requiring manual interventions. this work proposes a new machine-learning (ml)-based web platform, crystalmela (crystallography machine learning), for crystal systems classification. two different ml models, random forest and convolutional neural network, are available through the platform, as well as the extremely randomized trees algorithm, available from the literature. the ml models learned from simulated powder x-ray diffraction patterns of more than 280 000 published crystal structures from organic, inorganic and metal-organic compounds and minerals which were collected from the pow_cod database. a crystal system classification accuracy of 70%, which improved to more than 90% when considering the top-2 classification accuracy, was obtained in tenfold cross-validation. the validity of the trained models has also been tested against independent experimental data of published compounds. the classification options in the crystalmela platform are powerful, easy to use and supported by a user-friendly graphic interface. they can be extended over time with contributions from the community. the tool is freely available at https:// www.ba.ic.cnr.it/softwareic/crystalmela/ following registration.",AB_0551
"background and objective: the functions of an organism and its biological processes result from the ex-pression of genes and proteins. therefore quantifying and predicting mrna and protein levels is a crucial aspect of scientific research. concerning the prediction of mrna levels, the available approaches use the sequence upstream and downstream of the transcription start site (tss) as input to neural networks. the state-of-the-art models (e.g., xpresso and basenjii) predict mrna levels exploiting convolutional (cnn) or long short term memory (lstm) networks. however, cnn prediction depends on convolutional kernel size, and lstm suffers from capturing long-range dependencies in the sequence. concerning the predic-tion of protein levels, as far as we know, there is no model for predicting protein levels by exploit-ing the gene or protein sequences. methods: here, we exploit a new model type (called perceiver) for mrna and protein level prediction, exploiting a transformer-based architecture with an attention mod-ule to attend to long-range interactions in the sequences. in addition, the perceiver model overcomes the quadratic complexity of the standard transformer architectures. this work's contributions are 1. dnaper-ceiver model to predict mrna levels from the sequence upstream and downstream of the tss; 2. pro-teinperceiver model to predict protein levels from the protein sequence; 3. protein & dnaperceiver model to predict protein levels from tss and protein sequences. results: the models are evaluated on cell lines, mice, glioblastoma, and lung cancer tissues. the results show the effectiveness of the perceiver-type mod-els in predicting mrna and protein levels. conclusions: this paper presents a perceiver architecture for mrna and protein level prediction. in the future, inserting regulatory and epigenetic information into the model could improve mrna and protein level predictions. the source code is freely available at https://github.com/matteostefanini/dnaperceiver & copy; 2023 the authors. published by elsevier b.v. this is an open access article under the cc by-nc-nd license (  )",AB_0551
"deep learning methods have achieved promising results in crop mapping using satellite image time series. a challenge still remains on how to better learn discriminative feature representations to detect crop types when the model is applied to unseen data. to address this challenge and reveal the importance of proper supervision of deep neural networks in improving performance, we propose to supervise intermediate layers of a designed 3d fully convolutional neural network (fcn) by employing two middle supervision methods: cross-entropy loss middle supervision (ce-mids) and a novel middle supervision method, namely supervised contrastive loss middle supervision (supcon-mids). this method pulls together features belonging to the same class in embedding space, while pushing apart features from different classes. we demonstrate that supcon-mids enhances feature discrimination and clustering throughout the network, thereby improving the network performance. in addition, we employ two output supervision methods, namely f1 loss and intersection over union (iou) loss. our experiments on identifying corn, soybean, and the class other from landsat image time series in the u.s. corn belt show that the best set-up of our method, namely iou+supcon-mids, is able to outperform the state-of-the-art methods by miou scores of 3.5% and 0.5% on average when testing its accuracy across a different year (local test) and different regions (spatial test), respectively. further, adding supcon-mids to the output supervision methods improves miou scores by 1.2% and 7.6% on average in local and spatial tests, respectively. we conclude that proper supervision of deep neural networks plays a significant role in improving crop mapping performance. the code and data are available at: https://github.com/sina-mohammadi/cropsupervision.",AB_0551
"automated speaker recognition is enabling personalized interactions with the voice-based interfaces and assistants part of the modern cyber-physical-social systems. prior studies have unfortunately uncovered disparate impacts across demographic groups on the outcomes of speaker recognition systems and consequently proposed a range of countermeasures. understanding why a speaker recognition system may lead to this disparate performance for different (groups of) individuals, going beyond mere data imbalance reasons and black-box countermeasures, is an essential yet under-explored perspective. in this paper, we propose an explanatory framework that aims to provide a better understanding of how speaker recognition models perform as the underlying voice characteristics on which they are tested change. with our framework, we evaluate two state-of-the-art speaker recognition models, comparing their fairness in terms of security, through a systematic analysis of the impact of more than twenty voice characteristics. our findings include important takeaways to enable voice controlled cyber-physical-social systems for everyone. source code and data are available at https://bit.ly/ea-prletters . (c) 2023 elsevier b.v. all rights reserved.",AB_0551
"motivation: with the rapidly growing volume of knowledge and data in biomedical databases, improved methods for knowledge-graph-based computational reasoning are needed in order to answer translational questions. previous efforts to solve such challenging computational reasoning problems have contributed tools and approaches, but progress has been hindered by the lack of an expressive analysis workflow language for translational reasoning and by the lack of a reasoning engine-supporting that language-that federates semantically integrated knowledge-bases.results: we introduce arax, a new reasoning system for translational biomedicine that provides a web browser user interface and an application programming interface (api). arax enables users to encode translational biomedical questions and to integrate knowledge across sources to answer the user's query and facilitate exploration of results. for arax, we developed new approaches to query planning, knowledge-gathering, reasoning and result ranking and dynamically integrate knowledge providers for answering biomedical questions. to illustrate arax's application and utility in specific disease contexts, we present several use-case examples.availability and implementation: the source code and technical documentation for building the arax server-side software and its built-in knowledge database are freely available online (https://github.com/rtxteam/rtx). we provide a hosted arax service with a web browser interface at arax.rtx.ai and a web api endpoint at arax.rtx.ai/api/ arax/v1.3/ui/.",AB_0551
