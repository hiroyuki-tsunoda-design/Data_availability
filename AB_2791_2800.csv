AB,NO
"despite the great progress in 3d human pose estimation from videos, it is still an open problem to take full advantage of a redundant 2d pose sequence to learn representative representations for generating one 3d pose. to this end, we propose an improved transformer-based architecture, called strided transformer, which simply and effectively lifts a long sequence of 2d joint locations to a single 3d pose. specifically, a vanilla transformer encoder (vte) is adopted to model long-range dependencies of 2d pose sequences. to reduce the redundancy of the sequence, fully-connected layers in the feed-forward network of vte are replaced with strided convolutions to progressively shrink the sequence length and aggregate information from local contexts. the modified vte is termed as strided transformer encoder (ste), which is built upon the outputs of vte. ste not only effectively aggregates long-range information to a single-vector representation in a hierarchical global and local fashion, but also significantly reduces the computation cost. furthermore, a full-to-single supervision scheme is designed at both full sequence and single target frame scales applied to the outputs of vte and ste, respectively. this scheme imposes extra temporal smoothness constraints in conjunction with the single target frame supervision and hence helps produce smoother and more accurate 3d poses. the proposed strided transformer is evaluated on two challenging benchmark datasets, human3.6 m and humaneva-i, and achieves state-of-the-art results with fewer parameters. code and models are available at https://github.com/vegetebird/stridedtransformer-pose3d.",AB_0280
"the mars exploration mission of china named tianwen-1 is being carried out as scheduled. the navigation and terrain cameras (natecam) equipped on the zhurong rover play an essential role in obstacle recognition. the main obstacles on the martian surface are rocks of different sizes, which influence the path planning of zhurong rover in scientific exploration. most existing semantic segmentation methods are based on the u-net architecture with resnet or other backbones, and features extracted by these methods lack long-range dependencies. to fully exploit the context information, we propose the marsnet framework for the mars image, which combines transformers with the convolutional neural network (cnn) as the backbone, and hybrid dilated convolution (hdc) is also employed to the decoder path to help detect the huge rocks. besides, since there are few open-source datasets for rock segmentation for mars, we establish a segmentation dataset from the martian surface image, named twmars, captured by natecam. extensive experiments are conducted on the twmars dataset, and the experimental results demonstrate that marsnet achieves accurate rock segmentation and outperforms state-of-the-art methods. the source code is available at https://github.com/bupt-ant-1007/marsnet.",AB_0280
"thermal infrared (tir) technology is crucial for wildlife detection in unmanned aerial vehicles (uavs), allowing executives to explore and detect at night. however, the images captured by tir cameras are unavoidably affected by various unexpected challenges such as image jitter, wildlife overlap, and fog, which may drastically decrease wildlife detection ability. to overcome these challenges, we propose a high-accuracy infrared object detection method called channel enhancement retinanet (ce-retinanet). first, a new channel enhancement (ce) module is proposed to strengthen the feature extraction of infrared images. then, a new batch-norm stochastic channel attention (bsca) module is proposed to filter occlusion-caused anomalous activations and focus on the pixel in the same position across channels. next, a path augmentation (pa) operation is added after the feature pyramid network (fpn) to improve the localization capability at the entire feature level. finally, we modified the output strategy of the classification and regression subnets. additionally, we built a tir wildlife detection dataset called the infrared salient object detection (isod) comprising 2534 images, which is accessible at https://doi.org/10.5281/zenodo.7445307. we conduct extensive experiments on both public and isod datasets, and the experimental results reveal that ce-retinanet obtains higher average precision (ap) (e.g., 11.3% more) and recall (e.g., 11.6% more) compared to other state-of-the-art object detectors.",AB_0280
"recently, there has been an increasing interest in image editing methods that employ pre-trained unconditional image generators (e.g., stylegan). however, applying these methods to translate images to multiple visual domains remains challenging. existing works do not often preserve the domain-invariant part of the image (e.g., the identity in human face translations), or they do not usually handle multiple domains or allow for multi-modal translations. this work proposes an implicit style function (isf) to straightforwardly achieve multi-modal and multi-domain image-to-image translation from pre-trained unconditional generators. the isf manipulates the semantics of a latent code to ensure that the image generated from the manipulated code lies in the desired visual domain. our human faces and animal image manipulations show significantly improved results over the baselines. our model enables cost-effective multi-modal unsupervised image-to-image translations at high resolution using pre-trained unconditional gans. the code and data are available at: https://github.com/yhlleo/stylegan-mmuit.",AB_0280
"autoencoders (aes) are widely utilized in hyperspectral unmixing (hu) as an unsupervised learning model. in particular, convolutional ae networks are popular for processing multidimensional hyperspectral features. nonetheless, the traditional convolutional ae network's receptive field is constrained in the unmixing task, and establishing the connection between the local spatial neighborhood and the local spectrum fails to improve unmixing performance significantly. to address these limitations, a bilateral global attention network based on both spatial and spectral information is proposed. it enables the network to obtain respective feature dependencies in the two dimensions and achieve optimal fusion of both features. the network comprises two information extraction branches. the spatial information extraction branch uses the swin transformer block to acquire the global spatial attention of the overall image, while the spectral information extraction branch designates a simplified spectral channel attention mechanism to gain spectral attention weight maps. the network's efficacy is demonstrated through a comparative study using a synthetic dataset and two real datasets. the code of this work is available at https://github.com/upcgit/ssabn.",AB_0280
"stereo cameras are now commonly used in more and more devices. nevertheless, visually unpleasant images captured under low-light conditions hinder their practical application. as an initial attempt at low-light stereo image enhancement, we propose a novel dual-view enhancement network (dvenet) based on the retinex theory, which consists of two stages. the first stage estimates an illumination map to obtain a coarse enhancement result, which boosts the correlation of two views, while the second stage recovers details by integrating the information from two views to achieve fine image quality improvement with the guidance of the illumination map. to fully utilize the dual-view correlation, we further design a wavelet-based view transfer module to efficiently carry out multi-scale detail recovery. then, we design an illumination-aware attention fusion module to exploit the complementarity between the fused features from two views and the single-view features. experiments on both synthetic and real-world stereo datasets demonstrate the superiority of our proposed method over existing solutions. the code and model are publicly available at: https://github.com/kevinj-huang/stereo-low-light.",AB_0280
"optimized deep learning (dl)-based workflows can improve the efficiency and accuracy of earthquake detection and location processes. this article introduces a six-step automated event detection, phase association, and earthquake location workflow, which integrates the state-of-the-art pair-input dl (pidl) model and waveform migration location methods [integrated pidl and mil (ipiml)]. applying ipiml on an 18-month dataset of ghana digital seismic network (ghsdn) recorded from 2012 to 2014, a catalog with 461 events is automatically obtained. compared to other dl catalogs obtained using eqtransformer (eqt) and siamese eqt (s-eqt), the seismic event clusters in the ipiml catalog focus more on tectonically active regions or known seismogenic source areas and show a consistent depth distribution. the compiled catalog is 6.3x larger than the reported catalog obtained by applying eqt with the default settings, indicating the importance of optimization and hyperparameter tuning when applying dl models. as a result, a previously unknown seismogenic fault with a clear spatial trend has been identified using the new ipiml catalog, which provides more insights into the fault activities and seismic hazards in the region. the ipiml codes and datasets are available at the github repository https://github.com/sigproseismology/ipiml.git, contributing to the geoscience community.",AB_0280
"predicting the trajectory of ocean eddies can promote the understanding of the transport of matter and energy in the ocean. however, accurately and rapidly predicting the trajectory of eddies poses a significant challenge due to their intricate nonlinear motion within a physical environment. regrettably, existing data-driven methods primarily focus on the migration and combination of models, as well as the fusion processing of diverse observational data on oceanic eddies. these ways often overlook the crucial aspect of modeling the underlying motion mechanism of the eddies. we believe that the expeditious and precise prediction of eddies is closely intertwined with the physical mechanism and historical time series. consequently, a medium-range eddy trajectory prediction neural network (etpnet) compliant with the physical constraint is proposed, which embeds the physical regulation, intrinsic relations, and mutual interactions into the network via constraints. then, a novel variant of the long short-term memory (lstm) cell is designed to enhance the dynamic interaction and representation ability of the features, constraints, and knowledge. finally, a geographically informed comprehensive loss function for marine tasks is formulated, namely mean absolute geodetic error (mage), which optimizes the network in euclidean and sphere space. the proposed network is evaluated by predicting the future seven days trajectory of anticyclone eddies in the 15. n to 40. n. the extensive experiments and evaluations demonstrate that the proposed network guided by the comprehensive loss function can implement a state-of-the-art performance. the code is available at https://github.com/ai4ocean/etpnet",AB_0280
"hyperspectral images (hsis) can provide rich spectral-spatial information that has been widely utilized in many fields, such as national defense, mineralogy, and agriculture. most of the recent hsi interpretation methods are conducted in the raster pattern, which results in high memory costs, amplification distortion, and difficulties in topological editing. to address this issue, a novel end-to-end vectorization framework is proposed, called as the hsi vectorization network (hsi-vecnet), which learns a vector representation from spectral-spatial information through cross-level interactions. specifically, this framework integrates low-level geometry information and high-level semantic instance information, which consists of two branches: the hsi semantic instance segmentation (hsis) and the spectral-spatial junction prediction (ssjp). the hsis conducts the raster-based classification and extracts the semantic information of each object in the hsi. in addition, the ssjp exploits spectral-spatial information to predict the positions of junctions in the hsi. the instance information of each object and the relations of junctions are then fused to vectorize the hsi. to verify the effectiveness of the proposed method, four hyperspectral datasets are vectorially labeled. experimental results on these datasets demonstrate that the proposed end-to-end hsi-vecnet outperforms existing post-process vectorization methods. our model and datasets will be made publicly available at https://github.com/yyyyll0ss/hsi-vecnet.",AB_0280
"recently, few-shot learning (fsl) has been introduced for hyperspectral image (hsi) classification with few labeled samples. however, existing fsl-based hsi classification methods mainly focus on the meta-knowledge transfer between hsis. compared with hsis, natural images have sufficient annotated data. to utilize natural images (base class data) to achieve accurate classification of hsis (novel class data), we propose a novel few-shot classification framework with ssl (fscf-ssl) for hsis in this article. the orientation of objects in natural images is relatively unitary, whereas the objects of image patches for each pixel in hsis have diverse orientations in the spatial domain. to make better use of base classes, we design an ssl with geometric transformations (sslgts), which sets rotation labels as supervision to extract low-level features that can better represent diverse orientations, and then conduct sslgt and fsl on base classes to learn transferable spatial meta-knowledge. next, a spectral-spatial feature extraction network is carefully designed to better utilize the spatial and spectral information of hsis, where the weights of the first seven layers of the spatial part are initialized by the weights of the corresponding layers trained on base classes. finally, to fully explore the few annotated data from novel classes, we design an ssl with contrastive learning (sslcl) that can mine the category-invariant features contained in the novel class data itself, and then perform sslcl and fsl on novel classes to learn more discriminative individual knowledge. experimental results on four hsi datasets show that fscf-ssl offers a significant improvement over state-of-the-art methods. the code is available at https://github.com/li-zk/fscf-ssl-2023.",AB_0280
