AB,NO
"o-linked beta-n-acetylglucosamine (o-glcnac) is a post-translational modification (i.e., o-glcnacylation) on serine/threonine residues of proteins, regulating a plethora of physiological and pathological events. as a dynamic process, o-glcnac functions in a site-specific manner. however, the experimental identification of the o-glcnac sites remains challenging in many scenarios. herein, by leveraging the recent progress in cataloguing experimentally identified o-glcnac sites and advanced deep learning approaches, we establish an ensemble model, o-glcnacpred-dl, a deep learning-based tool, for the prediction of o-glcnac sites. in brief, to make a benchmark o-glcnac data set, we extracted the information on o-glcnac from the recently constructed database o-glcnacatlas, which contains thousands of experimentally identified and curated o-glcnac sites on proteins from multiple species. to overcome the imbalance between positive and negative data sets, we selected five groups of negative data sets in humans and mice to construct an ensemble predictor based on connection of a convolutional neural network and bidirectional long short-term memory. by taking into account three types of sequence information, we constructed four network frameworks, with the systematically optimized parameters used for the models. the thorough comparison analysis on two independent data sets of humans and mice and six independent data sets from other species demonstrated remarkably increased sensitivity and accuracy of the o-glcnacpred-dl models, outperforming other existing tools. moreover, a user-friendly web server for o-glcnacpred-dl has been constructed, which is freely available at http://oglcnac.org/pred_dl.",AB_0212
"backgroundprotein-protein interactions (ppis) are crucial in various biological functions and cellular processes. thus, many computational approaches have been proposed to predict ppi sites. although significant progress has been made, these methods still have limitations in encoding the characteristics of each amino acid in sequences. many feature extraction methods rely on the sliding window technique, which simply merges all the features of residues into a vector. the importance of some key residues may be weakened in the feature vector, leading to poor performance.resultswe propose a novel sequence-based method for ppi sites prediction. the new network model, ppinet, contains multiple feature processing paths. for a residue, the ppinet extracts the features of the targeted residue and its context separately. these two types of features are processed by two paths in the network and combined to form a protein representation, where the two types of features are of relatively equal importance. the model ensembling technique is applied to make use of more features. the base models are trained with different features and then ensembled via stacking. in addition, a data balancing strategy is presented, by which our model can get significant improvement on highly unbalanced data.conclusionthe proposed method is evaluated on a fused dataset constructed from dset186, dset_72, and pdbset_164, as well as the public dset_448 dataset. compared with current state-of-the-art methods, the performance of our method is better than the others. in the most important metrics, such as auprc and recall, it surpasses the second-best programmer on the latter dataset by 6.9% and 4.7%, respectively. we also demonstrated that the improvement is essentially due to using the ensemble model, especially, the hybrid feature. we share our code for reproducibility and future research at https://github.com/candicecong/stackingppinet.",AB_0212
"monitoring extent and severity is vital in the ulcerative colitis (uc) follow-up, however, current assessment is complex and low cost-effectiveness. we aimed to develop a routine blood-based clinical decision support tool, jin's model, to investigate the extent and severity of uc. the multicentre retrospective cohort study recruited 975 adult uc inpatients and sub-grouped into training, internal validation and external validation set. model was developed by logistics regression for the extent via montreal classification and for the severity via mayo score, truelove and witts score (tws), mayo endoscopic score (mes) and degree of ulcerative colitis burden of luminal inflammation (dublin) score. in montreal classification, left-sided and extensive versus proctitis model achieved area under the receiver operating characteristic curve (auroc) of 0.78 and 0.81 retrospectively. for severity, mayo score model, tws model, mes model and dublin score model achieved an auroc of 0.81, 0.70, 0.74 and 0.70 retrospectively. the models also were evaluated with satisfactory calibration and clinical unity. jin's model was free with open access at http://jinmodel.com:3000/. jin's model is a noninvasive, convenient, and efficient approach to assess the extent and severity of uc.",AB_0212
"although deep learning has demonstrated its capability in solving diverse scientific visualization problems, it still lacks generalization power across different tasks. to address this challenge, we propose coordnet, a single coordinate-based framework that tackles various tasks relevant to time-varying volumetric data visualization without modifying the network architecture. the core idea of our approach is to decompose diverse task inputs and outputs into a unified representation (i.e., coordinates and values) and learn a function from coordinates to their corresponding values. we achieve this goal using a residual block-based implicit neural representation architecture with periodic activation functions. we evaluate coordnet on data generation (i.e., temporal super-resolution and spatial super-resolution) and visualization generation (i.e., view synthesis and ambient occlusion prediction) tasks using time-varying volumetric data sets of various characteristics. the experimental results indicate that coordnet achieves better quantitative and qualitative results than the state-of-the-art approaches across all the evaluated tasks. source code and pre-trained models are available at https://github.com/stevenhan1991/coordnet.",AB_0212
"declarative grammar is becoming an increasingly important technique for understanding visualization design spaces. the gotreescape system presented in the paper allows users to navigate and explore the vast design space implied by gotree, a declarative grammar for visualizing tree structures. to provide an overview of the design space, gotreescape, which is based on an encoder-decoder architecture, projects the tree visualizations onto a 2d landscape. significantly, this landscape takes the relationships between different design features into account. gotreescape also includes an exploratory framework that allows top-down, bottom-up, and hybrid modes of exploration to support the inherently undirected nature of exploratory searches. two case studies demonstrate the diversity with which gotreescape expands the universe of designed tree visualizations for users. the source code associated with gotreescape is available at https://github.com/bitvis2021/gotreescape.",AB_0212
"in this paper, we propose a new method, called doublecoverudf, for extracting the zero level-set from unsigned distance fields (udfs). doublecoverudf takes a learned udf and a user-specified parameter r (a small positive real number) as input and extracts an iso-surface with an iso-value r using the conventional marching cubes algorithm. we show that the computed isosurface is the boundary of the r-offset volume of the target zero level-set s, which is an orientable manifold, regardless of the topology of s next, the algorithm computes a covering map to project the boundary mesh onto s, preserving the mesh's topology and avoiding folding. if s is an orientable manifold surface, our algorithm separates the double-layered mesh into a single layer using a robust minimum-cut post-processing step. otherwise, it keeps the double-layered mesh as the output. we validate our algorithm by reconstructing 3d surfaces of open models and demonstrate its efficacy and effectiveness on synthetic models and benchmark datasets. our experimental results confirm that our method is robust and produces meshes with better quality in terms of both visual evaluation and quantitative measures than existing udf-based methods. the source code is available at https://github.com/jjjkkyz/dcudf.",AB_0212
"we present the first large-scale database of measured spatially-varying anisotropic reflectance, consisting of 1,000 high-quality near-planar svbrdfs, spanning 9 material categories such as wood, fabric and metal. each sample is captured in 15 minutes, and represented as a set of high-resolution texture maps that correspond to spatially-varying brdf parameters and local frames. to build this database, we develop a novel integrated system for robust, high-quality and -efficiency reflectance acquisition and reconstruction. our setup consists of 2 cameras and 16,384 leds. we train 64 lighting patterns for efficient acquisition, in conjunction with a network that predicts per-point reflectance in a neural representation from carefully aligned two-view measurements captured under the patterns. the intermediate results are further fine-tuned with respect to the photographs acquired under 63 effective linear lights, and finally fitted to a brdf model. we report various statistics of the database, and demonstrate its value in the applications of material generation, classification as well as sampling. all related data, including future additions to the database, can be downloaded from https://opensvbrdf.github.io/.",AB_0212
"personalizing generative models offers a way to guide image generation with user-provided references. current personalization methods can invert an object or concept into the textual conditioning space and compose new natural sentences for text-to-image diffusion models. however, representing and editing specific visual attributes such as material, style, and layout remains a challenge, leading to a lack of disentanglement and editability. to address this problem, we propose a novel approach that leverages the step-by-step generation process of diffusion models, which generate images from low to high frequency information, providing a new perspective on representing, generating, and editing images. we develop the prompt spectrum space p*, an expanded textual conditioning space, and a new image representation method called prospect. prospect represents an image as a collection of inverted textual token embeddings encoded from per-stage prompts, where each prompt corresponds to a specific generation stage (i.e., a group of consecutive steps) of the diffusion model. experimental results demonstrate that p* and prospect offer better disentanglement and controllability compared to existing methods. we apply prospect in various personalized attribute-aware image generation applications, such as image-guided or text-driven manipulations of materials, style, and layout, achieving previously unattainable results from a single image input without fine-tuning the diffusion models. our source code is available at https://github.com/zyxelsa/prospect.",AB_0212
"recent advances in learning reusable motion priors have demonstrated their effectiveness in generating naturalistic behaviors. in this paper, we propose a new learning framework in this paradigm for controlling physics-based characters with improved motion quality and diversity over existing methods. the proposed method uses reinforcement learning (rl) to initially track and imitate life-like movements from unstructured motion clips using the discrete information bottleneck, as adopted in the vector quantized variational autoencoder (vq-vae). this structure compresses the most relevant information from the motion clips into a compact yet informative latent space, i.e., a discrete space over vector quantized codes. by sampling codes in the space from a trained categorical prior distribution, high-quality life-like behaviors can be generated, similar to the usage of vq-vae in computer vision. although this prior distribution can be trained with the supervision of the encoder's output, it follows the original motion clip distribution in the dataset and could lead to imbalanced behaviors in our setting. to address the issue, we further propose a technique named prior shifting to adjust the prior distribution using curiosity-driven rl. the outcome distribution is demonstrated to offer sufficient behavioral diversity and significantly facilitates upper-level policy learning for downstream tasks. we conduct comprehensive experiments using humanoid characters on two challenging downstream tasks, sword-shield striking and two-player boxing game. our results demonstrate that the proposed framework is capable of controlling the character to perform considerably high-quality movements in terms of behavioral strategies, diversity, and realism. videos, codes, and data are available at https://tencent-roboticsx.github.io/ncp/.",AB_0212
"diffusion models have achieved promising results in image restoration tasks, yet suffer from time-consuming, excessive computational resource consumption, and unstable restoration. to address these issues, we propose a robust and efficient diffusion-based low-light image enhancement approach, dubbed diffll. specifically, we present a wavelet-based conditional diffusion model (wcdm) that leverages the generative power of diffusion models to produce results with satisfactory perceptual fidelity. additionally, it also takes advantage of the strengths of wavelet transformation to greatly accelerate inference and reduce computational resource usage without sacrificing information. to avoid chaotic content and diversity, we perform both forward diffusion and denoising in the training phase of wcdm, enabling the model to achieve stable denoising and reduce randomness during inference. moreover, we further design a high-frequency restoration module (hfrm) that utilizes the vertical and horizontal details of the image to complement the diagonal information for better fine-grained restoration. extensive experiments on publicly available real-world benchmarks demonstrate that our method outperforms the existing state-of-the-art methods both quantitatively and visually, and it achieves remarkable improvements in efficiency compared to previous diffusion-based methods. in addition, we empirically show that the application for low-light face detection also reveals the latent practical values of our method. code is available at https://github.com/jianghaiscu/diffusion-low-light.",AB_0212
