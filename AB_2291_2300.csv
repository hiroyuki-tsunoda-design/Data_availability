AB,NO
"recently, many regression-based conditional independence (ci) test methods have been proposed to solve the problem of causal discovery. these methods provide alternatives to test ci of x, y given z by first removing the information of the controlling set z from x and y, and then testing the independence between the two residuals rx, z and ry, z. when the residuals are linearly uncorrelated, the independence test between them is nontrivial. with the ability to calculate inner product in high-dimensional space, kernel-based methods are usually used to achieve this goal, but they are considerably time-consuming. in this paper, we test the independence between two linear combinations under linear structural equation model. we show that the dependence between the two residuals can be captured by the difference between the similarity of rx, z and ry, z and that of rx, z and rr (rr is an independent copy of ry, z) in high-dimensional space. with this result, we provide a new way to test ci based on the similarity between residuals, which is called scit the abbreviation of similarity-based ci testing. furthermore, we develop two versions of the proposal, called kernel-scit and neural-scit, respectively. kernel-scit calculates the similarity by using kernel functions, while neural-scit approximates the upper bound of the similarity by using deep neural networks. in both algorithms, random permutation tests are performed to control type i error rate. the proposed tests are evaluated on (conditional) independence test and causal discovery with both synthetic and real datasets. experimental results show that kernel-scit is simpler yet more efficient and effective than the typical existing kernel-based methods hsic and kcit in the cases of small sample size, and neural-scit can significantly boost the performance of ci testing when sufficient samples are available. the source code is available at https://github.com/xyw5vplus1/scit.",AB_0230
"accurate prediction of nucleic binding residues is essential for the understanding of transcription and translation processes. integration of feature- and template-based strategies could improve the prediction of these key residues in proteins. nevertheless, traditional hybrid algorithms have been surpassed by recently developed deep learning-based methods, and the possibility of integrating deep learning- and template-based approaches to improve performance remains to be explored. to address these issues, we developed a novel structure-based integrative algorithm called nabind that can accurately predict dna- and rna-binding residues. a deep learning module was built based on the diversified sequence and structural descriptors and edge aggregated graph attention networks, while a template module was constructed by transforming the alignments between the query and its multiple templates into features for supervised learning. furthermore, the stacking strategy was adopted to integrate the above two modules for improving prediction performance. finally, a post-processing module dependent on the random walk algorithm was proposed to further correct the integrative predictions. extensive evaluations indicated that our approach could not only achieve excellent performance on both native and predicted structures but also outperformed existing hybrid algorithms and recent deep learning methods. the nabind server is available at http://liulab.hzau.edu.cn/nabind/. ten years ago we developed two hybrid algorithms (dnabind and rbrdetector) to predict nucleic acid binding residues by combining machine learning- and template-based strategies. however, this kind of algorithms have been surpassed by recent deep learning methods. moreover, the interplay between deep learning- and template-based approaches has yet to be explored. we thus designed a new generation hybrid algorithm termed nabind, in which a deep learning module was established by using diversified sequence and structural descriptors and edge-featured graph attention networks, while a template module was created by exploiting the relationship between the query protein and its multiple templates for supervised learning. afterward, a merging module based on the stacking strategy was adopted to integrate the above two modules, and a post-processing module dependent on the random walk algorithm was utilized to correct the integrative predictions. the new algorithm outperformed traditional hybrid methods by a large margin and showed better results than purely deep learning-based methods.",AB_0230
"here, we introduce trackplot, a python package for generating publication-quality visualization by a programmable and interactive web-based approach. compared to the existing versions of programs generating sashimi plots, trackplot offers a versatile platform for visually interpreting genomic data from a wide variety of sources, including gene annotation with functional domain mapping, isoform expression, isoform structures identified by scrna-seq and long-read sequencing, as well as chromatin accessibility and architecture without any preprocessing, and also offers a broad degree of flexibility for formats of output files that satisfy the requirements of major journals. the trackplot package is an open-source software which is freely available on bioconda (https://anaconda.org/bioconda/trackplot), docker (https://hub.docker.com/r/ygidtu/trackplot), pypi (https://pypi.org/project/trackplot/) and github (https://github.com/ygidtu/trackplot), and a built-in web server for local deployment is also provided. simultaneously visualizing how isoform expression, protein-dna/rna interactions, accessibility, and architecture of chromatin differs across conditions and cell types could inform our understanding on regulatory mechanisms and functional consequences of alternative splicing. however, the existing versions of tools generating sashimi plots remain inflexible, complicated, and user-unfriendly for integrating data sources from multiple bioinformatic formats or various genomics assays. thus, a more scalable visualization tool is necessary to broaden the scope of sashimi plots. to overcome these limitations, we present trackplot, a comprehensive tool that delivers high-quality plots via a programmable and interactive web-based platform. trackplot seamlessly integrates diverse data sources and utilizes a multi-threaded process, enabling users to explore genomic signal in large-scale sequencing datasets.",AB_0230
"vibrio splendidus is a common pathogen in the ocean that infects apostichopus japonicus, atlantic salmon and crassostrea gigas, leading to a variety of diseases. in this study, a virulent phage vb_vspm_vs1, which infects v. splendidus, was isolated from aquaculture ponds in dalian, china, and it belongs to the family straboviridae in the order caudoviricetes. vb_vspm_vs1 had an adsorption rate of 96% in 15 min, a latent period of 65 min, and a burst size of 140 & plusmn; 6 pfu/cell. the complete genome of phage vb_vspm_vs1 consists of a linear double-stranded dna that is 248,270 bp in length with an average g + c content of 42.5% and 389 putative protein-coding genes; 116 genes have known functions. there are 4 tail fiber genes in the positive and negative strands of the phage vb_vspm_vs1 genome. the protein domain of the phage vb_vspm_vs1 tail fibers was obtained from the protein data bank and the smart (http://smart.embl.de) database. bacterial challenge tests revealed that the growth of v. splendidus hs0 was apparently inhibited (od600 < 0.01) in 12 h at an moi of 10. in against biofilms, we also showed that the od570 value of the vb_vspm_vs1-treated group (moi = 1) decreased significantly to 0.04 & plusmn; 0.01 compared with that of the control group (0.48 & plusmn; 0.08) at 24 h. this study characterizes the genome of the phage vb_vspm_vs1 that infects the pathogenic bacterium v. splendidus of a. japonicus.",AB_0230
"accurate segmentation of multiple abdominal organs from computed tomography (ct) images plays an important role in computer-aided diagnosis, treatment planning and follow-up. currently, 3d convolution neural networks (cnn) have achieved promising performance for automatic medical image segmentation tasks. however, most existing 3d cnns have a large set of parameters and huge floating point operations (flops), and 3d ct volumes have a large size, leading to high computational cost, which limits their clinical application. to tackle this issue, we propose a novel framework based on lightweight network and knowledge distillation (kd) for delineating multiple organs from 3d ct volumes. we first propose a novel lightweight medical image segmentation network named lcov-net for reducing the model size and then introduce two knowledge distillation modules (i.e., class-affinity kd and multi-scale kd) to effectively distill the knowledge from a heavy-weight teacher model to improve lcov-net's segmentation accuracy. experiments on two public abdominal ct datasets for multiple organ segmentation showed that: 1) our lcov-net outperformed existing lightweight 3d segmentation models in both computational cost and accuracy; 2) the proposed kd strategy effectively improved the performance of the lightweight network, and it outperformed existing kd methods; 3) combining the proposed lcov-net and kd strategy, our framework achieved better performance than the state-of-the-art 3d nnu-net with only one-fifth parameters. the code is available at https://github.com/hilab-git/lcovnet-and-kd.",AB_0230
"recognition and quantitative analytics of histopathological cells are the golden standard for diagnosing multiple cancers. despite recent advances in deep learning techniques that have been widely investigated for the automated segmentation of various types of histopathological cells, the heavy dependency on specific histopathological image types with sufficient supervised annotations, as well as the limited access to clinical data in hospitals, still pose significant challenges in the application of computer-aided diagnosis in pathology. in this paper, we focus on the model generalization of cell segmentation towards cross-tissue histopathological images. remarkably, a novel target-specific finetuning-based self-supervised domain adaptation framework is proposed to transfer the cell segmentation model to unlabeled target datasets, without access to source datasets and annotations. when performed on the target unlabeled histopathological image set, the proposed method only needs to tune very few parameters of the pre-trained model in a self-supervised manner. considering the morphological properties of pathological cells, we introduce two constraint terms at both local and global levels into this framework to access more reliable predictions. the proposed cross-domain framework is validated on three different types of histopathological tissues, showing promising performance in self-supervised cell segmentation. additionally, the whole framework can be further applied to clinical tools in pathology without accessing the original training image data. the code and dataset are released at: https://github.com/neuronxjtu/sfda-cellseg.",AB_0230
"u-nets have achieved tremendous success in medical image segmentation. nevertheless, it may have limitations in global (long-range) contextual interactions and edge-detail preservation. in contrast, the transformer module has an excellent ability to capture long-range dependencies by leveraging the self-attention mechanism into the encoder. although the transformer module was born to model the long-range dependency on the extracted feature maps, it still suffers high computational and spatial complexities in processing high-resolution 3d feature maps. this motivates us to design an efficient transformer-based unet model and study the feasibility of transformer-based network architectures for medical image segmentation tasks. to this end, we propose to self-distill a transformer-based unet for medical image segmentation, which simultaneously learns global semantic information and local spatial-detailed features. meanwhile, a local multi-scale fusion block is first proposed to refine fine-grained details from the skipped connections in the encoder by the main cnn stem through self-distillation, only computed during training and removed at inference with minimal overhead. extensive experiments on brats 2019 and chaos datasets show that our missu achieves the best performance over previous state-of-the-art methods. code and models are available at: https://github.com/wangn123/missu.git",AB_0230
"cardiovascular disease (cvd) accounts for about half of non-communicable diseases. vessel stenosis in the coronary artery is considered to be the major risk of cvd. computed tomography angiography (cta) is one of the widely used noninvasive imaging modalities in coronary artery diagnosis due to its superior image resolution. clinically, segmentation of coronary arteries is essential for the diagnosis and quantification of coronary artery disease. recently, a variety of works have been proposed to address this problem. however, on one hand, most works rely on in-house datasets, and only a few works published their datasets to the public which only contain tens of images. on the other hand, their source code have not been published, and most follow-up works have not made comparison with existing works, which makes it difficult to judge the effectiveness of the methods and hinders the further exploration of this challenging yet critical problem in the community. in this paper, we propose a large-scale dataset for coronary artery segmentation on cta images. in addition, we have implemented a benchmark in which we have tried our best to implement several typical existing methods. furthermore, we propose a strong baseline method which combines multi-scale patch fusion and two-stage processing to extract the details of vessels. comprehensive experiments show that the proposed method achieves better performance than existing works on the proposed large-scale dataset. the benchmark and the dataset are published at https://github.com/xiaoweixu/imagecas-a-large-scale-dataset-and-benchmark-for-coronary-artery-segmentation-based-on-ct.",AB_0230
"dictionary learning is an efficient knowledge representation method that can learn the essential features of data. traditional dictionary learning methods are difficult to obtain nonlinear information when processing large-scale and high-dimensional datasets. while most dictionary learning algorithms are based on the assumption that the training data and test data have the same feature distribution, which is not always true in practical applications. to address the above problems, we propose the kernel fisher dictionary transfer learning (kfdtl) algorithm. first, we map each sample to high-dimensional space through kernel mapping and use any dictionary learning algorithm to learn the essential features. then, the feature-based transfer learning method is performed to predict the labels of the target samples. this method includes three main contributions: (1) kfdtl constructs a discriminative fisher embedding model tomake the same class samples have similar coding coefficients; (2) based on the relationship between profiles and atoms, kfdtl constructs an adaptive model that adapts source domain samples to target domain samples; (3) the kernel method is used to efficiently solve nonlinear problems. experiments on a large number of public image datasets have proved the effectiveness of the proposed method. the source code of the proposed method is available at https://github.com/zzfan3/kfdtl.",AB_0230
"image-text retrieval aims to take the text (image) query to retrieve the semantically relevant images (texts), which is fundamental and critical in the search system, online shopping, and social network. existing works have shown the effectiveness of visual-semantic embedding and unimodal knowledge exploiting (e.g., textual knowledge) in connecting the image and text. however, they neglect the implicit multimodal knowledge relations between these two modalities when the image contains information that is not directly described in the text, hindering the ability to connect the image and text with the implicit semantic relations. for instance, an image shows a person next to the tap but the pairing text description may only include the word wash, missing the washing tool tap. the implicit semantic relation between image object tap and text word wash can help to connect the above image and text. to sufficiently utilize the implicit multimodal knowledge relations, we propose a multimodal knowledge enhanced visual-semantic embedding (mkvse) approach building a multimodal knowledge graph to explicitly represent the implicit multimodal knowledge relations and injecting it to visual-semantic embedding for image-text retrieval task. the contributions in this article can be summarized as follows: (1) multimodal knowledge graph (mkg) is proposed to explicitly represent the implicit multimodal knowledge relations between the image and text as intra-modal semantic relations and inter-modal co-occurrence relations. intra-modal semantic relations provide synonymy information that is implicit in the unimodal data such as the text corpus. and inter-modal co-occurrence relations characterize the co-occurrence correlations (such as temporal, causal, and logical) that are implicit in image-text pairs. these two relations help establishing reliable image-text connections in the higher-level semantic space. (2) multimodal graph convolution networks (mgcn) is proposed to reason on the mkg in two steps to sufficiently utilize the implicit multimodal knowledge relations. in the first step, mgcn focuses on the intra-modal relations to distinguish other entities in the semantic space. in the second step, mgcn focuses on the inter-modal relations to connect multimodal entities based on co-occurrence correlations. the two-step reasoning manner can sufficiently utilize the implicit semantic relations between two modal entities to enhance the embeddings of the image and text. extensive experiments are conducted on two widely used datasets, namely, flickr30k and mscoco, to demonstrate the superiority of the proposed mkvse approach in achieving state-of-the-art performances. the codes are available at https://github.com/pku-icst-mipl/mkvse- tomm2023.",AB_0230
