AB,NO
"in this paper, we propose a feature affinity (fa) assisted knowledge distillation (kd) method to improve quantization-aware training of deep neural networks (dnn). the fa loss on intermediate feature maps of dnns plays the role of teaching middle steps of a solution to a student instead of only giving final answers in the conventional kd where the loss acts on the network logits at the output level. combining logit loss and fa loss, we found via convolutional network experiments on cifar-10/100, and tiny imagenet data sets that the quantized student network receives stronger supervision than from the labeled ground-truth data. the resulting fa quantization-distillation (faqd), trained to convergence with a cosine annealing scheduler for 200 epochs, is capable of compressing models on label-free data up to or exceeding the accuracy levels of their full precision counterparts, which brings immediate practical benefits as pre-trained teacher models are readily available and unlabeled data are abundant. in contrast, data labeling is often laborious and expensive. finally, we propose and prove error estimates for a fast feature affinity (ffa) loss function that accurately approximates fa loss at a lower order of computational complexity, which helps speed up training for high resolution image input. source codes are available at: https://github.com/lzj994/faqd",AB_0592
"background: current psychiatric epidemiological evidence estimates that 17% of young adults (aged 18-25 years) experienced a major depressive episode in 2020, relative to 8.4% of all adults aged & ge;26 years. young adults with a major depressive episode in the past year are the least likely to receive treatment for depression compared with other age groups.objective: we conducted a randomized clinical trial following our initial 4-week sms text message-delivered cognitive behavioral therapy (cbt-txt) for depression in young adults. we sought to test mechanisms of change for cbt-txt.methods: based on participant feedback, outcome data, and the empirical literature, we increased the treatment dosage from 4-8 weeks and tested 3 mechanisms of change with 103 young adults in the united states. participants were from 34 states, recruited from facebook and instagram and presenting with at least moderate depressive symptomatology. web-based assessments occurred at baseline prior to randomization and at 1, 2, and 3 months after enrollment. the primary outcome, the severity of depressive symptoms, was assessed using the beck depression inventory ii. behavioral activation, perseverative thinking, and cognitive distortions were measured as mechanisms of change. participants were randomized to cbt-txt or a waitlist control condition. those assigned to the cbt-txt intervention condition received 474 fully automated sms text messages, delivered every other day over a 64-day period and averaging 14.8 (sd 2.4) sms text messages per treatment day. intervention texts are delivered via textit, a web-based automated sms text messaging platform.results: across all 3 months of the study, participants in the cbt-txt group showed significantly larger decreases in depressive symptoms than those in the control group (p<.001 at each follow-up), producing a medium-to-large effect size (cohen d=0.76). over half (25/47, 53%) of the treatment group moved into the high-end functioning category, representing no or minimal clinically significant depressive symptoms, compared with 15% (8/53) of the control condition. mediation analysis showed that cbt-txt appeared to lead to greater increases in behavioral activation and greater decreases in cognitive distortions and perseverative thinking across the 3-month follow-up period, which were then associated with larger baseline to 3-month decreases in depression. the size of the indirect effects was substantial: 57%, 41%, and 50% of the cbt-txt effect on changes in depression were mediated by changes in behavioral activation, cognitive distortions, and perseverative thinking, respectively. models including all 3 mediators simultaneously showed that 63% of the cbt-txt effect was mediated by the combined indirect effects.conclusions: results provide evidence for the efficacy of cbt-txt to reduce young adult depressive symptoms through hypothesized mechanisms. to the best of our knowledge, cbt-txt is unique in its sms text message-delivered modality, the strong clinical evidence supporting efficacy and mechanisms of change.trial registration: clinicaltrials.gov nct05551702; https://clinicaltrials.gov/study/nct05551702",AB_0592
"satellite ocean color products derived from the visible infrared imaging radiometer suite (viirs) onboard the suomi national polar-orbiting partnership (snpp) and the national oceanic and atmospheric administration (noaa)-20, and the ocean and land colour instrument (olci) on the sentinel-3a (s3a) and sentinel-3b (s3b) have been widely used for surveillance of the ocean environment and research on ocean physical, biological, biogeochemical, and ecological processes. however, either viirs or olci daily ocean color images are often incomplete in spatial coverage due to cloud cover, contamination of high sun glint, narrow swath width, high sensor-zenith angle, high solar-zenith angle, and/or other unfavorable retrieval conditions. although merging daily ocean color images from multiple satellite sensors can help reduce the number of invalid pixels, gap-filling methods, such as the data interpolating empirical orthogonal function (dineof), are often used to reconstruct invalid pixels and generate gap-free images. the 9-km spatial resolution global gap-free ocean color data have been routinely produced by the noaa ocean color science team and distributed through noaa coast-watch (https://coastwatch.noaa.gov/cw/index.html). in this study, we aim to develop and produce improved spatial resolution gap-free products, including chlorophyll-a (chl-a) concentration, diffuse attenuation coefficient at the wavelength of 490 nm [k-d(490)], and suspended particulate matter (spm) concentration for spatial resolutions of 0.5-, 1-, and 2-km. two-sensor (viirs-snpp and viirs-noaa-20), three-sensor (two-sensor + olci-s3a), and four-sensor (three-sensor + olci-s3b) daily merged global level-3 ocean color data are created and compared. it is found that, by merging data from the two viirs sensors, similar to 38% more valid ocean product data are retrieved compared with a single sensor from either snpp or noaa-20. adding olci-s3a to the two-sensor merged data can increase the number of valid pixels by similar to 12%, and adding olci-s3b to the three-sensor merged data can further increase the number of valid pixels by similar to 8%. the dineof method is applied to daily two-, three-, and four-sensor merged data to generate global 2-km resolution gap-free images. results show that 2-km resolution gap-free images are able to resolve fine ocean features, such as coastal eddies and filaments, which are not available in the 9-km resolution images. while adding olci-s3a data significantly improves the three-sensor-derived gap-free images over the two-sensor images, no significant enhancement is found in the four-sensor-derived gap-free images by adding olci-s3b data. the dineof method is also applied to 1- and 0.5-km resolution four-sensor merged chl-a, k-d(490), and spm images in the gulf of mexico and u.s. west coast region. it is found that both 0.5- and 1-km resolution images show more detailed ocean structures and features in coastal regions.",AB_0592
"speckle is a type of multiplicative noise that affects all coherent imaging modalities including synthetic aperture radar (sar) images. the presence of speckle degrades the image quality and can adversely affect the performance of sar image applications such as automatic target recognition and change detection. thus, sar despeckling is an important problem in remote sensing. in this letter, we introduce sar-ddpm, a denoising diffusion probabilistic model for sar despeckling. the proposed method uses a markov chain that transforms clean images into white gaussian noise by successively adding random noise. the despeckled image is obtained through a reverse process that predicts the added noise iteratively, using a noise predictor conditioned on the speckled image. in addition, we propose a new inference strategy based on cycle spinning to improve the despeckling performance. our experiments on both synthetic and real sar images demonstrate that the proposed method leads to significant improvements in both quantitative and qualitative results over the state-of-the-art despeckling methods. the code is available at: https://github.com/malshav/sar_ddpm",AB_0592
"background: extant gaps in mental health services are intensified among first-generation college students. improving access to empirically based interventions is critical, and mobile health (mhealth) interventions are growing in support. acceptance and commitment therapy (act) is an empirically supported intervention that has been applied to college students, via mobile app, and in brief intervals.objective: this study evaluated the safety, feasibility, and effectiveness of an act-based mhealth intervention using a microrandomized trial (mrt) design.methods: participants (n=34) were 18-to 19-year-old first-generation college students reporting distress, who participated in a 6-week intervention period of twice-daily assessments and randomization to intervention. participants logged symptoms, moods, and behaviors on the mobile app lorevimo. after the assessment, participants were randomized to an act-based intervention or no intervention. analyses examined proximal change after randomization using a weighted and centered least squares approach. outcomes included values-based and avoidance behavior, as well as depressive symptoms and perceived stress.results: the findings indicated the intervention was safe and feasible. the intervention increased values-based behavior but did not decrease avoidance behavior. the intervention reduced depressive symptoms but not perceived stress.conclusions: an mrt of an mhealth act-based intervention among distressed first-generation college students suggests that a larger mrt is warranted. future investigations may tailor interventions to contexts where intervention is most impactful. trial registration: clinicaltrials.gov nct04081662; https://clinicaltrials.gov/show/nct04081662",AB_0592
"video represents the majority of internet traffic today, driving a continual race between the generation of higher quality content, transmission of larger file sizes, and the development of network infrastructure. in addition, the recent covid-19 pandemic fueled a surge in the use of video conferencing tools. since videos take up considerable bandwidth similar to 100 kbps to a few mbps), improved video compression can have a substantial impact on network performance for live and pre-recorded content, providing broader access to multimedia content worldwide. we present a novel video compression pipeline, called txt2vid, which dramatically reduces data transmission rates by compressing webcam videos (talking-head videos) to a text transcript. the text is transmitted and decoded into a realistic reconstruction of the original video using recent advances in deep learning based voice cloning and lip syncing models. our generative pipeline achieves two to three orders of magnitude reduction in the bitrate as compared to the standard audio-video codecs (encoders-decoders), while maintaining equivalent quality-of-experience based on a subjective evaluation by users n = 242) in an online study. the txt2vid framework opens up the potential for creating novel applications such as enabling audio-video communication during poor internet connectivity, or in remote terrains with limited bandwidth. the code for this work is available at https://github.com/tpulkit/txt2vid.git.",AB_0592
"background: substance use, particularly binge drinking of alcohol and noninjection substance use, is associated with increased risk for hiv infection among youth, but structured substance use screening and brief intervention are not often provided as part of hiv risk reduction.objective: the purpose of the study was to test the efficacy of a fully automated electronic screening and brief intervention, called step up, test up, to reduce alcohol misuse among adolescents and young adults presenting for hiv testing. secondary objectives were reduction in sexual risk and uptake of pre-exposure prophylaxis (prep) for hiv prevention.methods: youth aged 16 years to 25 years who presented for hiv testing at community-based locations were recruited for study participation. those who screened at moderate to high risk on the alcohol use disorders identification test were randomized (1:1) to either an electronic brief intervention or a time-attention control. the primary outcome was change in alcohol use at 1, 3, 6, and 12-month follow-ups. negative binomial and log binomial regression analyses with generalized estimating equations were conducted to evaluate the intervention efficacy.results: among a sample of 329 youth, there were no significant differences in alcohol use outcomes between conditions over time or at the 1, 3, 6, or 12-month time points. in terms of secondary outcomes, there was evidence of reduction in condomless insertive anal sex under the influence of alcohol and drugs at 12 months compared with 3 months in the intervention versus the attention control condition (incidence rate ratio=0.15, 95% ci 0.05-0.44); however, there were no other significant differences in sexual risk and no difference in prep engagement.conclusions: we found no effect of electronic brief intervention to reduce alcohol use and some effect on sexual risk among youth aged 16 years to 25 years who present for hiv testing. trial registration: clinicaltrials.gov number nct02703116; https://clinicaltrials.gov/ct2/show/nct02703116",AB_0592
"the rise of vision-based environmental, marine, and oceanic exploration research highlights the need for supporting underwater image enhancement techniques to help mitigate water effects on images such as blurriness, low color contrast, and poor quality. this paper presents an evaluation of common underwater image enhancement techniques using our new publicly-available challenging dataset for underwater image enhancement (cduie). the collected dataset is comprised of 85 images of aquatic plants taken at a shallow depth of up to three meters from three different locations in the great lake superior, usa, via a remotely operated vehicle (rov) equipped with a high-definition rgb camera. in particular, we use our dataset to benchmark nine state-of-the-art image enhancement models at three different depths using a set of common non-reference image quality evaluation metrics. then we provide a comparative analysis of the performance of the selected models at different depths and highlight the most prevalent ones. the obtained results show that the selected image enhancement models are capable of producing considerably better-quality images with some models performing better than others at certain depths. the dataset is available at https://www.github.com/ashrafrepo/underwater-image-enhancement.",AB_0592
"biomedical machine reading comprehension (bio-mrc), a crucial task in natural language processing, is a vital application of a computer-assisted clinical decision support system. it can help clinicians extract critical information effortlessly for clinical decision-making by comprehending and answering questions from biomedical text data. while recent advances in bio-mrc consider text data from resources such as clinical notes and scholarly articles, the clinical practice guidelines (cpgs) are still unexplored in this regard. cpgs are a pivotal component of clinical decision-making at the point of care as they provide recommendations for patient care based on the most up-to-date information available. although cpgs are inherently terse compared to a multitude of articles, often, clinicians find them lengthy and complicated to use. in this paper, we define a new problem domain - bio-mrc on cpgs - where the ultimate goal is to assist clinicians in efficiently interpreting the clinical practice guidelines using mrc systems. to that end, we develop a manually annotated and subject-matter expert-validated benchmark dataset for the bio-mrc task on cpgs - cpgqa. this dataset aims to evaluate intelligent systems performing mrc tasks on cpgs. hence, we employ the state-of-the-art mrc models to present a case study illustrating an extensive evaluation of the proposed dataset. we address the problem of lack of training data in this newly defined domain by applying transfer learning. the results show that while the current state-of-the-art models perform well with 78% exact match scores on the dataset, there is still room for improvement, warranting further research on this problem domain. we release the dataset at https://github.com/mmahbub/cpgqa.",AB_0592
"a major limitation to advances in fingerprint presentation attack detection (pad) is the lack of publicly available, large-scale datasets, a problem which has been compounded by increased concerns surrounding privacy and security of biometric data. furthermore, most state-of-the-art pad algorithms rely on deep networks which perform best in the presence of a large amount of training data. this work aims to demonstrate the utility of synthetic (both bona fide and pa style) fingerprints in supplying these algorithms with sufficient data to improve the performance of fingerprint pad algorithms beyond the capabilities when training on a limited amount of publicly available real datasets. first, we provide details of our approach in modifying a state-of-the-art generative architecture to synthesize high quality bona fide and pa fingerprints. then, we provide quantitative and qualitative analysis to verify the quality of our synthetic fingerprints in mimicking the distribution of real data samples. we showcase the utility of our synthetic bona fide and pa fingerprints in training a deep network for fingerprint pad, which dramatically boosts the performance across three different evaluation datasets compared to an identical model trained on real data alone. finally, we demonstrate that only 25% of the original (real) dataset is required to obtain similar detection performance when augmenting the training dataset with synthetic data. we make our synthetic dataset and model publicly available to encourage further research on this topic: https://github.com/groszste/spoofgan.",AB_0592
