AB,NO
"introduction dementia care management is a complex intervention intended to support persons with dementia and their (caring) relatives in home based care arrangements. dementia care management was developed in the federal state of mecklenburg-western pomerania in germany and subsequently adapted for the german region of siegen-wittgenstein, where it will now be implemented. four different service providers will carry out the implementation process. this study protocol describes the planned procedures for the parallel evaluation of the implementation process.methods and analysis a multiple embedded case study design was chosen for the planned process evaluation. data collection and analysis will be informed by the consolidated framework for implementation research, the expert recommendations for implementing change, the medical research council framework for conducting process evaluations of complex interventions and the taxonomy of outcomes for implementation research. information (qualitative and quantitative) will be collected from all stakeholders involved in the dementia care management intervention (ie, dementia care managers, general practitioners, people with dementia).ethics and dissemination the process evaluation is conducted in accordance with the declaration of helsinki, the recommendations on good scientific practice, the research ethics principles of the code of ethics of the german society of nursing science, and on the basis of ethical approval from the clinical ethics committee of university medicine greifswald (bb 110/22). the results of the process evaluation will be disseminated through reports to the funders of the study and also as a summary of recommendations for the sustainable implementation of dementia care management for future implementers. we also plan to publish the results of this process evaluation in an international peer-reviewed journal.trial registration number nct05529277, registered 7 september 2022, https://beta.clinicaltrials.gov/study/ nct05529277.",AB_0487
"thinning is a sub-sampling technique to reduce the memory footprint of markov chain monte carlo. despite being commonly used, thinning is rarely considered efficient. for sampling constraint-based models, a highly relevant use-case in systems biology, we here demonstrate that thinning boosts computational and, thereby, sampling efficiencies of the widely used coordinate hit-and-run with rounding (chrr) algorithm. by benchmarking chrr with thinning with simplices and genome-scale metabolic networks of up to thousands of dimensions, we find a substantial increase in computational efficiency compared to unthinned chrr, in our examples by orders of magnitude, as measured by the effective sample size per time (ess/t), with performance gains growing with polytope (effective network) dimension. using a set of benchmark models we derive a ready-to-apply guideline for tuning thinning to efficient and effective use of compute resources without requiring additional coding effort. our guideline is validated using three (out-of-sample) large-scale networks and we show that it allows sampling convex polytopes uniformly to convergence in a fraction of time, thereby unlocking the rigorous investigation of hitherto intractable models. the derivation of our guideline is explained in detail, allowing future researchers to update it as needed as new model classes and more training data becomes available. chrr with deliberate utilization of thinning thereby paves the way to keep pace with progressing model sizes derived with the constraint-based reconstruction and analysis (cobra) tool set. sampling and evaluation pipelines are available at https://jugit.fz-juelich.de/ibg-1/modsim/ fluxomics/chrrt.",AB_0487
"complexome profiling allows large-scale, untargeted, and comprehensive characterization of protein complexes in a biological sample using a combined approach of separating intact protein complexes e.g., by native gel electrophoresis, followed by mass spectrometric analysis of the proteins in the resulting fractions. over the last decade, its application has resulted in a large collection of complexome profiling datasets. while computational methods have been developed for the analysis of individual datasets, methods for large-scale comparative analysis of complexomes from multiple species are lacking. here, we present comparative clustering (compact), that performs fully automated integrative analysis of complexome profiling data from multiple species, enabling systematic characterization and comparison of complexomes. compact implements a novel method for leveraging orthology in comparative analysis to allow systematic identification of conserved as well as taxonspecific elements of the analyzed complexomes. we applied this method to a collection of 53 complexome profiles spanning the major branches of the eukaryotes. we demonstrate the ability of compact to robustly identify the composition of protein complexes, and show that integrated analysis of multiple datasets improves characterization of complexes from specific complexome profiles when compared to separate analyses. we identified novel candidate interactors and complexes in a number of species from previously analyzed datasets, like the emp24, the v-atpase and mitochondrial atp synthase complexes. lastly, we demonstrate the utility of compact for the automated large-scale characterization of the complexome of the mosquito anopheles stephensi shedding light on the evolution of metazoan protein complexes. compact is available from https://github.com/cmbi/compact-bio.",AB_0487
"a timely and accurate spatial mapping of built-up areas (ba) is crucial in making cities and human settlements safe, resilient, and sustainable. synthetic aperture radar (sar) data are useful for ba mapping due to strong coherent backscatter from diverse human-made targets, distinct texture patterns, and sensitivity to its geometric characteristics. however, ba mapping using sar data is still challenging due to various geometrical and physical factors that often lead to misinterpretations. therefore, this study presents a novel method to map ba using single-date dual polarized sentinel-1 sar data to overcome such challenges in complex built-up scenarios. here, we propose three normalized descriptors derived from the stokes vector elements. these three descriptors are found to be vital in characterizing different types of ba structures. we then consider the symmetric quadratic mean of the normalized descriptors to propose a novel dual polarimetric radar built-up index (dprbi). the proposed index provides information about the average normalized polarized power, which is useful for mapping diverse types of ba or their combination in an image. we assess the proposed methodology utilizing the sentinel-1 image acquired over three major cities: delhi, milan, and barcelona. the ba map accuracy for all three cities was found to be & ap; 85 % with a low ba omission error. we compared the mapping results with available ba/land cover products: world settlement footprint 2019 (wsf-19) and world cover 2020 (wc-20). the ba map obtained using the proposed index was better than wsf-19 and wc-20, particularly for ba omission errors. for example, we observed a relatively low ba omission error of 22.34 % using dprbi compared to 31.86 % and 41.79 % for wc-20 and wsf-19, respectively, over milan, italy. the code is available at: https://github.com/navv37/dprbi",AB_0487
"background the brain is a common site for cancer metastases. in case of large and/or symptomatic brain metastases, neurosurgical resection is performed. adjuvant radiotherapy is a standard procedure to minimize the risk of local recurrence and is increasingly performed as local stereotactic radiotherapy to the resection cavity. both hypofractionated stereotactic radiotherapy (hfsrt) and single fraction stereotactic radiosurgery (srs) can be applied in this case. although adjuvant stereotactic radiotherapy to the resection cavity is widely used in clinical routine and recommended in international guidelines, the optimal fractionation scheme still remains unclear. the saturnus trial prospectively compares adjuvant hfsrt with srs and seeks to detect the superiority of hfsrt over srs in terms of local tumor control. methods in this single center two-armed randomized phase iii trial, adjuvant radiotherapy to the resection cavity of brain metastases with hfsrt (6 - 7 x 5 gy prescribed to the surrounding isodose) is compared to srs (1 x 12-20 gy prescribed to the surrounding isodose). patients are randomized 1:1 into the two different treatment arms. the primary endpoint of the trial is local control at the resected site at 12 months. the trial is based on the hypothesis that hfsrt is superior to srs in terms of local tumor control. discussion although adjuvant stereotactic radiotherapy after resection of brain metastases is considered standard of care treatment, there is a need for further prospective research to determine the optimal fractionation scheme. to the best of our knowledge, the saturnus study is the only randomized phase iii study comparing different regimes of postoperative stereotactic radiotherapy to the resection cavity adequately powered to detect the superiority of hfsrt regarding local control. trial registration the study was retrospectively registered with clinicaltrials.gov, number nct05160818, on december 16, 2021. the trial registry record is available on https://clinicaltrials.gov/study/nct05160818. the presented protocol refers to version v1.3 from march 21, 2021.",AB_0487
"satellite telemetry data is a special case of multivariate time series characterized by large volumes (in terms of both the number of series and samples), varying sampling rates (including time gaps), redundant sensors, and many interconnections between the series. special tools are needed to handle visualization, analysis, and, most importantly, annotation of such data. manually prepared annotations are crucial when designing and evaluating algorithms for satellite telemetry analysis, including anomaly detection in telemetry data. although there are many applications for time series analysis, there are no tools that would smoothly handle typical satellite telemetry and at the same time provide a free user-friendly interface accessible from any computer without the need for installation, registration, data sharing, or special training. as a solution to this technology gap, we propose the web-based oxi tool written in javascript and publicly available at https://oxi.kplabs.pl/. based on the trainset application (https://trainset.geocene.com/), we optimized each part of the interface to handle real satellite telemetry data from european space agency (esa) missions. the most important improvements include the redesigned data loading and visualization to effectively handle large datasets (up to 2,000,000 samples), different annotation modes (1d/2d and single/multi-series), autosaving annotation status in the browser storage, and dozens of user experience enhancements (autoscaling of axes, color-coded selectors, additional hotkeys, and many others). the tool was designed and evaluated in cooperation with domain experts from airbus and esa. finally, we provide an extensive description of the software, design choices, and their impact on creating and evaluating machine learning models for anomaly detection in satellite telemetry.& copy; 2023 published by elsevier b.v. this is an open access article under the cc by license ().",AB_0487
"scientists employing omics in life science studies face challenges such as the modeling of multiassay studies, recording of all relevant parameters, and managing many samples with their metadata. they must manage many large files that are the results of the assays or subsequent computation. users with diverse backgrounds, ranging from computational scientists to wet-lab scientists, have dissimilar needs when it comes to data access, with programmatic interfaces being favored by the former and graphical ones by the latter. we introduce sodar, the system for omics data access and retrieval. sodar is a software package that addresses these challenges by providing a web-based graphical user interface for managing multiassay studies and describing them using the isa (investigation, study, assay) data model and the isa-tab file format. data storage is handled using the irods data management system, which handles large quantities of files and substantial amounts of data. sodar also offers programmable apis and command-line access for metadata and file storage. sodar supports complex omics integration studies and can be easily installed. the software is written in python 3 and freely available at https://github.com/bihealth/sodar-server under the mit license.",AB_0487
"studying the impact of new-physics models on low-energy observables necessitates matching to effective field theories at the relevant mass thresholds. we introduce the first public version of matchete, a computer tool for matching weakly-coupled models at one-loop order. it uses functional methods to directly compute all matching contributions in a manifestly gauge-covariant manner, while simplification methods eliminate redundant operators from the output. we sketch the workings of the program and provide examples of how to match simple standard model extensions. the package, documentation, and example notebooks are publicly available at https://gitlab.com/matchete/matchete.",AB_0487
"subspace distance is an invaluable tool exploited in a wide range of feature selection methods. the power of subspace distance is that it can identify a representative subspace, including a group of features that can efficiently approximate the space of original features. on the other hand, employing intrinsic statistical information of data can play a significant role in a feature selection process. nevertheless, most of the existing feature selection methods founded on the subspace distance are limited in properly fulfilling this objective. to pursue this void, we propose a framework that takes a subspace distance into account which is called variance-covariance subspace distance. the approach gains advantages from the correlation of information included in the features of data, thus determines all the feature subsets whose corresponding variance-covariance matrix has the minimum norm property. consequently, a novel, yet efficient unsupervised feature selection framework is introduced based on the variance-covariance distance to handle both the dimensionality reduction and subspace learning tasks. the proposed framework has the ability to exclude those features that have the least variance from the original feature set. moreover, an efficient update algorithm is provided along with its associated convergence analysis to solve the optimization side of the proposed approach. an extensive number of experiments on nine benchmark datasets are also conducted to assess the performance of our method from which the results demonstrate its superiority over a variety of stateof-the-art unsupervised feature selection methods. the source code is available at https://github.com/ & copy; 2023 the author(s). published by elsevier ltd. this is an open access article under the cc by license ().",AB_0487
"evaporites flow in the solid state under relatively low differential stress and have unique mechanical properties compared to other sedimentary rocks. worldwide, they control the structural and stratigraphical architecture of many basins and orogens in ancient and active tectonic settings. moreover, they host mineral deposits and play a key role in petroleum systems because they typically act as seals due to their low permeability, and their ability to flow results in the formation of structural hydrocarbon traps such as folds and faults in their encasing rocks. additionally, evaporite structures can be used as subsurface storage sites for geo-energy applications and nuclear waste. the systematic characterisation of subsurface evaporite structures is thus key for the development of geoscience-based technologies to address societal challenges. owing to their value, massive amounts of surface and subsurface information about (among others) the stratigraphy, structure, geochemistry, and petrophysical properties of evaporite structures and their surrounding rocks have been acquired by earth scientists, petroleum and mining exploration companies, and geological surveys. however, the data often appear segregated (i.e. in the form of database fragments, scientific articles, and unpublished reports), are not systematically organised, and are sometimes not fully accessible. this contribution presents the iberian evaporite structure database (iesdb), the first comprehensive assessment that focuses on evaporite structures carried out in any region of the world. the iesdb includes information and figures for 150 evaporite structures and their surrounding rocks inventoried in spain and portugal and is sourced from other six thematic databases and more than 1500 published and unpublished scientific documents. the database targets undeformed to slightly deformed evaporite successions, outcropping and buried diapirs, evaporite-cored anticlines, evaporite-detached thrusts, and allochthonous evaporite bodies. collated data include information about the structure, stratigraphy, event chronology, surface and subsurface data availability, mining activity, and key bibliographic references. the iesdb follows the fair principles of database management (findable, accessible, interoperable, and reusable) and is presented as an interactive web page and an open-access database, where indexed structures can easily be selected from a map or browser and filtered by a search engine. the iesdb intends to be a useful resource for teaching (i.e. pointing out examples of exceptional evaporite outcrops), academic and industry research (i.e. identifying knowledge deficits on specific structures or tectonic settings), and for the sustainable exploration and appraisal of mineral resources and geo-energy applications (i.e. representing a terminus a quo for site selection and suitability assessment). the framework provided by the iesdb is an opportunity to enhance the scientific research on iberian evaporite structures in spain and portugal and to take advantage of their scientific and economic potential to tackle important societal challenges faced by these countries. the iesdb is freely available at https://iesdb.eu (last access: 15 june 2023) and the datasets can be downloaded from  (gonzalez-esvertit et al., 2022).",AB_0487
