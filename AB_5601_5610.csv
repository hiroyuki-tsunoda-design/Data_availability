AB,NO
"motion tracking is a widely used image processing technique, where the goal is to follow and register the movement of specified objects over time, from video recordings. thanks to the development of optical devices and tracking algorithms, the popularity of the method among researchers is continuously growing in a rich area of applications. despite the interest, there is currently no free and open-source motion tracking software, which can satisfy the growing demands of the scientific community for engineering applications. this paper introduces motion tracker beta: a gui based open-source motion tracking application. with multiple implemented tracking algorithms, the possibility of multi-object, rotation or size change tracking and a diverse set of numerical differentiation methods for velocity and acceleration calculations, the aim of the software is to facilitate motion analysis in various research areas. the software and the source code are available at https://github.com/flochkristof/motiontracker.& copy; 2023 the author(s). published by elsevier b.v. this is an open access article under the cc by license ().",AB_0561
"prognostic scales may help to optimize the use of hospital resources, which may be of prime interest in the context of a fast spreading pandemics. nonetheless, such tools are underdeveloped in the context of covid-19. in the present article we asked whether accurate prognostic scales could be developed to optimize the use of hospital resources. we retrospectively studied 467 files of hospitalized patients after covid-19. the odds ratios for 16 different biomarkers were calculated, those that were significantly associated were screened by a pearson's correlation, and such index was used to establish the mathematical function for each marker. the scales to predict the need for hospitalization, intensive-care requirement and mortality had enhanced sensitivities (0.91 ci 0.87-0.94; 0.96 ci 0.94-0.98; 0.96 ci 0.94-0.98; all with p < 0.0001) and specificities (0.74 ci 0.62-0.83; 0.92 ci 0.87-0.96 and 0.91 ci 0.86-0.94; all with p < 0.0001). interestingly, when a different population was assayed, these parameters did not change considerably. these results show a novel approach to establish the mathematical function of a marker in the development of highly sensitive prognostic tools, which in this case, may aid in the optimization of hospital resources. an online version of the three algorithms can be found at: http://benepachuca.no-.ip.org/covid/index.php",AB_0561
"diana-mirpath is an online mirna analysis platform harnessing predicted or experimentally supported mirna interactions towards the exploration of combined mirna effects. in its latest version (v4.0, http://www.microrna.gr/mirpathv4), diana-mirpath breaks new ground by introducing the capacity to tailor its target-based mirna functional analysis engine to specific biological and/or experimental contexts. via a redesigned modular interface with rich interaction, annotation and parameterization options, users can now perform enrichment analysis on gene ontology (go) terms, kegg and reactome pathways, sets from molecular signatures database (msigdb) and pfam. included mirna interaction sets are derived from state-of-the-art resources of experimentally supported (diana-tarbase v8.0, mirtarbase and microclip cell-type-specific interactions) or from in silico mirna-target interactions (updated diana-microt-cds and targetscan predictions). bulk and single-cell expression datasets from the cancer genome atlas (tcga), the genotype-tissue expression project (gtex) and adult/fetal single-cell atlases are integrated and can be used to assess the expression of enriched term components across a wide range of states. a discrete module enabling enrichment analyses using crispr knock-out screen datasets enables the detection of selected mirnas with potentially crucial roles within conditions under study. notably, the option to upload custom interaction, term, expression and screen sets further expands the versatility of mirpath webserver. [graphics] .",AB_0561
"objective the focus of this modified delphi study was to investigate and build consensus regarding the medical management of children with moderate and severe acute spinal cord injury (sci) during their initial inpatient hospital-ization. this impetus for the study was based on the aans/cns guidelines for pediatric sci published in 2013, which indicated that there was no consensus provided in the literature describing the medical management of pediatric patients with scis.methods an international, multidisciplinary group of 19 physicians, including pediatric neurosurgeons, orthopedic sur-geons, and intensivists, were asked to participate. the authors chose to include both complete and incomplete injuries with traumatic as well as iatrogenic etiologies (e.g., spinal deformity surgery, spinal traction, intradural spinal surgery, etc.) due to the overall low incidence of pediatric sci, potentially similar pathophysiology, and scarce literature exploring whether different etiologies of sci should be managed differently. an initial survey of current practices was administered, and based on the responses, a follow-up survey of potential consensus statements was distributed. consensus was defined as & ge; 80% of participants reaching agreement on a 4-point likert scale (strongly agree, agree, disagree, strongly disagree). a final meeting was held virtually to generate final consensus statements. results following the final delphi round, 35 statements reached consensus after modification and consolidation of previous statements. statements were categorized into the following eight sections: inpatient care unit, spinal immobili-zation, pharmacological management, cardiopulmonary management, venous thromboembolism prophylaxis, genitouri-nary management, gastrointestinal/nutritional management, and pressure ulcer prophylaxis. all participants stated that they would be willing or somewhat willing to change their practices based on consensus guidelines.conclusions general management strategies were similar for both iatrogenic (e.g., spinal deformity, traction, etc.) and traumatic scis. steroids were recommended only for injury after intradural surgery, not after acute traumatic or iat-rogenic extradural surgery. consensus was reached that mean arterial pressure ranges are preferred for blood pressure targets following sci, with goals between 80 and 90 mm hg for children at least 6 years of age. further multicenter study of steroid use following acute neuromonitoring changes was recommended. https://thejns.org/doi/abs/10.3171/2023.1.spine221188",AB_0561
"computing the shortest path between two points or a set of points on a point cloud representing a manifold is a crucial problem in computational science, particularly in computer graphics and cad/cam. most methods calculate geodesic paths on a polygonal model of the manifold, while only a few compute them directly on the point cloud. when the point cloud has noise, constructing a triangular mesh is challenging and results in inaccurate geodesic path calculations. this work calculates the geodesic path by minimizing the discrete geodesic curvature of the connecting curve, using an iterative newton minimization and a projection procedure based on directed point-projection and gabriel neighborhoods. the proposed algorithm has quadratic convergence and produces accurate results in synthetic and free-form point clouds, outperforming triangle mesh-based methods in noisy point clouds. the paper concludes with a demonstration of geodesic path computation in diverse freeform point-clouds and a case study in template-based digital surface reconstruction. the source code of the proposed method can be found in https://github.com/agalex1974/libgeodesicoppgc.& copy; 2023 elsevier ltd. all rights reserved.",AB_0561
"this paper introduces a new bio-inspired metaheuristic algorithm called walrus optimization algorithm (waoa), which mimics walrus behaviors in nature. the fundamental inspirations employed in waoa design are the process of feeding, migrating, escaping, and fighting predators. the waoa implementation steps are mathematically modeled in three phases exploration, migration, and exploitation. sixty-eight standard benchmark functions consisting of unimodal, high-dimensional multimodal, fixed-dimensional multimodal, cec 2015 test suite, and cec 2017 test suite are employed to evaluate waoa performance in optimization applications. the optimization results of unimodal functions indicate the exploitation ability of waoa, the optimization results of multimodal functions indicate the exploration ability of waoa, and the optimization results of cec 2015 and cec 2017 test suites indicate the high ability of waoa in balancing exploration and exploitation during the search process. the performance of waoa is compared with the results of ten well-known metaheuristic algorithms. the results of the simulations demonstrate that waoa, due to its excellent ability to balance exploration and exploitation, and its capacity to deliver superior results for most of the benchmark functions, has exhibited a remarkably competitive and superior performance in contrast to other comparable algorithms. in addition, the use of waoa in addressing four design engineering issues and twenty-two real-world optimization problems from the cec 2011 test suite demonstrates the apparent effectiveness of waoa in real-world applications. the matlab codes of waoa are available in https://uk.mathworks.com/matlabcentral/profile/authors/13903104.",AB_0561
"we study the nodal set of laplace eigenfunctions on the flat 2d torus t-2. we prove an asymptotic law for the nodal length of such eigenfunctions, under some growth assumptions on their fourier coefficients. moreover, we show that their nodal set is asymptotically equidistributed on t-2. the proofs are based on bourgain's de randomisation technique and the main new ingredient, which might be of independent interest, is the integrability of arbitrarily large powers of the doubling index of laplace eigenfunctions on t-2, based on the work of nazarov (algebra anal 5:3-66, 1993; summability of large powers of logarithm of classic lacunary series and its simplest consequences https://users.math.msu.edu/users/fedja/prepr.html, 1995).",AB_0561
"objective: to demonstrate and develop an approach enabling individual researchers or small teams to create their own ad-hoc, lightweight knowledge bases tailored for specialized scientific interests, using text-mining over scientific literature, and demonstrate the effectiveness of these knowledge bases in hypothesis generation and literature-based discovery (lbd). methods: we propose a lightweight process using an extractive search framework to create ad-hoc knowledge bases, which require minimal training and no background in bio-curation or computer science. these knowledge bases are particularly effective for lbd and hypothesis generation using swanson's abc method. the person-alized nature of the knowledge bases allows for a somewhat higher level of noise than public facing ones, as researchers are expected to have prior domain experience to separate signal from noise. fact verification is shifted from exhaustive verification of the knowledge base to post-hoc verification of specific entries of interest, allowing researchers to assess the correctness of relevant knowledge base entries by considering the paragraphs in which the facts were introduced.results: we demonstrate the methodology by constructing several knowledge bases of different kinds: three knowledge bases that support lab-internal hypothesis generation: drug delivery to ovarian tumors (ddot); tissue engineering and regeneration; challenges in cancer research; and an additional comprehensive, accurate knowledge base designated as a public resource for the wider community on the topic of cell specific drug delivery (csdd). in each case, we show the design and construction process, along with relevant visualizations for data exploration, and hypothesis generation. for csdd and ddot we also show meta-analysis, human evaluation, and in vitro experimental evaluation.conclusion: our approach enables researchers to create personalized, lightweight knowledge bases for specialized scientific interests, effectively facilitating hypothesis generation and literature-based discovery (lbd). by shifting fact verification efforts to post-hoc verification of specific entries, researchers can focus on exploring and generating hypotheses based on their expertise. the constructed knowledge bases demonstrate the versatility and adaptability of our approach to versatile research interests. the web-based platform, available at https://spike-k bc.apps.allenai.org, provides researchers with a valuable tool for rapid construction of knowledge bases tailored to their needs.",AB_0561
"in this paper we briefly review the finite-temperature thomas-fermi model for a mixture of elements and describe a number of modifications made for the new version (1.5) of the code. the model is intended for the calculation of thermodynamic properties of electrons in a mixture of elements. the modifications include density besides volume as an input parameter, switching off the calculation of thermal energy using the integration of heat capacity, more thermodynamic functions in the output including cold parts of thermodynamic functions and gruneizen parameter, the possibility to plot both isotherms and isochores in the graphical user interface and a lot of minor corrections. new version program summary program title: tfmix, version 1.5 cpc library link to program files: https://doi .org /10 .17632 /mc3vj77jfn .2 licensing provisions: gplv3 programming language: c, python supplementary materials: detailed description of revisions journal reference of previous version: comput. phys. commun. 235 (2019) 378, https://doi .org /10 .1016 /j . cpc .2018 .09 .008 does the new version supersede the previous version?: yes reasons for the new version: in our previous paper [1] we presented the model for the calculation of thermodynamic properties of electrons in a mixture of atoms based upon the finite-temperature thomas-fermi model (fttf) [2]. the model was implemented in the form of a computer code tfmix v. 1.0 that can be launched from both a command line and a simple graphical user interface. the guaranteed accuracy of all thermodynamic functions including second derivatives of helmholtz free energy was the main unique feature of the code. in [1] we also announced a number of modifications which would be useful for the users of the code. in this paper we present the new version of the tfmix code (v. 1.5) in which the announced modifications and some new features have been implemented. summary of revisions: modifications to the tfmix code: & bull; a special command line argument-e has been added to switch off the calculation of thermal energy using the integration of isochoric heat capacity; simple subtraction of the cold contribution is used instead. this leads to much faster calculations with the penalty of uncontrolled accuracy for thermal energy. & bull; one more parameter has been introduced to the input file to indicate that density is used as an input parameter instead of volume. & bull; cold parts of some thermodynamic functions have been added to the output: energy, chemical potential, (8 f /8 v)t and (82f /8 v2)t at t = 0. & bull; two additional thermodynamic functions have been added to the output: chemical potential & mu; and gruneizen parameter v (8 p /8 e)v. & bull; the derivatives (82f /8 t2)v for the mixture components have been added to the output. modifications to the gui:",AB_0561
"estimating t2 relaxation time distributions from multi-echo t2-weighted mri (t2w) data can provide valuable biomarkers for assessing inflammation, demyelination, edema, and cartilage composition in various patholo-gies, including neurodegenerative disorders, osteoarthritis, and tumors. deep neural network (dnn) based methods have been proposed to address the complex inverse problem of estimating t2 distributions from mri data, but they are not yet robust enough for clinical data with low signal-to-noise ratio (snr) and are highly sensitive to distribution shifts such as variations in echo-times (te) used during acquisition. consequently, their application is hindered in clinical practice and large-scale multi-institutional trials with heterogeneous acquisition protocols. we propose a physically-primed dnn approach, called p2t2, that incorporates the signal decay forward model in addition to the mri signal into the dnn architecture to improve the accuracy and robustness of t2 distribution estimation. we evaluated our p2t2 model in comparison to both dnn-based methods and classical methods for t2 distribution estimation using 1d and 2d numerical simulations along with clinical data. our model improved the baseline model's accuracy for low snr levels (snr < 80) which are common in the clinical setting. further, our model achieved a & sim;35% improvement in robustness against distribution shifts in the acquisition process compared to previously proposed dnn models. finally, our p2t2 model produces the most detailed myelin-water fraction maps compared to baseline approaches when applied to real human mri data. our p2t2 model offers a reliable and precise means of estimating t2 distributions from mri data and shows promise for use in large-scale multi-institutional trials with heterogeneous acquisition protocols. our source code is available at: https://github.com/hben-atya/p2t2-robust-t2-estimation.git.",AB_0561
