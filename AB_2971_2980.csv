AB,NO
"visible-infrared person re-identification (vi-reid) conducts comprehensive identity analysis on non-overlapping visible and infrared camera sets for intelligent surveillance systems, which face huge instance variations derived from modality discrepancy. existing methods employ different kinds of network structure to extract modality-invariant features. differently, we propose a novel framework, named dual-semantic consistency learning network (dscnet), which attributes modality discrepancy to channel-level semantic inconsistency. dscnet optimizes channel consistency from two aspects, fine-grained inter-channel semantics, and comprehensive inter-modality semantics. furthermore, we propose joint semantics metric learning to simultaneously optimize the distribution of the channel-and-modality feature embeddings. it jointly exploits the correlation between channel-specific and modality-specific semantics in a fine-grained manner. we conduct a series of experiments on the sysu-mm01 and regdb datasets, which validates that dscnet delivers superiority compared with current state-of-the-art methods. on the more challenging sysu-mm01 dataset, our network can achieve 73.89% rank-1 accuracy and 69.47% map value. our code is available at https://github.com/bitreidgroup/dscnet.",AB_0298
"medical image report generation (meirg) aims at generating associated diagnosis descriptions with natural language sentences from medical images, which is essential in the computer-aided diagnosis system. nevertheless, this task remains challenging in that medical images and linguistic expressions should be understood jointly which however show great discrepancies in the modality. to fill this visual-to-semantic gap, we propose a novel framework that follows the encoder-decoder pipeline. our framework is characterized by encoding both deep visual and semantic embeddings through a triple-branch network (trinet) during the encoding phase. the visual attention branch captures attended visual embeddings from medical images with the soft-attention mechanism. the medical report (merp) embedding branch predicts semantic report embeddings. the embedding branch of medical subject headings (mesh) obtains semantic embeddings of related medical tags as complementary information. then, outputs of these branches are fused and fed into a decoder for the report generation. experimental results on two benchmark datasets have demonstrated the excellent performance of our method. related codes are available at https://github.com/yangyan22/medical-report-generation-trinet.",AB_0298
"gait recognition has a rapid development in recent years. however, current gait recognition focuses primarily on ideal laboratory scenes, leaving the gait in the wild unexplored. one of the main reasons is the difficulty of collecting in-the-wild gait datasets, which must ensure diversity of both intrinsic and extrinsic human gait factors. to remedy this problem, we propose to construct a large-scale gait dataset with the help of controllable computer simulation. in detail, to diversify the intrinsic factors of gait, we generate numerous characters with diverse attributes and associate them with various types of walking styles. to diversify the extrinsic factors of gait, we build a complicated scene with a dense camera layout. then we design an automatic generation toolkit under unity3d for simulating the walking scenarios and capturing the gait data. as a result, we obtain a dataset simulating towards the in-the-wild scenario, called versatilegait, which has more than one million silhouette sequences of 10,000 subjects with diverse scenarios. versatilegait possesses several nice properties, including huge dataset size, diverse pedestrian attributes, complicated camera layout, high-quality annotations, small domain gap with the real one, good scalability for new demands, and no privacy issues. by conducting a series of experiments, we first explore the effects of different factors on gait recognition. we further illustrate the effectiveness of using our dataset to pre-train models, which obtain considerable performance gain on casia-b, ou-mvlp, and casia-e. besides, we show the great potential of the fine-grained labels other than the id label in improving the efficiency and effectiveness of models. our dataset and its corresponding generation toolkit are available at https://github.com/peterzpy/versatilegait.",AB_0298
"for the task of autonomous indoor parking, various visual-inertial simultaneous localization and mapping (slam) systems are expected to achieve comparable results with the benefit of complementary effects of visual cameras and the inertial measurement units. to compare these competing slam systems, it is necessary to have publicly available datasets, offering an objective way to demonstrate the pros/cons of each slam system. however, the availability of such high-quality datasets is surprisingly limited due to the profound challenge of the groundtruth trajectory acquisition in the global positioning satellite denied indoor parking environments. in this article, we establish bevis, a large-scale benchmark dataset with visual (front-view), i nertial and surround-view sensors for evaluating the performance of slam systems developed for autonomous indoor parking, which is the first of its kind where both the raw data and the groundtruth trajectories are available. in bevis, the groundtruth trajectories are obtained by tracking artificial landmarks scattered in the indoor parking environments, whose coordinates are recorded in a surveying manner with a high-precision electronic total station. moreover, the groundtruth trajectories are comprehensively evaluated in terms of two respects, the reprojection error and the pose volatility, respectively. apart from bevis, we propose a novel tightly coupled semantic slam framework, namely visslam-2, leveraging visual (frontview), i nertial, and surround-view sensor modalities, specially for the task of autonomous indoor parking. it is the first work attempting to provide a general form to model various semantic objects on the ground. experiments on bevis demonstrate the effectiveness of the proposed visslam-2. our benchmark dataset bevis is publicly available at https://shaoxuan92.github.io/bevis.",AB_0298
"infrared tiny ship detection aims at separating tiny ships from the images captured by earth orbiting satellites. due to the extremely large image coverage area (e.g., thousands of square kilometers), candidate targets in these images are much smaller, dimer, and more changeable than those targets observed by aerial-and land-based imaging devices. existing short imaging distance-based infrared datasets and target detection methods cannot be well adopted to the space-based surveillance task. to address these problems, we develop a space-based infrared tiny ship detection dataset (namely, nudt-sirst-sea) with 48 space-based infrared images and 17 598 pixel-level tiny ship annotations. each image covers about 10 000 km2 of area with 10 000 x 10 000 pixels. considering the extreme characteristics (e.g., small, dim, and changeable) of those tiny ships in such challenging scenes, we propose a multilevel transunet (mtu-net) in this article. specifically, we design a vision transformer (vit) convolutional neural network (cnn) hybrid encoder to extract multilevel features. local feature maps are first extracted by several convolution layers and then fed into the multilevel feature extraction module [multilevel vit module (mvtm)] to capture long-distance dependency. we further propose a copy-rotate-resize-paste (crrp) data augmentation approach to accelerate the training phase, which effectively alleviates the issue of sample imbalance between targets and background. besides, we design a focaliou loss to achieve both target localization and shape description. experimental results on the nudt-sirst-sea dataset show that our mtu-net outperforms traditional and existing deep learning-based single-frame infrared small target (sirst) methods in terms of probability of detection, false alarm rate, and intersection over union. our code is available at https://github.com/tianhaowu16/multilevel-transunet-for-space-based-infrared-tiny-ship-detection",AB_0298
"pan-sharpening aims to super-solve low-spatial resolution multiple spectral (ms) images with the guidance of high-resolution (hr) texture-rich panchromatic (pan) images. recently, deep-learning-based pan-sharpening approaches have dominated this field and achieved remarkable advancement. however, most promising algorithms are devised in one-way mapping and have not fully explored the mutual dependencies between pan and ms modalities, thus impacting the model performance. to address this issue, we propose a novel information compensation and integration network for pan-sharpening by effective cross-modality joint learning in this work. first, the cross-central difference convolution is employed to explicitly extract the texture details of the pan images. second, we implement the compensation process by imitating the classical back-projection (bp) technique where the extracted pan textures are employed to guide the intrinsic information learning of ms images iteratively. subsequently, we devise the hierarchical transformer to integrate the comprehensive relations of stage-iteration information from spatial and temporal contexts. extensive experiments over multiple satellite datasets demonstrate the superiority of our method to the existing state-of-the-art methods. the source code is available at https://github.com/manman1995/pansharpening.",AB_0298
"blockchain smart contracts have given rise to a variety of interesting and compelling applications and emerged as a revolutionary force for the internet. smart contracts from various fields now hold over one trillion dollars worth of virtual coins, attracting numerous attacks. quite a few practitioners have devoted themselves to developing tools for detecting bugs in smart contracts. one line of efforts revolve around static analysis techniques, which heavily suffer from high false positive rates. another line of works concentrate on fuzzing techniques. unfortunately, current fuzzing approaches for smart contracts tend to conduct fuzzing starting from the initial state of the contract, which expends too much energy revolving around the initial state of the contract and thus is usually unable to unearth bugs triggered by other states. moreover, most existing methods treat each branch equally, failing to take care of the branches that are rare or more likely to possess bugs. this might lead to resources wasted on normal branches. in this paper, we try to tackle these challenges from three aspects: 1) generating function invocation sequences, we explicitly consider data dependencies between functions to facilitate exploring richer states. we further prolong a function invocation sequence s-1 by appending a new sequence $\mathcal s-2, so that the appended sequence s-2 can start fuzzing from states that are different from the initial state; 2) we incorporate a branch distance-based measure to evolve test cases iteratively towards a target branch; 3) we engage a branch search algorithm to discover rare and vulnerable branches, and design an energy allocation mechanism to take care of exercising these crucial branches. we implement ir-fuzz and extensively evaluate it over 12k real-world contracts. empirical results show that: (i) ir-fuzz achieves 28% higher branch coverage than state-of-the-art fuzzing approaches, (ii) ir-fuzz detects more vulnerabilities and increases the average accuracy of vulnerability detection by 7% over current methods, and (iii) ir-fuzz is fast, generating an average of 350 test cases per second. our implementation and dataset are released at https://github.com/messi-q/ir-fuzz, hoping to facilitate future research.",AB_0298
"deep learning-based algorithms have greatly improved the performance of remote sensing image (rsi) super-resolution (sr). however, increasing network depth and parameters cause a huge burden of computing and storage. directly reducing the depth or width of existing models results in a large performance drop. we observe that the sr difficulty of different regions in an rsi varies greatly, and existing methods use the same deep network to process all regions in an image, resulting in a waste of computing resources. in addition, existing sr methods generally predefine integer scale factors and cannot perform stepless sr, i.e., a single model can deal with any potential scale factor. retraining the model on each scale factor wastes considerable computing resources and model storage space. to address the above problems, we propose a saliency-aware dynamic routing network (saldrn) for lightweight and stepless sr of rsis. first, we introduce visual saliency as an indicator of region-level sr difficulty and integrate a lightweight saliency detector into the saldrn to capture pixel-level visual characteristics. then, we devise a saliency-aware dynamic routing strategy that employs path selection switches to adaptively select feature extraction paths of appropriate depth according to the sr difficulty of subimage patches. finally, we propose a novel lightweight stepless upsampling module whose core is an implicit feature function for realizing mapping from low-resolution feature space to high-resolution feature space. comprehensive experiments verify that the saldrn can achieve a good tradeoff between performance and complexity. the code is available at https://github.com/hanlinwu/saldrn.",AB_0298
"the joint hyperspectral image (hsi) and light detection and ranging (lidar) data classification aims to interpret ground objects at more detailed and precise level. although deep learning methods have shown remarkable success in the multisource data classification task, self-supervised learning has rarely been explored. it is commonly nontrivial to build a robust self-supervised learning model for multisource data classification, due to the fact that the semantic similarities of neighborhood regions are not exploited in the existing contrastive learning framework. furthermore, the heterogeneous gap induced by the inconsistent distribution of multisource data impedes the classification performance. to overcome these disadvantages, we propose a nearest neighbor-based contrastive learning network (nncnet), which takes full advantage of large amounts of unlabeled data to learn discriminative feature representations. specifically, we propose a nearest neighbor-based data augmentation scheme to use enhanced semantic relationships among nearby regions. the intermodal semantic alignments can be captured more accurately. in addition, we design a bilinear attention module to exploit the second-order and even high-order feature interactions between the hsi and lidar data. extensive experiments on four public datasets demonstrate the superiority of our nncnet over state-of-the-art methods. the source codes are available at https://github.com/summitgao/nncnet.",AB_0298
"hyperspectral image (hsi) classification aims at predicting the pixel-wise labels in an image, where there are only a few labeled pixel samples (hard labels) for training. it is a challenging task since the classification process is susceptible to over-fitting under training with limited samples. to relieve this problem, we propose a method based on dual hierarchical learning. first, we employ a connectionist hyperspectral convolution (hc) network to capture the representations of the pixels from different receptive fields. specifically, an hc is designed to learn the correlation among adjacent pixels and is further extended to a connectionist hierarchical structure. these operations use the correlation to enhance one-pixel learning from multiple receptive fields. second, we analyze the properties in the hyperspectral image and introduce a hierarchical pseudo label generation algorithm to enrich the supervision of the label information. finally, we design a dual hierarchical learning strategy to help all hc layers learn from both the hard labels and the hierarchical pseudo labels. in other words, it addresses the hsi classification problem from different views. for inference, we employ two fusion strategies to find a better prediction. the experimental results on four popular hsi benchmarks, i.e., salinas-a, indianpines, paviau, and paviac, demonstrate the effectiveness of the proposed method. our code is publicly available on github: https://github.com/shuowangcs/hsi-dhl.",AB_0298
