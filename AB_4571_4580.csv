AB,NO
"background:the victoria trial (vericiguat global study in subjects with heart failure with reduced ejection fraction) demonstrated that, in patients with high-risk heart failure, vericiguat reduced the primary composite outcome of cardiovascular death or heart failure hospitalization relative to placebo. the hazard ratio for all-cause mortality was 0.95 (95% ci, 0.84-1.07). in a prespecified analysis, treatment effects varied substantially as a function of baseline nt-probnp (n-terminal pro-b-type natriuretic peptide) levels, with survival benefit for vericiguat in the lower nt-probnp quartiles (hazard ratio, 0.82 [95% ci, 0.69-0.97]) and no benefit in the highest nt-probnp quartile (hazard ratio, 1.14 [95% ci, 0.95-1.38]). an economic analysis was a major secondary objective of the victoria research program.methods:medical resource use data were collected for all victoria patients (n=5050). costs were estimated by applying externally derived us cost weights to resource use counts. life expectancy was projected from patient-level empirical trial survival results with the use of age-based survival modeling methods. quality-of-life adjustments were based on prospectively collected eq-5d-based utilities. the primary outcome was the incremental cost-effectiveness ratio, comparing vericiguat with placebo, assessed from the us health care sector perspective over a lifetime horizon. cost-effectiveness was estimated using the total victoria cohort, both with and without interaction between treatment and baseline nt-probnp.results:life expectancy modeling results varied according to whether the observed heterogeneity of treatment effect by baseline nt-probnp values was incorporated into the modeling. including the interaction term, the vericiguat arm had an estimated quality-adjusted life expectancy of 4.56 quality-adjusted life-years (qalys) compared with 4.13 qalys for placebo (incremental discounted qaly, 0.43). without the treatment heterogeneity/interaction term, vericiguat had 4.50 qalys compared with 4.33 qalys for placebo (incremental discounted qaly, 0.17). incremental discounted costs (vericiguat minus placebo) were $28 546 with the treatment interaction and $20 948 without it. corresponding incremental cost-effectiveness ratios were $66 509 per qaly allowing for treatment heterogeneity and $124 512 without heterogeneity.conclusions:vericiguat use in the victoria trial met criteria for intermediate value, but the incremental cost-effectiveness ratio estimates were sensitive to whether the analysis accounted for observed nt-probnp treatment effect heterogeneity. the cost-effectiveness of vericiguat was driven by the projected incremental life expectancy among patients in the lowest 3 quartiles of nt-probnp.registration:url: https://www.clinicaltrials.gov; unique identifier: nct02861534.",AB_0458
"backgroundthis update summarizes key changes made to the protocol for the frequency of screening and spontaneous breathing trial (sbt) technique trial-north american weaning collaborative (fast-nawc) trial since the publication of the original protocol. this multicenter, factorial design randomized controlled trial with concealed allocation, will compare the effect of both screening frequency (once vs. at least twice daily) to identify candidates to undergo a sbt and sbt technique [pressure support + positive end-expiratory pressure vs. t-piece] on the time to successful extubation (primary outcome) in 760 critically ill adults who are invasively ventilated for at least 24 h in 20 north american intensive care units.methods/designprotocols for the pilot, factorial design trial and the full trial were previously published in j clin trials () and trials (https://doi: 10.1186/s13063-019-3641-8). as planned, participants enrolled in the fast pilot trial will be included in the report of the full fast-nawc trial. in response to the onset of the coronavirus disease of 2019 (covid-19) pandemic when approximately two thirds of enrollment was complete, we revised the protocol and consent form to include critically ill invasively ventilated patients with covid-19. we also refined the statistical analysis plan (sap) to reflect inclusion and reporting of participants with and without covid-19. this update summarizes the changes made and their rationale and provides a refined sap for the fast-nawc trial. these changes have been finalized before completion of trial follow-up and the commencement of data analysis.trial registrationclinical trials.gov nct02399267.",AB_0458
"core-collapse supernova explosions play a wide role in astrophysics by producing compact remnants (neutron stars or black holes) and the synthesis and injection of many heavy elements into their host galaxy. because they are produced in some of the most extreme conditions in the universe, they can also probe physics in extreme conditions (matter at nuclear densities and extreme temperatures and magnetic fields). to quantify the impact of supernovae on both fundamental physics and our understanding of the universe, we must leverage a broad set of observables of this engine. in this paper, we study a subset of these probes using a suite of one-dimensional, parameterized mixing models: ejecta remnants from supernovae, ultraviolet, optical and infrared light curves, and transient gamma-ray emission. we review the other diagnostics and show how the different probes tie together to provide a more clear picture of the supernova engine. join us in improving and evolving this document through active community engagement. instructions are provided at this link: https://github.com/clfryer/mm-sne.",AB_0458
"lexical and semantic matching capture different successful approaches to text retrieval and the fusion of their results has proven to be more effective and robust than either alone. prior work performs hybrid retrieval by conducting lexical and semantic matching using different systems (e.g., lucene and faiss, respectively) and then fusing their model outputs. in contrast, our work integrates lexical representations with dense semantic representations by densifying high-dimensional lexical representations into what we call low-dimensional dense lexical representations (dlrs). our experiments show that dlrs can effectively approximate the original lexical representations, preserving effectiveness while improving query latency. furthermore, we can combine dense lexical and semantic representations to generate dense hybrid representations (dhrs) that are more flexible and yield faster retrieval compared to existing hybrid techniques. in addition, we explore jointly training lexical and semantic representations in a single model and empirically show that the resulting dhrs are able to combine the advantages of the individual components. our best dhr model is competitive with state-of-the-art single-vector and multi-vector dense retrievers in both in-domain and zero-shot evaluation settings. furthermore, our model is both faster and requires smaller indexes, making our dense representation framework an attractive approach to text retrieval. our code is available at https://github.com/castorini/dhr.",AB_0458
"background: we often must conduct diagnostic tests on a massive volume of samples within a limited time during outbreaks of infectious diseases (e.g., covid-19,screening) or repeat many times routinely (e.g., regular and massive screening for plant virus infections in farms). these tests aim to obtain the diagnostic result of all samples within a limited time. in such scenarios, the limitation of testing resources and human labor drives the need to pool individual samples and test them together to improve testing efficiency. when a pool is positive, further testing is required to identify the affected individuals; whereas when a pool is negative, we conclude all individuals in the pool are negative. how one splits the samples into pools is a critical factor affecting testing efficiency. objective: we aim to find the optimal strategy that adaptively guides users on optimally splitting the sample cohort into test-pools. methods: we developed an algorithm that minimizes the expected number of tests needed to obtain the diagnostic results of all samples. our algorithm dynamically updates the critical information according to the result of the most recent test and calculates the optimal pool size for the next test. we implemented our novel adaptive sample pooling strategy into a web-based application, adsp (https://adsp.uvic.ca). adsp interactively guides users on how many samples to be pooled for the current test, asks users to report the test result back and uses it to update the best strategy on how many samples to be pooled for the next test. results: we compared adsp with other popular pooling methods in simulation studies, and found that adsp requires fewer tests to diagnose a cohort and is more robust to the inaccurate initial estimate of the test cohort's disease prevalence. conclusion: our web-based application can help researchers decide how to pool their samples for grouped diagnostic tests. it improves test efficiency when grouped tests are conducted.",AB_0458
"it is commonly accepted that the prion replicative propensity and strain structural determinant (ssd) are encoded in the fold of prpsc amyloid fibril assemblies. by exploring the quaternary structure dynamicity of several prion strains, we revealed that all mammalian prion assemblies exhibit the generic property of spontaneously generating two sets of discreet infectious tetrameric and dimeric species differing significantly by their specific infectivity. by using perturbation approaches such as dilution and ionic strength variation, we demonstrated that these two oligomeric species were highly dynamic and evolved differently in the presence of chaotropic agents. in general, our observations of seven different prion strains from three distinct species highlight the high dynamicity of prpsc assemblies as a common and intrinsic property of mammalian prions. the existence of such small infectious prpsc species harboring the ssd indicates that the prion infectivity and the ssd are not restricted only to the amyloid fold but can also be encoded in other alternative quaternary structures. such diversity in the quaternary structure of prion assemblies tends to indicate that the structure of prpsc can be divided into two independent folding domains: a domain encoding the strain structural determinant and a second domain whose fold determines the type of quaternary structure that could adopt prpsc assemblies.(c) 2023 the author(s). published by elsevier ltd. this is an open access article under the cc by-nc-nd license (http://crea-tivecommons.org/licenses/by-nc-nd/4.0/).",AB_0458
"the performance of learning-based algorithms improves with the amount of labelled data used for training. yet, manually annotating data is particularly difficult for medical image segmentation tasks because of the limited expert availability and intensive manual effort required. to reduce manual labelling, active learning (al) targets the most informative samples from the unlabelled set to annotate and add to the labelled training set. on the one hand, most active learning works have focused on the classification or limited segmentation of natural images, despite active learning being highly desirable in the difficult task of medical image segmentation. on the other hand, uncertainty-based al approaches notoriously offer sub-optimal batch-query strategies, while diversity-based methods tend to be computationally expensive. over and above methodological hurdles, random sampling has proven an extremely difficult baseline to outperform when varying learning and sampling conditions. this work aims to take advantage of the diversity and speed offered by random sampling to improve the selection of uncertainty-based al methods for segmenting medical images. more specifically, we propose to compute uncertainty at the level of batches instead of samples through an original use of stochastic batches (sb) during sampling in al. stochastic batch querying is a simple and effective addon that can be used on top of any uncertainty-based metric. extensive experiments on two medical image segmentation datasets show that our strategy consistently improves conventional uncertainty-based sampling methods. our method can hence act as a strong baseline for medical image segmentation. the code is available on: https://github.com/minimel/stochasticbatchal.git.",AB_0458
"backgroundthis study hypothesized that patients with extubation failure exhibit a loss of lung aeration and heterogeneity in air distribution, which could be monitored by chest eit and lung ultrasound. patients at risk of extubation failure were included after a successful spontaneous breathing trial. lung ultrasound [with calculation of lung ultrasound score (lus)] and chest eit [with calculation of the global inhomogeneity index, frontback center of ventilation (cov), regional ventilation delay (rvd) and surface available for ventilation] were performed before extubation during pressure support ventilation (h0) and two hours after extubation during spontaneous breathing (h2). eit was then repeated 6 h (h6) after extubation. eit derived indices and lus were compared between patients successfully extubated and patients with extubation failure.results40 patients were included, of whom 12 (30%) failed extubation. before extubation, when compared with patients with successful extubation, patients who failed extubation had a higher lus (19 vs 10, p = 0.003) and a smaller surface available for ventilation (352 vs 406 pixels, p = 0.042). after extubation, gi index and lus were higher in the extubation failure group, whereas the surface available for ventilation was lower. the rvd and the cov were not different between groups.conclusionbefore extubation, a loss of lung aeration was observed in patients who developed extubation failure afterwards. after extubation, this loss of lung aeration persisted and was associated with regional lung ventilation heterogeneity.trial registration clinical trials, nct04180410, registered 27 november 2019-prospectively registered, https://clinicaltrials.gov/ct2/show/nct04180410.conclusionbefore extubation, a loss of lung aeration was observed in patients who developed extubation failure afterwards. after extubation, this loss of lung aeration persisted and was associated with regional lung ventilation heterogeneity.trial registration clinical trials, nct04180410, registered 27 november 2019-prospectively registered, https://clinicaltrials.gov/ct2/show/nct04180410.",AB_0458
"cell size and cell count are adaptively regulated and intimately linked to growth and function. yet, despite their widespread relevance, the relation between cell size and count has never been formally examined over the whole human body. here, we com-pile a comprehensive dataset of cell size and count over all major cell types, with data drawn from >1,500 published sources. we consider the body of a representative male (70 kg), which allows further estimates of a female (60 kg) and 10 -y -old child (32 kg). we build a hierarchical interface for the cellular organization of the body, giving easy access to data, methods, and sources (https://humancelltreemap.mis.mpg.de/). in total, we estimate total body counts of =36 trillion cells in the male, =28 trillion in the female, and =17 trillion in the child. these data reveal a surprising inverse relation between cell size and count, implying a trade -off between these variables, such that all cells within a given logarithmic size class contribute an equal fraction to the body's total cellular biomass. we also find that the coefficient of variation is approximately independent of mean cell size, implying the existence of cell-size regulation across cell types. our data serve to establish a holistic quantitative framework for the cells of the human body, and highlight large-scale patterns in cell biology.",AB_0458
"we present astrophot, a fast, powerful, and user-friendly python based astronomical image photometry solver. astrophot incorporates automatic differentiation and graphics processing unit (gpu), or parallel central processing unit (cpu), acceleration, powered by the machine learning library pytorch. everything: astrophot can fit models for sky, stars, galaxies, point spread functions (psfs), and more in a principled chi(2) forward optimization, recovering bayesian posterior information and covariance of all parameters. everywhere: astrophot can optimize forward models on cpu or gpu; across images that are large, multiband, multi-epoch, rotated, dithered, and more. all at once: the models are optimized together, thus handling overlapping objects and including the covariance between parameters (including psf and galaxy parameters). a number of optimization algorithms are available including levenberg-marquardt, gradient descent, and no-u-turn markov chain monte carlo sampling. with an object-oriented user interface, astrophot makes it easy to quickly extract detailed information from complex astronomical data for individual images or large survey programs. this paper outlines novel features of the astrophot code and compares it to other popular astronomical image modelling software. astrophot is open-source, fully python based, and freely accessible at https://github.com/autostronomy/astrophot .",AB_0458
