AB,NO
"deep learning-based semantic segmentation has been widely applied for building extraction. however, due to the domain gap, the extraction of building in high-resolution remote sensing imagery is difficult when the model trained on a source dataset is directly used to test on a target data. considering that humans can retrieve memory to deal with correlative tasks in different domains, memory mechanisms have been developed effectively to assist cross-domain feature extraction. besides, the effectiveness of memory mechanisms highly depends on the correlation of memory to the task. therefore, the domain-invariant memory is crucial in cross-domain building extraction task. to this end, a memory-contrastive unsupervised domain adaptation (da) method is proposed on the basis of a novel memory mechanism. specifically, to facilitate the model to memorize domain-invariant features, we first conduct a normalization-based image style transfer strategy and a discriminator-based adversarial method at the image level and feature level, respectively. subsequently, we carry out a memory-contrastive module to obtain domain-invariant features. especially, a teacher-student network is exploited to help knowledge transferring by knowledge distillation to enhance the performance of the memory-contracted (mcd) module. to narrow the distance between the two domains, a memory bank is designed to store and update category features obtained from the source domain, and then, the similarity between category features in the target domain and memory bank is calculated. results of the cross-domain experiments show that the proposed method can achieve optimal building extraction (github: https://github.com/rs-csu/mdanet).",AB_0299
"ship detection plays a crucial role in a variety of military and civilian marine inspection applications. infrared images are irreplaceable data sources for ship detection due to their strong adaptability and excellent all-weather reconnaissance ability. however, previous researches mainly focus on visible light or synthetic aperture radar (sar) ship detection, while infrared ship detection is left in a huge blind spot. the main obstacles to this dilemma lie in the absence of public datasets, small scale, and poor semantic information of infrared ships, and severe clutter in complex ocean environments. to address the above challenges, we propose a knowledge-driven context perception network (kcpnet) and construct a public dataset called infrared ship detection dataset (isdd). in kcpnet, aiming at the small scale of infrared ships, a balanced feature fusion network (bff-net) is proposed to balance information from all backbone layers and generate nonlocal features with balanced receptive fields. moreover, considering the key role of contextual information, a contextual attention network (ca-net) is designed to improve robustness in complex scenes by enhancing target and contextual information and suppressing clutter. inspired by prior knowledge of human cognitive processes, we construct a novel knowledge-driven prediction head to autonomously learn visual features and back-propagate the knowledge throughout the whole network, which can efficiently reduce false alarms. extensive experiments demonstrate that the proposed kcpnet achieves state-of-the-art performance on isdd. source codes and isdd are accessible at https://github.com/yaqihan-9898.",AB_0299
"multiview stereo (mvs) aerial image depth estimation is a research frontier in the remote sensing field. recent deep learning-based advances in close-range object reconstruction have suggested the great potential of this approach. meanwhile, the deformation problem and the scale variation issue are also worthy of attention. these characteristics of aerial images limit the applicability of the current methods for aerial image depth estimation. moreover, there are few available benchmark datasets for aerial image depth estimation. in this regard, this article describes a new benchmark dataset called the luojia-mvs dataset (https://irsip.whu.edu.cn/resources/resources_en_v2.php), as well as a new deep neural network known as the hierarchical deformable cascade mvs network (hdc-mvsnet). the luojia-mvs dataset contains 7972 five-view images with a spatial resolution of 10 cm, pixel-wise depths, and precise camera parameters, and was generated from an accurate digital surface model (dsm) built from thousands of stereo aerial images. in the hdc-mvsnet network, a new full-scale feature pyramid extraction module, a hierarchical set of 3-d convolutional blocks, and true 3-d deformable 3-d convolutional layers are specifically designed by considering the aforementioned characteristics of aerial images. overall and ablation experiments on the whu and luojia-mvs datasets validated the superiority of hdc-mvsnet over the current state-of-the-art mvs depth estimation methods and confirmed that the newly built dataset can provide an effective benchmark.",AB_0299
"in this paper, we tackle the problem of synthesizing a ground-view panorama image conditioned on a top-view aerial image, which is a challenging problem due to the large gap between the two image domains with different view-points. instead of learning cross-view mapping in a feedforward pass, we propose a novel adversarial feedback gan framework named panogan with two key components: an adversarial feedback module and a dual branch discrimination strategy. first, the aerial image is fed into the generator to produce a target panorama image and its associated segmentation map in favor of model training with layout semantics. second, the feature responses of the discriminator encoded by our adversarial feedback module are fed back to the generator to refine the intermediate representations, so that the generation performance is continually improved through an iterative generation process. third, to pursue high-fidelity and semantic consistency of the generated panorama image, we propose a pixel-segmentation alignment mechanism under the dual branch discrimiantion strategy to facilitate cooperation between the generator and the discriminator. extensive experimental results on two challenging cross-view image datasets show that panogan enables high-quality panorama image generation with more convincing details than state-of-the-art approaches. the source code and trained models are available at https://github.com/ sswuai/ panogan.",AB_0299
"currently, the use of rich spectral and spatial information of hyperspectral images (hsis) to classify ground objects is a research hotspot. however, the classification ability of existing models is significantly affected by its high data dimensionality and massive information redundancy. therefore, we focus on the elimination of redundant information and the mining of promising features and propose a novel bole convolution (bc) neural network with a tandem three-direction attention (tda) mechanism (bta-net) for the classification of hsi. a new bc is proposed for the first time in this algorithm, whose core idea is to enhance effective features and eliminate redundant features through feature punishment and reward strategies. considering that traditional attention mechanisms often assign weights in a one-direction manner, leading to a loss of the relationship between the spectra, a novel three-direction (horizontal, vertical, and spatial directions) attention mechanism is proposed, and an addition strategy and a maximization strategy are used to jointly assign weights to improve the context sensitivity of spatial-spectral features. in addition, we also designed a tandem tda mechanism module and combined it with a multiscale bc output to improve classification accuracy and stability even when training samples are small and unbalanced. we conducted scene classification experiments on four commonly used hyperspectral datasets to demonstrate the superiority of the proposed model. the proposed algorithm achieves competitive performance on small samples and unbalanced data, according to the results of comparison and ablation experiments. the source code for bta-net can be found at https://github.com/vivitsai/bta-net.",AB_0299
"dnase i hypersensitive sites (dhss) are a specific genomic region, which is critical to detect or understand cis-regulatory elements. although there are many methods developed to detect dhss, there is a big gap in practice. we presented a deep learning-based language model for predicting dhss, named langmodhs. the langmodhs mainly comprised the convolutional neural network (cnn), the bi-directional long short-term memory (bi-lstm) and the feed-forward attention. the cnn and the bi-lstm were stacked in a parallel manner, which was helpful to accumulate multiple -view representations from primary dna sequences. we conducted 5-fold cross-validations and independent tests over 14 tissues and 4 developmental stages. the empirical experiments showed that the langmodhs is competitive with or slightly better than the idhs-deep, which is the latest method for predicting dhss. the empirical experiments also implied substantial contribution of the cnn, bi-lstm, and attention to dhss prediction. we implemented the langmodhs as a user-friendly web server which is accessible at http://ww.biolscience.cn/langmodhs/. we used indices related to information entropy to explore the sequence motif of dhss. the analysis provided a certain insight into the dhss.",AB_0299
"despite the development of computer vision techniques, the micro-expression (me) recognition task still remains a great challenge because mes have very low intensity and short duration. however, the me recognition is of great significance since it provides important clues for real affective states detection. this paper proposes a novel block division convolutional network (bdcnn) with the implicit deep features augmentation. in detail, bdcnn learns from four optical flow features computed by the onset and apex frames of each video. it innovatively divides each image into a set of small blocks in the deep learning model, then the convolution and pooling operations are performed on these small blocks in sequence. to handle the small sample size problem in the micro-expression data, this study uses the improved implicit semantic data augmentation algorithm in the deep features space. experiments are conducted on three publicly available databases, viz, casme ii, smic, and samm. experimental results show that our model outperforms the state-of-the-art methods by attaining the accuracy of 84.32% and f1-score of 82.13% on the 3-class datasets, and the accuracy of 81.82% and f1-score of 75.46% on the 5-class datasets, respectively. our source code is publicly available for non-commercial or research use at https://github.com/mldmxm2017/bdcnn.",AB_0299
"convolutional neural network (cnn) plays a vital role in the development of computer vision applications. the depth neural network composed of u-shaped structures and jump connections is widely used in various medical image tasks. recently, based on the self-attention mechanism, the transformer structure has made great progress and tends to replace cnn, and it has great advantages in understanding global information. in this paper, the convwin transformer structure is proposed, which refers to the w-msa structure in swin and combines with the convolution. it can not only accelerate the convergence speed, but also enrich the information exchange between patches and improve the understanding of local information. then, it is integrated with unet, a u-shaped architecture commonly used in medical image segmentation, to form a structure called convwin-unet. meanwhile, this paper improves the patch expanding layer to perform the upsampling operation. the experimental results on the hubmap datasets and synapse multi-organ segmentation dataset indicate that the proposed convwin-unet structure achieves excellent results. partial code and models of this work are available at https://github.com/xmfeng-hdu/convwin-unet.",AB_0299
"the attention-based networks have become prevailing recently in visual question answering (vqa) due to their high performances. however, the extensive memory consumption of attention-based models poses excessive-high demand for the implementation equipment, raising concerns about their future application scenarios. therefore, designing an efficient and lightweight vqa model is central to expanding possible application areas. our work presents a novel lightweight attention-based vqa model, namely residual weight-sharing attention network (rwsan), consisting of residual weight-sharing attention (rwsa) layers cascaded in depth. each rwsa layer models the textual representation with self residual weight-sharing attention (srwsa) and captures question features and question-image interactions with self-guided residual weight-sharing attention (sgrwsa). inside each rwsa layer, the proposed low-rank attention (lra) units perform residual learning with learned connection patterns and shared parameters, and every stacked rwsa layer also uses the same parameters. extensive ablation experiments with quantitative and qualitative analysis are conducted to illustrate the effectiveness and generality of rwsa. experiments on vqa-v2, gqa, and clevr datasets show that the rwsan achieves competitive performance with much fewer parameters over the state-of-the-art methods. we release our code at https://github.com/brightqin/rwsan.",AB_0299
"salient instance segmentation (sis) can be considered as the next generation task for the saliency detection community. most of the existing state-of-the-art methods used for this novel challenging task are built on the mainstream mask r-cnn architecture. however, this mechanism relies heavily on hand-designed anchors and nms post-processing. in this paper, we provide a one stage sis framework with transformers, termed orientative query transformer (oqtr). to leverage the long-range dependencies of transformers, a cross fusion module is designed to efficiently fuse the global features in the encoder and salient query features for salient mask prediction. furthermore, derived from the center prior in traditional saliency models, we propose an orientative query that is considered as the initial salient object query to accelerate convergence. in addition, to mitigate the issue of the lack of a large-scale dataset with salient instance labels, we collect a new sis dataset (sis10 k) containing over 10 k images elaborately annotated with both object- and instance-level labels to promote the community. without any post-processing, our end-to-end oqtr framework significantly surpasses the top-1 rdpnet by an average of 13.1% ap scores across all three challenging datasets, demonstrating the strong performance of the proposed oqtr. the code and the dataset proposed in this work are available at: https://github.com/ssecv/oqtr.",AB_0299
