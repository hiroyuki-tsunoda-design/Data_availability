AB,NO
"for a long time, the local descriptors learning benefited from the use of l2 normalization, which projects the descriptor space onto the hypersphere. however, there is no free lunch in the world. although hypersphere description space stabilizes the optimization and improves the repeatability of the descriptors, it causes the descriptors to have a denser distribution, which reduces the discrimination between descriptors and leads to some incorrect matches. to alleviate this problem, we propose the learnable cross normalization technology as an alternative to l2 normalization, which can achieve a consistent improvement in several of the current popular local descriptors. in addition, we propose an er-backbone that can efficiently reuse features in descriptors extraction and an idc loss that can provide an image-level description space distribution consistency constraint to further stimulate the performance of the local descriptors. based on the above innovations, we provide a novel local descriptors extraction method named cndesc. we perform experiments on image matching, homography estimation, 3d reconstruction, and visual localization tasks, and the results demonstrate that our cndesc surpasses the current state-of-the-art local descriptors. our code is available at https:// github.com/ vignywang/ cndesc.",AB_0300
"prostate cancer is the second leading cause of cancer death among men in the united states. the diagnosis of prostate mri often relies on accurate prostate zonal segmentation. however, state-of-the-art automatic segmentation methods often fail to produce well-contained volumetric segmentation of the prostate zones since certain slices of prostate mri, such as base and apex slices, are harder to segment than other slices. this difficulty can be overcome by leveraging important multi-scale image-based information from adjacent slices, but current methods do not fully learn and exploit such cross-slice information. in this paper, we propose a novel cross-slice attention mechanism, which we use in a transformer module to systematically learn cross-slice information at multiple scales. the module can be utilized in any existing deep-learning-based segmentation framework with skip connections. experiments show that our cross-slice attention is able to capture cross-slice information significant for prostate zonal segmentation in order to improve the performance of current state-of-the-art methods. cross-slice attention improves segmentation accuracy in the peripheral zones, such that segmentation results are consistent across all the prostate slices (apex, mid-gland, and base). the code for the proposed model is available at https://bit.ly/cat-net.",AB_0300
"convolutional neural networks (cnns) have achieved state-of-the-art performance for medical image segmentation, yet need plenty of manual annotations for training. semi-supervised learning (ssl) methods are promising to reduce the requirement of annotations, but their performance is still limited when the dataset size and the number of annotated images are small. leveraging existing annotated datasets with similar anatomical structures to assist training has a potential for improving the model's performance. however, it is further challenged by the cross-anatomy domain shift due to the image modalities and even different organs in the target domain. to solve this problem, we propose contrastive semi-supervised learning for cross anatomy domain adaptation (cs-cada) that adapts a model to segment similar structures in a target domain, which requires only limited annotations in the target domain by leveraging a set of existing annotated images of similar structures in a source domain. we use domain-specific batch normalization (dsbn) to individually normalize feature maps for the two anatomical domains, and propose a cross-domain contrastive learning strategy to encourage extracting domain invariant features. they are integrated into a self-ensembling mean-teacher (se-mt) framework to exploit unlabeled target domain images with a prediction consistency constraint. extensive experiments show that our cs-cada is able to solve the challenging cross-anatomy domain shift problem, achieving accurate segmentation of coronary arteries in x-ray images with the help of retinal vessel images and cardiac mr images with the help of fundus images, respectively, given only a small number of annotations in the target domain. our code is available at https://github.com/hilab-git/dag4mia.",AB_0300
"recently, deep neural network-based methods have shown promising advantages in accurately recognizing skin lesions from dermoscopic images. however, most existing works focus more on improving the network framework for better feature representation but ignore the data imbalance issue, limiting their flexibility and accuracy across multiple scenarios in multi-center clinics. generally, different clinical centers have different data distributions, which presents challenging requirements for the network's flexibility and accuracy. in this paper, we divert the attention from framework improvement to the data imbalance issue and propose a new solution for multi-center skin lesion classification by introducing a novel adaptively weighted balance (awb) loss to the conventional classification network. benefiting from awb, the proposed solution has the following advantages: 1) it is easy to satisfy different practical requirements by only changing the backbone; 2) it is user-friendly with no tuning on hyperparameters; and 3) it adaptively enables small intraclass compactness and pays more attention to the minority class. extensive experiments demonstrate that, compared with solutions equipped with state-of-the-art loss functions, the proposed solution is more flexible and more competent for tackling the multi-center imbalanced skin lesion classification task with considerable performance on two benchmark datasets. in addition, the proposed solution is proved to be effective in handling the imbalanced gastrointestinal disease classification task and the imbalanced dr grading task. code is available at https://github.com/weipeishan2021.",AB_0300
"the tumor grading of laryngeal cancer pathological images needs to be accurate and interpretable. the deep learning model based on the attention mechanism-integrated convolution (amc) block has good inductive bias capability but poor interpretability, whereas the deep learning model based on the vision transformer (vit) block has good interpretability but weak inductive bias ability. therefore, we propose an end-to-end vit-amc network (vit-amcnet) with adaptive model fusion and multiobjective optimization that integrates and fuses the vit and amc blocks. however, existing model fusion methods often have negative fusion: 1). there is no guarantee that the vit and amc blocks will simultaneously have good feature representation capability. 2). the difference in feature representations learning between the vit and amc blocks is not obvious, so there is much redundant information in the two feature representations. accordingly, we first prove the feasibility of fusing the vit and amc blocks based on hoeffding's inequality. then, we propose a multiobjective optimization method to solve the problem that vit and amc blocks cannot simultaneously have good feature representation. finally, an adaptive model fusion method integrating the metrics block and the fusion block is proposed to increase the differences between feature representations and improve the deredundancy capability. our methods improve the fusion ability of vit-amcnet, and experimental results demonstrate that vit-amcnet significantly outperforms state-of-the-art methods. importantly, the visualized interpretive maps are closer to the region of interest of concern by pathologists, and the generalization ability is also excellent. our code is publicly available at https://github.com/baron-huang/vit-amcnet.",AB_0300
"traffic prediction is the cornerstone of intelligent transportation system. accurate traffic forecasting is essential for the applications of smart cities, i.e., intelligent traffic management and urban planning. although various methods are proposed for spatio-temporal modeling, they ignore the dynamic characteristics of correlations among locations on road network. meanwhile, most recurrent neural network based works are not efficient enough due to their recurrent operations. additionally, there is a severe lack of fair comparison among different methods on the same datasets. to address the above challenges, in this article, we propose a novel traffic prediction framework, named dynamic graph convolutional recurrent network (dgcrn). in dgcrn, hyper-networks are designed to leverage and extract dynamic characteristics from node attributes, while the parameters of dynamic filters are generated at each time step. we filter the node embeddings and then use them to generate dynamic graph, which is integrated with pre-defined static graph. as far as we know, we are first to employ a generation method to model fine topology of dynamic graph at each time step. furthermore, to enhance efficiency and performance, we employ a training strategy for dgcrn by restricting the iteration number of decoder during forward and backward propagation. finally, a reproducible standardized benchmark and a brand new representative traffic dataset are opened for fair comparison and further research. extensive experiments on three datasets demonstrate that our model outperforms 15 baselines consistently. source codes are available at https://github.com/tsinghua-fib-lab/traffic-benchmark.",AB_0300
"multi-view clustering, which appropriately integrates information from multiple sources to reveal data's inherent structure, is gaining traction in clustering. though existing procedures have yielded satisfactory results, we observe that they have neglected the inherent local structure in the base kernels. this may cause adverse effects on clustering. to solve the problem, we introduce lf-mkc-lka, a simple yet effective late fusion multiple kernel clustering with local kernel alignment maximisation approach. in particular, we first determine the nearest $k$ neighbours in the average kernel space for each sample and record the information in the nearest neighbor indicator matrix. then, the nearest neighbor indicator matrix can be used to generate local structure matrix of each sample. the local kernels of each view may then be generated using the local structure matrix, retaining just the highly confident local similarities for learning the intrinsic global manifold of data. they can also be utilised to keep the block diagonal structure and improve the robustness of the underlying kernels against noise.we input the local kernels of each view into the kernel $k$-means (kkm) algorithm and get the local base partitions. finally, we use a three-step iterative optimization approach to maximize the alignment of the consensus partition using base partitions and a regularisation term. as demonstrated, a significant number of trials on 11 multi-kernel benchmark datasets have shown that the proposed lf-mkc-lka is effective and efficient. a number of experiments are also designed to demonstrate the fast convergence, excellent performance, robustness and low parameter sensitivity of the algorithm. our code can be find at https://github.com/tiejianzhang/tmm21-lf-mkc-lka.",AB_0300
"multi-view learning has progressed rapidly in recent years. although many previous studies assume that each instance appears in all views, it is common in real-world applications for instances to be missing from some views, resulting in incomplete multi-view data. to tackle this problem, we propose a novel latent heterogeneous graph network (lhgn) for incomplete multi-view learning, which aims to use multiple incomplete views as fully as possible in a flexible manner. by learning a unified latent representation, a trade-off between consistency and complementarity among different views is implicitly realized. to explore the complex relationship between samples and latent representations, a neighborhood constraint and a view-existence constraint are proposed, for the first time, to construct a heterogeneous graph. finally, to avoid any inconsistencies between training and test phase, a transductive learning technique is applied based on graph learning for classification tasks. extensive experimental results on real-world datasets demonstrate the effectiveness of our model over existing state-of-the-art approaches. our code is available at: https://github.com/yxjdarren/lhgn_tmm_2022.",AB_0300
"attention has become an indispensable component of the models of various multimedia tasks like image captioning (ic) and visual question answering (vqa). however, most existing attention modules are designed for capturing the spatial dependency, and are still insufficient in semantic understanding, e.g., the categories of objects and their attributes, which is also critical for image captioning. to compensate for this defect, we propose a novel attention module termed channel-wise attention block (cab) to model channel-wise dependency for both visual modality and linguistic modality, thereby improving semantic learning and multi-modal reasoning simultaneously. specifically, cab has two novel designs to tackle with the high overhead of channel-wise attention, which are the reduction-reconstruction block structure and the gating-based attention prediction. based on cab, we further propose a novel semantic-enhanced dual attention transformer (termedsdatr), which combines the merits of spatial and channel-wise attentions. to validate sdatr, we conduct extensive experiments on the ms coco dataset and yield new state-of-the-art performance of 134.5 cider score on coco karpathy test split and 136.0 cider score on the official online testing server. to examine the generalization of sdatr, we also apply it to the task of visual question answering, where superior performance gains are also witnessed. the code and models are publicly available at https:// github.com/ xmu-xiaoma666/sdatr.",AB_0300
"lidar-based 3d single object tracking is a challenging issue in robotics and autonomous driving. currently, existing approaches usually suffer from the problem that objects at long distance often have very sparse or partially-occluded point clouds, which makes the features extracted by the model ambiguous. ambiguous features will make it hard to locate the target object and finally lead to bad tracking results. to solve this problem, we utilize the powerful transformer architecture and propose a point-track-transformer (ptt) module for point cloud-based 3d single object tracking task. specifically, ptt module generates fine-tuned attention features by computing attention weights, which guides the tracker focusing on the important features of the target and improves the tracking ability in complex scenarios. to evaluate our ptt module, we embed ptt into the dominant method and construct a novel 3d sot tracker named ptt-net. in ptt-net, we embed ptt into the voting stage and proposal generation stage, respectively. ptt module in the voting stage could model the interactions among point patches, which learns context-dependent features. meanwhile, ptt module in the proposal generation stage could capture the contextual information between object and background. we evaluate our ptt-net on kitti and nuscenes datasets. experimental results demonstrate the effectiveness of ptt module and the superiority of ptt-net, which surpasses the baseline by a noticeable margin, similar to 10% in the car category. meanwhile, our method also has a significant performance improvement in sparse scenarios. in general, the combination of transformer and tracking pipeline enables our ptt-net to achieve state-of-the-art performance on both two datasets. additionally, ptt-net could run in real-time at 40fps on nvidia 1080ti gpu. our code is open-sourced for the research community at https://github.com/shanjiayao/ptt.",AB_0300
