AB,NO
"many materials, like polymer melts, solutions, biopolymers and textiles, are composed of entangled filaments. the entanglement in these systems significantly affects their mechanical properties and their function. we introduce the topological entanglement in polymers, proteins and periodic systems (teppp) software, that enables to measure the topological and geometrical complexity in such systems. in particular, this software enables the computation of the writhe, the gauss linking integral and the jones polynomial of each filament or pair of filaments in the system, whether they are open or closed. in particular, for systems employing periodic boundary conditions (pbc), the software also allows to compute the total pairwise entanglement in pbc, using the periodic linking number and the periodic writhe. for linear (open) chains, teppp can calculate all these topological parameters (including the jones polynomial) without any closure scheme. in addition, teppp also enables measuring self and pairwise entanglement at different length-scales along a chain or a pair of chains. with appropriate preprocessing of input files, the code can also be used for star or branched architectures. we provide examples of how the code is used and we present results on the entanglement effect in polymers obtained using this package. we show how teppp can be used to measure the topological entanglement of linear polymer chains in a melt, revealing subtle entanglement transitions never seen before. we also used teppp to analyze the effect of knotting and its location in diblock copolymer melts, which reveals that knotting localization transition coincides with lamellar-disorder transition in these systems. finally, we use teppp to reveal some of the topological structure of the sars-cov-2 spike protein, which points to interesting structure in a region that contains the s1/s2 cleavage site.program summaryprogram title: topological entanglement in polymers, proteins and periodic systems (teppp) softwarecpc library link to program files: https://doi .org /10 .17632 /ygdbpnhpzw.1developer's repository link: https://github .com /teppp-softwarelicensing provisions: bsd 3-clauseprogramming language: c++ supplementary material:nature of problem: measuring single and pairwise entanglement and knotting in systems of linear or ring filaments (open or closed curves) in 3-space or in systems employing periodic boundary conditions (pbc) at different length scales.solution method: teppp can be used to measure topological entanglement complexity in single or multi -chain filament systems in 3-space or in systems employing pbc. given as input the coordinates of the curves, teppp can compute the gauss linking integral, the writhe, the jones polynomial, the periodic",AB_0591
"quantitative susceptibility mapping (qsm) involves acquisition and reconstruction of a series of images at multi-echo time points to estimate tissue field, which prolongs scan time and requires specific reconstruction technique. in this paper, we present our new framework, called learned acquisition and reconstruction op-timization (laro), which aims to accelerate the multi-echo gradient echo (mgre) pulse sequence for qsm. our approach involves optimizing a cartesian multi-echo k-space sampling pattern with a deep reconstruc-tion network. next, this optimized sampling pattern was implemented in an mgre sequence using cartesian fan-beam k-space segmenting and ordering for prospective scans. furthermore, we propose to insert a recur-rent temporal feature fusion module into the reconstruction network to capture signal redundancies along echo time. our ablation studies show that both the optimized sampling pattern and proposed reconstruction strategy help improve the quality of the multi-echo image reconstructions. generalization experiments show that laro is robust on the test data with new pathologies and different sequence parameters. our code is available at https://github.com/jinwei1209/laro-qsm.git .",AB_0591
"evaluation of suspected myeloid neoplasms involves testing for recurrent, diagnostically and thera-peutically relevant genetic alterations. current molecular testing requires multiple technologies, different domains of expertise, and unconnected workflows, resulting in variable, lengthy turnaround times that can delay treatment. to address this unmet clinical need, we evaluated the oncomine myeloid assay gx panel on the ion torrent genexus platform, a rapid, integrated nucleic acid to report next-generation sequencing platform for detecting clinically relevant genetic aberrations in myeloid disorders. specimens included synthetic dna (101 targets) and rna (9 targets) controls and real-world nucleic acid material derived from bone marrow or peripheral blood samples (40 patients). ion torrent genexus results and performance indices were compared with those obtained from clinically validated genomic testing workflows in 2 separate clinical laboratories. the ion torrent genexus identified 100% of dna and rna control variants. for primary patient specimens, the ion torrent genexus reported 82 of 107 dna variants and 19 of 19 rna gene fusions identified on clinically validated assays, yielding an 80% overall detection rate. reanalysis of exported, unfiltered ion torrent genexus data revealed 15 dna variants not called by the filtered on-board bioinformatics pipeline, yielding a 92% potential detection rate. these results hold promise for the implementation of an integrated next-generation sequencing system to rapidly detect genetic aberrations, facilitating accurate, genomics-based diagnoses and accelerated time to precision therapies in myeloid neoplasms. (j mol diagn 2023, 25: 87-93; https:// doi.org/10.1016/j.jmoldx.2022.11.005)",AB_0591
"influence estimation analyzes how changes to the training data can lead to different model predictions; this analysis can help us better understand these predictions, the models making those predictions, and the data sets they're trained on. however, most influenceestimation techniques are designed for deep learning models with continuous parameters. gradient-boosted decision trees (gbdts) are a powerful and widely-used class of models; however, these models are black boxes with opaque decision-making processes. in the pursuit of better understanding gbdt predictions and generally improving these models, we adapt recent and popular influence-estimation methods designed for deep learning models to gbdts. specifically, we adapt representer-point methods and tracin, denoting our new methods trex and boostin, respectively; source code is available at https://github.com/jjbrophy47/tree_influence. we compare these methods to leafinfluence and other baselines using 5 different evaluation measures on 22 real-world data sets with 4 popular gbdt implementations. these experiments give us a comprehensive overview of how different approaches to influence estimation work in gbdt models. we find boostin is an efficient influence-estimation method for gbdts that performs equally well or better than existing work while being four orders of magnitude faster. our evaluation also suggests the gold-standard approach of leave-one-out (loo) retraining consistently identifies the single-most influential training example but performs poorly at finding the most influential set of training examples for a given target prediction.",AB_0591
"the prediction accuracy of machine learning methods is steadily increasing, but the calibra-tion of their uncertainty predictions poses a significant challenge. numerous works focus on obtaining well-calibrated predictive models, but less is known about reliably assessing model calibration. this limits our ability to know when algorithms for improving calibra-tion have a real effect, and when their improvements are merely artifacts due to random noise in finite datasets. in this work, we consider detecting mis-calibration of predictive models using a finite validation dataset as a hypothesis testing problem. the null hypoth-esis is that the predictive model is calibrated, while the alternative hypothesis is that the deviation from calibration is sufficiently large. we find that detecting mis-calibration is only possible when the conditional probabili-ties of the classes are sufficiently smooth functions of the predictions. when the conditional class probabilities are ho center dot lder continuous, we propose t-cal, a minimax optimal test for calibration based on a debiased plug-in estimator of the .22-expected calibration error (ece). we further propose adaptive t-cal, a version that is adaptive to unknown smooth-ness. we verify our theoretical findings with a broad range of experiments, including with several popular deep neural net architectures and several standard post-hoc calibration methods. t-cal is a practical general-purpose tool, which-combined with classical tests for discrete-valued predictors-can be used to test the calibration of virtually any proba-bilistic classification method. t-cal is available at https://github.com/dh7401/t-cal.",AB_0591
"most work in neural networks focuses on estimating the conditional mean of a contin-uous response variable given a set of covariates. in this article, we consider estimating the conditional distribution function using neural networks for both censored and un-censored data. the algorithm is built upon the data structure particularly constructed for the cox regression with time-dependent covariates. without imposing any model assumptions, we consider a loss function that is based on the full likelihood where the conditional hazard function is the only unknown nonparametric parameter, for which un-constrained optimization methods can be applied. through simulation studies, we show that the proposed method possesses desirable performance, whereas the partial likelihood method and the traditional neural networks with l2 loss yields biased estimates when model assumptions are violated. we further illustrate the proposed method with several real-world data sets. the implementation of the proposed methods is made available at https://github.com/bingqing0729/nncde.",AB_0591
"in recent years, model-agnostic meta-learning (maml) has become a popular research area. however, the stochastic optimization of maml is still underdeveloped. existing maml algorithms rely on the episode idea by sampling a few tasks and data points to update the meta-model at each iteration. nonetheless, these algorithms either fail to guarantee convergence with a constant mini-batch size or require processing a large number of tasks at every iteration, which is unsuitable for continual learning or cross-device federated learning where only a small number of tasks are available per iteration or per round. to address these issues, this paper proposes memory-based stochastic algorithms for maml that converge with vanishing error. the proposed algorithms require sampling a constant number of tasks and data samples per iteration, making them suitable for the continual learning scenario. moreover, we introduce a communication-efficient memory-based maml algorithm for personalized federated learning in cross-device (with client sampling) and cross-silo (without client sampling) settings. our theoretical analysis improves the optimization theory for maml, and our empirical results corroborate our theoretical findings. interested readers can access our code at https://github.com/bokun-wang/moml.",AB_0591
"statistical inference of directed relations given some unspecified interventions (i.e., the in-tervention targets are unknown) is challenging. in this article, we test hypothesized directed relations with unspecified interventions. first, we derive conditions to yield an identifiable model. unlike classical inference, testing directed relations requires identifying the an-cestors and relevant interventions of hypothesis-specific primary variables. to this end, we propose a peeling algorithm based on nodewise regressions to establish a topological order of primary variables. moreover, we prove that the peeling algorithm yields a con-sistent estimator in low-order polynomial time. second, we propose a likelihood ratio test integrated with a data perturbation scheme to account for the uncertainty of identifying ancestors and interventions. also, we show that the distribution of a data perturbation test statistic converges to the target distribution. numerical examples demonstrate the utility and effectiveness of the proposed methods, including an application to infer gene regulatory networks. the r implementation is available at https://github.com/chunlinli/intdag.",AB_0591
"this paper introduces a novel method for translating natural-language instructions into executable robot actions using openai's chatgpt in a few-shot setting. we propose customizable input prompts for chatgpt that can easily integrate with robot execution systems or visual recognition programs, adapt to various environments, and create multi-step task plans while mitigating the impact of token limit imposed on chatgpt. in our approach, chatgpt receives both instructions and textual environmental data, and outputs a task plan and an updated environment. these environmental data are reused in subsequent task planning, thus eliminating the extensive record-keeping of prior task plans within the prompts of chatgpt. experimental results demonstrated the effectiveness of these prompts across various domestic environments, such as manipulations in front of a shelf, a fridge, and a drawer. the conversational capability of chatgpt allows users to adjust the output via natural-language feedback. additionally, a quantitative evaluation using virtualhome showed that our results are comparable to previous studies. specifically, 36% of task planning met both executability and correctness, and the rate approached 100% after several rounds of feedback. our experiments revealed that chatgpt can reasonably plan tasks and estimate post-operation environments without actual experience in object manipulation. despite the allure of chatgpt-based task planning in robotics, a standardized methodology remains elusive, making our work a substantial contribution. these prompts can serve as customizable templates, offering practical resources for the robotics research community. our prompts and source code are open source and publicly available at https://github.com/microsoft/chatgpt-robot-manipulation-prompts.",AB_0591
"this paper proposes a data-efficient detection method for deep neural networks against backdoor attacks under a black-box scenario. the proposed approach is motivated by the intuition that features corresponding to triggers have a higher influence in determining the backdoored network output than any other benign features. to quantitatively measure the effects of triggers and benign features on determining the backdoored network output, we introduce five metrics. to calculate the five-metric values for a given input, we first generate several synthetic samples by injecting the input's partial contents into clean validation samples. then, the five metrics are computed by using the output labels of the corresponding synthetic samples. one contribution of this work is the use of a tiny clean validation dataset. having the computed five metrics, five novelty detectors are trained from the validation dataset. a meta novelty detector fuses the output of the five trained novelty detectors to generate a meta confidence score. during online testing, our method determines if online samples are poisoned or not via assessing their meta confidence scores output by the meta novelty detector. we show the efficacy of our methodology through a broad range of backdoor attacks, including ablation studies and comparison to existing approaches. our methodology is promising since the proposed five metrics quantify the inherent differences between clean and poisoned samples. additionally, our detection method can be incrementally improved by appending more metrics that may be proposed to address future advanced attacks. code is available at https://github.com/fu1001hao/five-metrics-detector.git.",AB_0591
