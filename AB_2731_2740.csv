AB,NO
"high-resolution nighttime light (hr-ntl) imagery is a reliable indicator of human activity in urban areas at night. however, hr-ntl images on earth are blurred because of issues such as blooming, noise, and overexposure in the imaging system and transmission path. toward this end, a nighttime light image deblooming network (ntl-db-net) is proposed, which aims to make the earth clearer at night. the ntl-db-net employs a generative adversarial network (gan) as its deblooming framework. as the lack of ideal clear ntl data for gan training, our method integrates a blur transfer algorithm to simulate degradation for generating training data. this method was tested using hr-ntl data on wuhan, macau, changchun, xiamen, atlanta, and jerusalem from the hr jilin-1 satellite constellation. compared with the results of state-of-the-art self-adjusting model (seam), uformer, and drbnet, those from ntl-db-net demonstrated superior visual features and achieved the highest scores across all selected nonreference evaluation metrics. ntl-db-net also exhibited a lower number of network parameters and a smaller time cost. in addition, this study conducted a spatial clustering analysis of nighttime light with road networks and permeable surfaces. the results indicated that nightlights and roads exhibited a distinct spatially aggregated distribution, while permeable surfaces displayed a clear spatially dispersed distribution. the code and data are available at https://github.com/lixinghua5540/ntl-db-net.",AB_0274
"single-frame infrared small target detection is a challenging task due to the noise and clutter interference. recent emerging deep learning methods achieve superior detection performance compared to traditional model-driven methods. however, these data-driven methods do not possess the explicit gradient encoding capability of local contrast methods. to overcome the restriction, we propose a holistic local contrast network (holoconet) in this letter to gradually couple the local contrast into the end-to-end network, which consists of a multiscaled multidirectional attention module (m2am) to directly processes the input image, a multibranch dilated difference convolution module (d2cm) for secondary refinement of the multiscale features extracted by the backbone network, and a semantic-enhanced aggregation module (seam) for bottom-up feature fusion by enhancing shallow features with deep semantic knowledge. the experimental results on the widely accepted nudt-sirst and irstd-1k dataset demonstrate the rationality and effectiveness of the proposed holoconet with the probability of detection reaching 99.2 and 94.3. the source codes are available at https://github.com/jzchenriver/holoconet.",AB_0274
"remote sensing (rs) image semantic segmentation has attracted much attention due to its wide applications. however, deep learning-based rs image semantic segmentation methods usually require substantial manual pixelwise annotations, which are expensive and hard to obtain in practice. although the existing semisupervised rs semantic segmentation methods effectively reduce dependence on labeled data, they generally focus on information consistency between labeled and unlabeled images, but ignore the potential context information between different areas of the rs image. in fact, the objects contained in an rs image usually have some long-range dependence between each other, since trees are usually on both sides of a road, and the middle of two rows of houses is commonly a road. therefore, we believe that the potential dependencies between different areas of the rs image should be beneficial to reduce the label dependence of rs semantic segmentation. based on this point, we propose a novel semisupervised rs image semantic segmentation network named segmind, which is based on mean-teacher (mt) architecture and adopts masked image modeling (mim) to enhance information interactions of different areas. moreover, contrastive learning (cl) and entropy loss are introduced to segmind framework to further improve the linear separability and prediction confidence of the proposed model. experiments on three datasets have demonstrated the superiority of the proposed method over the state-of-the-art methods. the code is available at https://github.com/lzh-ggs-ddu/segmind.",AB_0274
"multispectral image (msi) and hyperspectral image (hsi) fusion can combine the best of both worlds to produce images with both high spatial and spectral resolutions. in this article, we have designed a network for fusing msis and hsis, called dspnet. on the one hand, in order to ensure the accuracy of the spectral dimension, i.e., spectral fidelity, we designed the spectral pyramid (spepy) module and the multiscale local spectral information fusion (mlsif) module. the former extracts the multiscale local spectral information that captures the subtle spectral details and variations between different spectra. the latter establishes long-range dependency in the spectral dimension through the spectralwise multihead hybrid-attention (s-mha) mechanism, thus enabling the network to focus on the local spectral information needed to recover the spectral details. on the other hand, to address the spatial information of msis, we designed the spatial pyramid (spapy) module. the spapy module can extract the nonlocal spatial information of msis at different scales, which enables the network to adapt to different remote sensing scenes. experiments performed on simulated and real data demonstrate the superiority of our method over the state-of-the-art methods both qualitatively and quantitatively. our code is publicly available at https://github.com/syc11-25/dspnet.",AB_0274
"landslides are common and highly threatening geological disasters, and detecting landslide occurrence areas using remote sensing images has important social significance for disaster warning, prediction, and proactive rescue. currently, the most effective and direct application is in-orbit real-time detection, which obtains the boundary, location and other relevant information of the post-disaster areas by performing in-orbit calculations on the raw images, thereby shortening the relief cycle. however, challenges associated with this application are high efficiency and portability, while overcoming complex surface distributions to ensure high accuracy. in this article, we propose a lightweight network framework and deploy it on a civilian qk series environmental monitoring satellite, transmitting the detection results in graphic form to the ground station. this framework addresses the problems of parameter redundancy and low real-time performance in existing embedded device landslide detection methods. the model adopts a conditional attention mechanism, multifeature fusion, and asymmetric upsampling modules (aums). it employs only 3.045 mb of parameters, with a mean intersection over union (miou) of 88.38% and an f1-scores of 93.77%, striking a good balance between computational efficiency and accuracy, and its performance can meet the requirements of inorbit applications. additionally, we have labeled and published landslide samples that occurred in luding, sichuan province, southwest china, in september 2022, which is available at https://github.com/fuadou/project/tree/main/luding_datasets.",AB_0274
"although hyperspectral image (hsi) classification has made great progress, most classification methods assume that the training and test data have the same class, and that there are no classes in the test data that are not present in the training data. as a result, unknown classes are ignored during model building, which requires the use of open-set classification (osc) methods to reject unknown classes. however, the current osc methods do not consider the constraints during feature learning, which can lead to the problem that the feature spaces of known and unknown classes may tend to be consistent. to ensure the discriminability of the feature space and improve the accuracy of the osc, we propose a novel open-set hsi classification framework based on supervised contrastive learning (osc-scl). by adding scl to spectral and spatial feature learning, respectively, not only samples in the same class can be pulled closer, but also unknown classes can be distinguished from known classes. we also introduce a class anchor-based clustering strategy, which can effectively reject unknown classes while ensuring that known classes are correctly classified. our method is validated on two hsi datasets and outperforms existing state-of-the-art methods. the code is available at https://github.com/li-zk/osc-scl.",AB_0274
"compared with general optical images, hyperspectral images (hsis) contain richer spectral information. on one hand, this provides a sufficient basis for ground object recognition. on the other hand, it results in the intermingling of spatial and spectral information. in order to make better use of the rich spatial and spectral information in hsis, we resort to vision transformer (vit). to be specific, we propose the cross spatial-spectral dense transformer (cs2dt) for spatial-spectral feature extracting and feature fusing. for feature extraction, cs2dt employs the adaptive dense encoder (ade) module, which enables the extraction of multiscale semantic information. during the features fusion stage, we use the cross spatial-spectral attention (cs2a) module based on the cross-attention (ca) operation to better integrate spatial and spectral features. we evaluate the classification performance of the proposed cs2dt on three well-known datasets by conducting extensive experiments. experimental results demonstrate that cs2dt can achieve higher accuracy and higher stability when compared with the state-of-the-art (sota) methods. the source code will be made available at https://github.com/shouhengx/cs2dt.",AB_0274
"ship detection is of great importance in territorial security and marine environmental protection. however, the accurate detection of small ships is a challenging task in complex environments mainly due to small ships having few features on remote sensing images. in this letter, we propose a small ship detection model based on yolov5s. the major features of the proposed model include: 1) a detection layer is added with a shallow feature map in the head and skip connections are employed in the neck to improve the detection accuracy of small ships; 2) a novel and effective hybrid spatial pyramid pooling (hspp) is proposed to fuse the local and global information of feature maps; 3) a coordinate attention (ca) mechanism is employed in the backbone to augment the representations of small ships, and efficient iou (eiou) is used as the loss function for bounding box regression to enhance the localization accuracy of the proposed model; and 4) k-means++ algorithm is used to obtain more reasonable anchors for small ship detection. we introduce the multiscale ship dataset ossd, which contains 10133 images. experiments on levir-ship and ossd validate the effectiveness of our proposed model. the code and ossd will be available at https://github.com/wenjieo/improved-yolov5s-for-small-ship-detection.",AB_0274
"traditional deep-learning-based object detection networks often resize images during the data preprocessing stage to achieve a uniform size and scale in the feature map. resizing is done to facilitate model propagation and fully connected classification. however, resizing inevitably leads to object deformation and loss of valuable information in the images. this drawback becomes particularly pronounced for tiny objects such as distribution towers (dts) with linear shapes and few pixels. to address this issue, we propose abandoning the resizing operation. instead, we introduce positional-encoding multihead criss-cross attention (cca). this allows the model to capture contextual information and learn from multiple representation subspaces, effectively enriching the semantics of dts. in addition, we enhance spatial pyramid pooling by reshaping three pooled feature maps into a new unified one while also reducing the computational burden. this approach allows images of different sizes and scales to generate feature maps with uniform dimensions and can be used in feature map propagation. our scaresnet incorporates these aforementioned improvements into the backbone network resnet. we evaluated our scaresnet using the electric transmission and distribution infrastructure imagery (etdii) dataset from duke university. without any additional tricks, we used various object detection models with gaussian receptive-field-based label assignment (rfla) as the baseline. when incorporating the scaresnet into the baseline model, we achieved a 2.1% improvement in maps. this demonstrates the advantages of our scaresnet in detecting transmission and dts and its value in tiny object detection (tod). the source code is available at https://github.com/lisavilalee/scaresnet_mmdet.",AB_0274
"datasets play a key role in developing superior building detection approaches. however, most of the previous work focuses on accurate building masks and scale expansion, while the categories are always missing, which hinders the further analysis of urban development and cultures. therefore, we propose a benchmark for building detection and fine-grained classification from very high-resolution (vhr) satellite imagery. an extensive annotation is performed for about 0.5 million building instances with 12 fine-grained roof types and individual polygons. the annotation of building functions of two cities in the previous version (ubcv1) (huang et al., 2022) is also integrated. to ensure the building variety, it consists of vhr optical images of 20 unique cities worldwide with various landforms and styles of architecture. its variety and fine-grained categories pose great challenges and meanwhile provide a foundation for the building extraction and fine-grained classification on a global scale. besides, 17 cities are provided with finely aligned synthetic aperture radar (sar) images, which can be used for the development and evaluation of approaches optionally based on optical, sar, or multimodal images. significantly, the proposed benchmark is used as the base of the 2023 ieee grss data fusion contest (persello et al., 2023). the dataset and codes of the baseline methods are available at: https://github.com/aicyberteam/ubc-dataset/tree/ubcv2.",AB_0274
