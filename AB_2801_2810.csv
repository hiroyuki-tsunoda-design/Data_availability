AB,NO
"continual learning is an effective way to overcome catastrophic forgetting (cf) in incremental learning for semantic segmentation. the existing continual semantic segmentation (css) methods of remote sensing (rs) ignore the semantic relationships among pixels across different images, which will lead to disappointing segmentation results, such as edge pixel misclassification and small object omission. in this article, we propose a framework for modeling cross-image semantic relationship dependencies (micro), which aims to learn an interclass separable and intraclass cohesive feature space from the pixel relationships across various images to ensure that learned categories can prevent cf in the incremental process. specifically, we exploit the relationships among pixels of images in minibatch to construct three losses: 1) cross-image feature relationship distillation (cfrd) loss, which builds a well-structured feature space; 2) cross-image intraclass feature cohesion (cifc) loss, which is devised to make intraclass features more cohesive; and 3) cross-image class-area weighted cross-entropy (ccwce) loss, which is mainly employed to inversely weight the proportion of category area in minibatch. the effectiveness of the proposed approach is demonstrated by extensive experiments on three rs semantic segmentation datasets from isprs vaihingen, isprs potsdam, and isaid. micro is superior to the current most advanced methods in most incremental settings, especially improving miou by 11.59% on isprs vaihingen, 13.17% on isprs potsdam, and 15.01% on isaid in the most difficult incremental settings, which promotes the css to a state-of-the-art (sota) level. the code will be available at https://github.com/rongxuee/micro.",AB_0281
"object detection in aerial images is a challenging task for two main reasons: small object and scale variation. existing methods utilize multilevel features to solve the scale variation problem but ignore the scale confusion problem of shallow features, limiting the small object detection performance. to solve this issue, we propose a scale decoupling module (sdm) to emphasize small object features by eliminating large object features in shallow layers. moreover, a sparse nonlocal attention (snla) and an adaptive anchor matching strategy (aams) are proposed to further improve the small object detection performance. the snla only aggregates contextual information of specific sparse positions, which not only refines small object features but also is computationally friendly. the aams is suitable for the measurement of small objects, and it can assign more positive samples to small objects. extensive experiments on three challenging aerial datasets, visdrone-det2019, uavdt, and dior, demonstrate the effectiveness and adaptivity of our method. the code will be available online (https://github.com/mayou1997/sdp).",AB_0281
"in this article, we propose an efficient remote sensing fake sample generation (rsfsg) framework based on the diffusion model, so as to generate controllable samples consistent with real scenes. firstly, in order to alleviate the huge time consumption caused by the large parameters of the diffusion model, we come up with a multifrequency dynamic knowledge distillation based on the consistent power spectrum of predicted gaussian noise. the proposed multi-frequency knowledge transfer lets the lightweight model learn different frequency outputs from teacher model during diffusion process at different stages. secondly, to address the problem of slow training of diffusion models, we propose a progressive training strategy (pts), inspired by the fitting mechanism of deep networks from low to high frequencies. pts enables fast fitting of diffusion models by enabling the model to learn from low-frequency information such as color at low resolution, and gradually move to high-resolution images full of details such as texture. the established two methods above achieve good generation performance under lightweight parameters, within almost half of the training time consumed. extensive evaluations demonstrate that the proposed model significantly outperforms the state-of-the-art methods on rs controllable fake sample generation. within our knowledge, we are the first to introduce the diffusion model into the rsfsg task and obtain good performance; the code and the corresponding pretrained files have been released at https://github.com/xiaoyuan1996/controllable-fake-sample-generation-for-rs.",AB_0281
"recently, hyperspectral image classification (hic) with noisy labels is attracting increasing interest. however, existing methods usually neglect to explore feature-dependent knowledge to reduce label noise and, thus, perform poorly when the noise ratio is high or the clean samples are limited. in this article, a novel triple contrastive representation learning (tcrl) framework is proposed from a deep clustering perspective for robust hic with noisy labels. the tcrl explores the cluster-, instance-, and structure-level representations of hic by defining triple learning loss. first, the strong and weak transformations are defined for hyperspectral data augmentation. then, a simple yet effective lightweight spectral prior attention-based network (span) is presented for spatial-spectral feature extraction of all augmented samples. in addition, cluster- and instance-level contrastive learnings are performed on two projection subspaces for clustering and distinguishing samples, respectively. meanwhile, structure-level representation learning is employed to maximize the consistency of data after different projections. taking the feature-dependent information learned by triple representation learning, our proposed end-to-end tcrl can effectively alleviate the overfitting of classifiers to noisy labels. extensive experiments have been taken on three public datasets with various noise ratios and two types of noise. the results show that the proposed tcrl could provide more robust classification results when training on noisy datasets compared with state-of-the-art methods, especially when clean samples are limited. the code will be available at https://github.com/zhangxy1999.",AB_0281
"ultrasonography is a widely used medical imaging technique for detecting breast cancer. while manual diagnostic methods are subject to variability and time-consuming, computer-aided diagnostic (cad) methods have proven to be more efficient. however, current cad approaches neglect the impact of noise and artifacts on the accuracy of image analysis. to enhance the precision of breast ultrasound image analysis for identifying tissues, organs and lesions, we propose a novel approach for improved tumor classification through a dual-input model and global average pooling (gap)-guided attention loss function. our approach leverages a convolutional neural network with transformer architecture and modifies the single-input model for dual-input. this technique employs a fusion module and gap operation-guided attention loss function simultaneously to supervise the extraction of effective features from the target region and mitigate the effect of information loss or redundancy on misclassification. our proposed method has three key features: (i) resnet and mobilevit are combined to enhance local and global information extraction. in addition, a dual-input channel is designed to include both attention images and original breast ultrasound images, mitigating the impact of noise and artifacts in ultrasound images. (ii) a fusion module and gap operation-guided attention loss function are proposed to improve the fusion of dual-channel feature information, as well as supervise and constrain the weight of the attention mechanism on the fused focus region. (iii) using the collected uterine fibroid ultrasound dataset to train resnet18 and load the pre-trained weights, our experiments on the busi and busc public datasets demonstrate that the proposed method outperforms some stateof-the-art methods. the code will be publicly released at https://github.com/425877/improved-breast-ultrasound-tumor-classification.",AB_0281
"capturing screen content by smart-phone cameras has become a daily routine to record or share instant information from display screens for convenience. however, these recaptured screen images are often degraded by moire patterns and usually present color cast against the original screen source. we observe that performing demoireing in raw domain before feeding into the image signal processor (isp) is more effective than demoireing in the srgb domain as done in recent demoireing works. in this paper, we investigate the demoireing of raw images through a class-specific learning approach. to this end, we build the first well-aligned raw moire image dataset by pixel-wise alignment between the recaptured images and source ones. noting that document images occupy a large portion of screen contents and have different properties from generic images, we propose a class-specific learning strategy for textual images and natural color images. in addition, to deal with moire patterns with various scales, a multi-scale encoder with multi-level feature fusion is proposed. the shared encoder enables us to extract rich representations for the two kinds of contents and the class-specific decoders benefit the specific content reconstruction by focusing on targeted representations. experiment results demonstrate that our method achieves state-of-the-art demoireing performance. we have released the code and dataset in https://github.com/tju-chengyijia/rdnet",AB_0281
"hyperspectral unmixing (hu) based on the linear mixing model (lmm) has received much attention in the remote sensing community over the past decades. however, many hu algorithms are based on the fixed endmember and do not fully exploit the inherent spatial characteristics of the hyperspectral image (hsi). in this letter, a new hu algorithm named graph laplacian regularization based on l(1)-norm-gaussian mixture model (glr(l1)-gmm) is proposed to solve these problems. we use gmm to represent the endmember variability. then, considering the local smoothness in the abundance map, a glr(l1 )is embedded in the prior abundance. under the bayesian framework, the objective density function leads to a maximum posterior (map) problem, which can be solved by a generalized expectation-maximization (gem) algorithm. experiments on two real datasets demonstrate the effectiveness of the proposed algorithm compared with other state-of-the-art methods. the source code is available at https://github.com/lwdinwhu/ gmm-glrl1.",AB_0281
"limited by the imaging paradigm, stripes are pervasive in remote sensing scenes, and its intensity, density, and periodicity differ dramatically among different imaging systems. worse, it always coexists with random noises caused by unstable imaging condition. however, current destriping methods are victim to undue ideal assumptions and fail to accurately eliminate stripes against diverse practical degradation, yielding excessive or inadequate destriping results. this study proposes a progressive hyperspectral destriping method with an adaptive frequency focus for accurate destriping and delicate restoration. specifically, a hierarchical decomposition and reconstruction framework based on progressive wavelet learning encodes the degraded input to the frequency domain with smaller scales, easing the difficulty of restoration. then, to avoid excessive or insufficient destriping, we devote specific efforts to finely separating noise and preserving details in the high-frequency domain. first, we devise a gradient-aware frequency attention block based on the prominent unidirectional pattern of stripes, empowering to adaptively assign weights according to their sensitivity to the spatial gradient. second, we design a focal high-frequency loss item that is dynamically scaled according to the feature distance in the high-frequency domain, profiting in identifying and preserving details. extensive experiments conducted on data with synthetic stripes and realistic satellite scenes validate the superiority of the proposed method over the current state-of-the-art methods. the code is available at https://github.com/etpan/phid.",AB_0281
"abundant spectral signatures and spatial characteristics embedded in hyperspectral (hs) images enable the fine identification of land covers, attracting plenty of studies on feature extraction (fe) and feature utilization. nevertheless, the high representative spectral and spatial features in the hs cube are unevenly distributed, which is failed to consider by many current methods. to conquer this shortcoming, we rethink the fe of hs images from an anisotropic perspective and propose a novel model called grid network (gnet) for hs image classification (hsic). beyond representing spectral-spatial features in three classic paradigms (simultaneously, hierarchically, and separately), gnet is capable of learning them in two new processes: multistage and multipath. in this way, spectral and spatial features can be fully and balanced explored. more significantly, to make full use of low- and high-level features and avoid the existing semantic gap, we devise a spectral-spatial cross-level feature fusion (s2clf2) module to model the relationship between them. extensive experiments, implemented on three hs datasets, demonstrate that the proposed gnet enables to acquire promising classification performance compared with state-of-the-art methods. the codes of this work will be available at https://github.com/zhonghaochen/gnet_master for the sake of reproducibility.",AB_0281
"remote sensing images provide us with rich information for extracting road networks. however, there are still great challenges ahead, such as occlusions caused by trees and shadows, and complex topology. in this work, we focus on the topology of road networks. inspired by the observation that road networks are composed of road fragments in a bottom-up way and the breaks between fragments tend to be connected within a local area, we propose a topology-enhanced road network extraction (termed ternformer) method by exploring local connectivity. first, a transformer-based network is built for road feature extraction to capture long-range context. furthermore, we propose parallel depthwise separable dilated convolution blocks (dsdbs) to extract local information within different ranges. thereafter, a minimum spanning tree-based local structure exploring block (lseb) is built to enhance the topology of the road network. finally, a simple but effective shortest path-based method is used to refine the road network connectivity within a local threshold. experiments conducted on two datasets demonstrate the superiority of ternformer. ternformer outperforms the state-of-the-art methods on the cityscale dataset with the best topology performance. the result on the deepglobe dataset improves by 4.83% average path length similarity (apls) compared to state-of-the-art methods. code is available at https://github.com/dawn-bin/ternformer.",AB_0281
