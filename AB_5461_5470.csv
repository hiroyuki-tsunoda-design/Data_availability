AB,NO
"flow cytometry (fcm) can investigate dozens of parameters from millions of cells and hundreds of specimens in a short time and at a reasonable cost, but the amount of data that is generated is considerable. computational approaches are useful to identify novel subpopulations and molecular biomarkers, but generally require deep expertize in bioinformatics and the use of different platforms. to overcome these limitations, we introduce crusty, an interactive, user-friendly webtool incorporating the most popular algorithms for fcm data analysis, and capable of visualizing graphical and tabular results and automatically generating publication -quality figures within minutes. crusty also hosts an interactive interface for the exploration of results in real time. thus, crusty enables a large number of users to mine complex datasets and reduce the time required for data exploration and interpretation. crusty is accessible at https://crusty.humanitas.it/.",AB_0547
"partially observable monte carlo planning (pomcp) is a powerful online algorithm that can generate approximate policies for large partially observable markov decision processes. the online nature of this method supports scalability by avoiding complete policy representation. however, the lack of an explicit policy representation hinders interpretability and a proper evaluation of the risks an agent may incur. in this work, we propose a methodology based on maximum satisfiability modulo theory (max-smt) for analyzing pomcp policies by inspecting their traces, namely, sequences of belief action pairs generated by the algorithm. the proposed method explores local properties of the policy to build a compact and informative summary of the policy behaviour. moreover, we introduce a rich and formal language that a domain expert can use to describe the expected behaviour of a policy. in more detail, we present a formulation that directly computes the risk involved in taking actions by considering the highlevel elements specified by the expert. the final formula can identify risky decisions taken by pomcp that violate the expert indications. we show that this identification process can be used offline (to improve the policy's explainability and identify anomalous behaviours) or online (to shield the risky decisions of the pomcp algorithm). we present an extended evaluation of our approach on four domains: the well-known tiger and rocksample benchmarks, a problem of velocity regulation in mobile robots, and a problem of battery management in mobile robots. we test the methodology against a state-ofthe-art anomaly detection algorithm to show that our approach can be used to identify anomalous behaviours in faulty pomcp. we also show, comparing the performance of shielded and unshielded pomcp, that the shielding mechanism can improve the system's performance. we provide an open-source implementation of the proposed methodologies at https://github .com /giumaz /xpomcp.& copy; 2023 the author(s). published by elsevier b.v. this is an open access article under the cc by license ( .org /licenses /by /4 .0/).",AB_0547
"motivation: coiled-coil domains (ccd) are widespread in all organisms and perform several crucial functions. given their relevance, the computational detection of ccd is very important for protein functional annotation. state-of-the-art prediction methods include the precise identification of ccd boundaries, the annotation of the typical heptad repeat pattern along the coiled-coil helices as well as the prediction of the oligomerization state. results: in this article, we describe coconat, a novel method for predicting coiled-coil helix boundaries, residue-level register annotation, and oligomerization state. our method encodes sequences with the combination of two state-of-the-art protein language models and implements a three-step deep learning procedure concatenated with a grammatical-restrained hidden conditional random field for ccd identification and refinement. a final neural network predicts the oligomerization state. when tested on a blind test set routinely adopted, coconat obtains a performance superior to the current state-of-the-art both for residue-level and segment-level ccd. coconat significantly outperforms the most recent state-of-the-art methods on register annotation and prediction of oligomerization states. availability and implementation: coconat web server is available at https://coconat.biocomp.unibo.it. standalone version is available on github at https://github.com/bolognabiocomp/coconat.",AB_0547
"electronic transport coefficients such as the electrical conductivity, the termo-power, and the charge carrier concentration are routinely measured in a variety of application areas such as electronics or thermoelectric power-generation and cooling. using fitting procedures, those measurements are used to infer microscopic features of the samples. the code m*2t facilitates the estimation of electronic structure parameters such as the effective masses and band energies improving the current approach by increasing the complexity of the band structure representation. the software is designed with a server-client architecture to enhance performance and scalability. the server is implemented in the julia programming language. we illustrate the design and the efficiency of the code with selected applications, which are relevant to the optimization of thermoelectric materials. program summary program title: m*2t cpc library link to program files: https://doi .org /10 .17632 /494nj6ftbv.1 developer's repository link: https://github .com /marcofornari /etransport .git licensing provisions: gplv3 programming language: julia, python. nature of problem: electronic transport measurements are routinely used to link the functional properties exploited in electronics and energy sciences applications with the underlying electronic structure of the material under investigation. experimentalists collect data of derived and integrated physical quantities, from which they estimate properties and parameters, e.g., nature of the conduction mechanisms and effective mass. the interpretation is based on simplistic models that rarely represent the complexity of the band structure. the code m*2t improves the current state of the art and facilitates the estimation of effective masses and energies from experimental measurements of electrical conductivity, seebeck coefficients, and carrier concentration using a multi-valley anisotropic parabolic band structure as a model for the unknown real band structure. experimental data can be imported and visualized to facilitate the comparison with theoretical analysis. solution method: the boltzmann equation within the relaxation-time approximation is used to compute the electronic transport tensors from the electronic density of states characterized in terms of a set of effective masses tensors m*i and critical energies ei. numerical and analytical techniques are adopted to integrate the boltzmann equation efficiently. by tuning the features of the density of states, temperature, fermi level, and the functional expression for the relaxation time, the software streamlines the reconstruction of the underlying electronic properties from experimental data. additional comments including restrictions and unusual features: the software is designed with a serverclient architecture to enhance performance and scalability. the server is implemented in the julia programming language as a stand-alone library. it performs all the numerical operations to compute the transport tensors from a set of multi-valley parabolic band structures. the client is implemented either",AB_0547
"the development of small molecules that selectively target the cannabinoid receptor subtype 2 (cb2r) is emerging as an intriguing therapeutic strategy to treat neurodegeneration, as well as to contrast the onset and progression of cancer. in this context, in-silico tools able to predict cb2r affinity and selectivity with respect to the subtype 1 (cb1r), whose modulation is responsible for undesired psychotropic effects, are highly desirable. in this work, we developed a series of machine learning classifiers trained on high-quality bioactivity data of small molecules acting on cb2r and/or cb1r extracted from chembl v30. our classifiers showed strong pre-dictive power in accurately determining cb2r affinity, cb1r affinity, and cb2r/cb1r selectivity. among the built models, those obtained using random forest as algorithm proved to be the top-performing ones (auc in validation & ge;0.96) and were made freely accessible through a user-friendly web platform developed ad hoc and called alpaca (https://www.ba.ic.cnr.it/softwareic/alpaca/). due to its user-friendly interface and robust predictive power, alpaca can be a valuable tool in saving both time and resources involved in the design of selective cb2r modulators.",AB_0547
"maintaining good surface water quality is crucial to protect ecosystem health and for safeguarding human wa-ter use activities. however, our quantitative understanding of surface water quality is mostly predicated upon observa-tions at monitoring stations that are highly limited in space and fragmented across time. physical models based upon pollutant emissions and subsequent routing through the hy-drological network provide opportunities to overcome these shortcomings. to this end, we have developed the dynamical surface water quality model (dynqual) for simulating water temperature (t-w) and concentrations of total dissolved solids (tds), biological oxygen demand (bod) and fecal coliform (fc) with a daily time step and at 5 arcmin (similar to 10 km) spatial resolution. here, we describe the main components of this new global surface water quality model and evaluate model performance against in situ water quality observations. fur-thermore, we describe both the spatial patterns and temporal trends in tds, bod and fc concentrations for the period 1980-2019, and we also attribute the dominant contribut-ing sectors to surface water pollution. modelled output in-dicates that multi-pollutant hotspots are especially prevalent across northern india and eastern china but that surface wa-ter quality issues exist across all world regions. trends to-wards water quality deterioration have been most profound in the developing world, particularly sub-saharan africa and south asia. the model code is available open source (https://doi.org/10.5281/zenodo.7932317, jones et al., 2023), and we provide global datasets of simulated hydrology, t-w, tds, bod and fc at 5 arcmin resolution with a monthly time step (https://doi.org/10.5281/zenodo.7139222, jones et al., 2022b). these data have the potential to inform assess-ments in a broad range of fields, including ecological, human health and water scarcity studies.",AB_0547
"the present contribution introduces a novel computationalprotocolcalled pyrmd2dock, which combines the ligand-based virtual screening(lbvs) tool pyrmd with the popular docking software autodock-gpu (ad4-gpu) to enhance the throughput of virtual screening campaignsfor drug discovery. by implementing pyrmd2dock, we demonstrate thatit is possible to rapidly screen massive chemical databases and identifythose with the highest predicted binding affinity to a target protein.our benchmarking and screening experiments illustrate the predictivepower and speed of pyrmd2dock and highlight its potential to acceleratethe discovery of novel drug candidates. overall, this study showcasesthe value of combining ai-powered lbvs tools with docking softwareto enable effective and high-throughput virtual screening of ultralargemolecular databases in drug discovery. pyrmd and the pyrmd2dock protocolare freely available on github (https://github.com/cosconatilab/pyrmd) as an open-source tool.",AB_0547
"software systems that learn from data with machine learning (ml) are used in critical decision-making processes. unfortunately, real-world experience shows that the pipelines for data preparation, feature encoding and model training in ml systems are often brittle with respect to their input data. as a consequence, data scientists have to run different kinds of data centric what-if analyses to evaluate the robustness and reliability of such pipelines, e.g., with respect to data errors or preprocessing techniques. these what-if analyses follow a common pattern: they take an existing ml pipeline, create a pipeline variant by introducing a small change, and execute this variant to see how the change impacts the pipeline's output score. we recently proposed mlwhatif, a library that enables data scientists to declaratively specify what-if analyses for an ml pipeline, and to automatically generate, optimize and execute the required pipeline variants. we demonstrate how data scientists can leverage mlwhatif for a variety of pipelines and three different what-if analyses focusing on the robustness of a pipeline against data errors, the impact of data cleaning operations, and the impact of data preprocessing operations on fairness. in particular, we demonstrate step-by-step how mlwhatif generates and optimizes the required execution plans for the pipeline analyses. our library is publicly available at https://github.com/stefan- grafberger/mlwhatif.",AB_0547
"background: the growing power and ever decreasing cost of rna sequencing (rnaseq) technologies have resulted in an explosion of rna-seq data production. comparing gene expression values within rna-seq datasets is relatively easy for many interdisciplinary biomedical researchers; however, user-friendly software applications increase the ability of biologists to efficiently explore available datasets. results: here, we describe rogue (rna-seq ontology graphic user environment, https://marisshiny.research.chop.edu/rogue/), a user-friendly r shiny application that allows a biologist to perform differentially expressed gene analysis, gene ontology and pathway enrichment analysis, potential biomarker identification, and advanced statistical analyses. we use rogue to identify potential biomarkers and show unique enriched pathways between various immune cells. conclusions: user-friendly tools for the analysis of next generation sequencing data, such as rogue, will allow biologists to efficiently explore their datasets, discover expression patterns, and advance their research by allowing them to develop and test hypotheses.",AB_0547
"motivation: the process of drug development is inherently complex, marked by extended intervals from the inception of a pharmaceutical agent to its eventual launch in the market. additionally, each phase in this process is associated with a significant failure rate, amplifying the inherent challenges of this task. computational virtual screening powered by machine learning algorithms has emerged as a promising approach for predicting therapeutic efficacy. however, the complex relationships between the features learned by these algorithms can be challenging to decipher. results: we have engineered an artificial neural network model designed specifically for predicting drug sensitivity. this model utilizes a biologically informed visible neural network, thereby enhancing its interpretability. the trained model allows for an in-depth exploration of the biological pathways integral to prediction and the chemical attributes of drugs that impact sensitivity. our model harnesses multiomics data derived from a different tumor tissue sources, as well as molecular descriptors that encapsulate the properties of drugs. we extended the model to predict drug synergy, resulting in favorable outcomes while retaining interpretability. given the imbalanced nature of publicly available drug screening datasets, our model demonstrated superior performance to state-of-the-art visible machine learning algorithms. availability and implementation: movida is implemented in python using pytorch library and freely available for download at https://github. com/luigi-ferraro/movida. training data, ris score and drug features are archived on zenodo https://doi.org/10.5281/zenodo.8180380.",AB_0547
