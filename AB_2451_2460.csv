AB,NO
"pathogen detection from biological and environmental samples is important for global disease control. despite advances in pathogen detection using deep learning, current algorithms have limitations in processing long genomic sequences. through the deep cross fusion of cross, residual and deep neural networks, we developed dcipatho for accurate pathogen detection based on the integrated frequency features of 3-to-7 k-mers. compared with the existing state-of-the-art algorithms, dcipatho can be used to accurately identify distinct pathogenic bacteria infecting humans, animals and plants. we evaluated dcipatho on both learned and unlearned pathogen species using both genomics and metagenomics datasets. dcipatho is an effective tool for the genomic-scale identification of pathogens by integrating the frequency of k-mers into deep cross-fusion networks. the source code is publicly available at https://github.com/ lormebioai/dcipatho.",AB_0246
"in the field of weakly supervised semantic segmentation (wsss), class activation maps (cam) are typically adopted to generate pseudo masks. yet, we find that the crux of the unsatisfactory pseudo masks is the incomplete cam. specifically, as convolutional neural networks tend to be dominated by the specific regions in the high-confidence channels of feature maps during prediction, the extracted cam contains only parts of the object. to address this issue, we propose the disturbed cam (dcam), a simple yet effective method for wsss. following cam, we adopt a binary cross-entropy (bce) loss to train a multi-label classification model. then, we disturb the feature map with retraining to enhance the high-confidence channels. in addition, a softmax cross-entropy (sce) loss branch is employed to increase the model attention to the target classes. once converged, we extract dcam in the same way as in cam. the evaluation on both pascal voc and ms coco shows that dcam not only generates high-quality masks (6.2% and 1.4% higher than the benchmark models), but also enables more accurate activation in object regions. the code is available at https://github.com/gyyang23/dcam.",AB_0246
"imaging genetics is a crucial tool that is applied to explore potentially disease-related biomarkers, particularly for neurodegenerative diseases (nds). with the development of imaging technology, the association analysis between multimodal imaging data and genetic data is gradually being concerned by a wide range of imaging genetics studies. however, multimodal data are fused first and then correlated with genetic data in traditional methods, which leads to an incomplete exploration of their common and complementary information. in addition, the inaccurate formulation in the complex relationships between imaging and genetic data and information loss caused by missing multimodal data are still open problems in imaging genetics studies. therefore, in this study, a deep multimodality-disentangled association analysis network (dmaan) is proposed to solve the aforementioned issues and detect the disease-related biomarkers of nds simultaneously. first, the imaging data are nonlinearly projected into a latent space and imaging representations can be achieved. the imaging representations are further disentangled into common and specific parts by using a multimodal-disentangled module. second, the genetic data are encoded to achieve genetic representations, and then, the achieved genetic representations are nonlinearly mapped to the common and specific imaging representations to build nonlinear associations between imaging and genetic data through an association analysis module. moreover, modality mask vectors are synchronously synthesized to integrate the genetic and imaging data, which helps the following disease diagnosis. finally, the proposed method achieves reasonable diagnosis performance via a disease diagnosis module and utilizes the label information to detect the disease-related modality-shared and modality-specific biomarkers. furthermore, the genetic representation can be used to impute the missing multimodal data with our learning strategy. two publicly available datasets with different nds are used to demonstrate the effectiveness of the proposed dmaan. the experimental results show that the proposed dmaan can identify the disease-related biomarkers, which suggests the proposed dmaan may provide new insights into the pathological mechanism and early diagnosis of nds. the codes are publicly available at https://github.com/meiyan88/dmaan.",AB_0246
"automatic segmentation of vertebral bodies (vbs) and intervertebral discs (ivds) in 3d magnetic resonance (mr) images is vital in diagnosing and treating spinal diseases. however, segmenting the vbs and ivds simultaneously is not trivial. moreover, problems exist, including blurry segmentation caused by anisotropy resolution, high computational cost, inter-class similarity and intra-class variability, and data imbalances. we proposed a two-stage algorithm, named semi-supervised hybrid spine network (sshsnet), to address these problems by achieving accurate simultaneous vb and ivd segmentation. in the first stage, we constructed a 2d semi-supervised deeplabv3+ by using cross pseudo supervision to obtain intra-slice features and coarse segmentation. in the second stage, a 3d full-resolution patch-based deeplabv3+ was built. this model can be used to extract inter-slice information and combine the coarse segmentation and intra-slice features provided from the first stage. moreover, a cross tri-attention module was applied to compensate for the loss of inter-slice and intra-slice information separately generated from 2d and 3d networks, thereby improving feature representation ability and achieving satisfactory segmentation results. the proposed sshsnet was validated on a publicly available spine mr image dataset, and remarkable segmentation performance was achieved. moreover, results show that the proposed method has great potential in dealing with the data imbalance problem. based on previous reports, few studies have incorporated a semi-supervised learning strategy with a cross attention mechanism for spine segmentation. therefore, the proposed method may provide a useful tool for spine segmentation and aid clinically in spinal disease diagnoses and treatments. codes are publicly available at: https://github.com/meiyan88/sshsnet.",AB_0246
"background: single-cell rna sequencing (scrna-seq) strives to capture cellular diversity with higher resolution than bulk rna sequencing. clustering analysis is critical to transcriptome research as it allows for further identification and discovery of new cell types. unsupervised clustering cannot integrate prior knowledge where relevant information is widely available. purely unsupervised clustering algorithms may not yield biologically interpretable clusters when confronted with the high dimensional-ity of scrna-seq data and frequent dropout events, which makes identification of cell types more challenging.results: we propose scsemiaae, a semi-supervised clustering model for scrna sequence analysis using deep generative neural networks. specifically, scsemiaae carefully designs a zinb adversarial autoencoder-based architecture that inherently integrates adversarial training and semi-supervised modules in the latent space. in a series of experiments on scrna-seq datasets spanning thousands to tens of thousands of cells, scsemiaae can significantly improve clustering performance compared to dozens of unsupervised and semi-supervised algorithms, promoting clustering and interpretability of downstream analyses.conclusion: scsemiaae is a python-based algorithm implemented on the vscode platform that provides efficient visualization, clustering, and cell type assignment for scrna-seq data. the tool is available from https://github.com/whang98/scsemiaae.",AB_0246
"motivation: biomedical named entity recognition (bioner) seeks to automatically recognize biomedical entities in natural language text, serving as a necessary foundation for downstream text mining tasks and applications such as information extraction and question answering. manually labeling training data for the bioner task is costly, however, due to the significant domain expertise required for accurate annotation. the resulting data scarcity causes current bioner approaches to be prone to overfitting, to suffer from limited generalizability, and to address a single entity type at a time (e.g. gene or disease). results: we therefore propose a novel all-in-one (aio) scheme that uses external data from existing annotated resources to enhance the accuracy and stability of bioner models. we further present aioner, a general-purpose bioner tool based on cutting-edge deep learning and our aio schema. we evaluate aioner on 14 bioner benchmark tasks and show that aioner is effective, robust, and compares favorably to other state-of-the-art approaches such as multi-task learning. we further demonstrate the practical utility of aioner in three independent tasks to recognize entity types not previously seen in training data, as well as the advantages of aioner over existing methods for processing biomedical text at a large scale (e.g. the entire pubmed data). availability and implementation: the source code, trained models and data for aioner are freely available at https://github.com/ncbi/aioner.",AB_0246
"n-7-methylguanosine(m(7)g) is a crucial post-transcriptionalrna modification that plays a pivotal role in regulating gene expression.accurately identifying m(7)g sites is a fundamental stepin understanding the biological functions and regulatory mechanismsassociated with this modification. while whole-genome sequencing isthe gold standard for rna modification site detection, it is a time-consuming,expensive, and intricate process. recently, computational approaches,especially deep learning (dl) techniques, have gained popularity inachieving this objective. convolutional neural networks and recurrentneural networks are examples of dl algorithms that have emerged asversatile tools for modeling biological sequence data. however, developingan efficient network architecture with superior performance remainsa challenging task, requiring significant expertise, time, and effort.to address this, we previously introduced a tool called autobioseqpy,which streamlines the design and implementation of dl networks forbiological sequence classification. in this study, we utilized autobioseqpyto develop, train, evaluate, and fine-tune sequence-level dl modelsfor predicting m(7)g sites. we provided detailed descriptionsof these models, along with a step-by-step guide on their execution.the same methodology can be applied to other systems dealing withsimilar biological questions. the benchmark data and code utilizedin this study can be accessed for free at http://github.com/jingry/autobioseeqpy/tree/2.0/examples/m7g.",AB_0246
"background: structural variations (svs) refer to variations in an organism's chromosome structure that exceed a length of 50 base pairs. they play a significant role in genetic diseases and evolutionary mechanisms. while long-read sequencing technology has led to the development of numerous sv caller methods, their performance results have been suboptimal. researchers have observed that current sv callers often miss true svs and generate many false svs, especially in repetitive regions and areas with multi-allelic svs. these errors are due to the messy alignments of long-read data, which are affected by their high error rate. therefore, there is a need for a more accurate sv caller method. result: we propose a new method-svcnn, a more accurate deep learning-based method for detecting svs by using long-read sequencing data. we run svcnn and other sv callers in three real datasets and find that svcnn improves the f1-score by 2-8% compared with the second-best method when the read depth is greater than 5x. more importantly, svcnn has better performance for detecting multi-allelic svs. conclusions: svcnn is an accurate deep learning-based method to detect svs. the program is available at https://github.com/nwpuzhengyan/svcnn.",AB_0246
"efficient and accurate distinction of histopathological subtype of lung cancer is quite critical for the indi-vidualized treatment. so far, artificial intelligence techniques have been developed, whose performance yet remained debatable on more heterogenous data, hindering their clinical deployment. here, we propose an end-to-end, well-generalized and data-efficient weakly supervised deep learning-based method. the method, end-to-end feature pyramid deep multi-instance learning model (e2efp-mil), contains an iterative sampling module, a trainable feature pyramid module and a robust feature aggregation module. e2efp-mil uses end-to-end learning to extract generalized morphological features automatically and identify discriminative histomorphological patterns. this method is trained with 1007 whole slide images (wsis) of lung cancer from tcga, with aucs of 0.95-0.97 in test sets. we validated e2efp-mil in 5 real-world external heterogenous cohorts including nearly 1600 wsis from both united states and china with aucs of 0.94-0.97, and found that 100-200 training images are enough to achieve an auc of >0.9. e2efp-mil overperforms multiple state-of-the-art mil-based methods with high accuracy and low hardware requirements. excellent and robust results prove generalizability and effectiveness of e2efp-mil in clinical practice. our code is available at https://github.com/raycaohmu/e2efp-mil.",AB_0246
"with the continuous development of deep learning, neural networks have made great progress in license plate recognition (lpr). nevertheless, there is still room to improve the performance of license plate recognition for low-resolution and relatively blurry images in remote surveillance scenarios. when it is difficult to enhance the recognition algorithm, we choose super-resolution (sr) to improve the quality of license plate images and thereby provide clearer input for the subsequent recognition stage. in this paper, we propose an automatic super-resolution license plate recognition (srlpr) network which consists of four parts separately: license plate detection, character detection, single character super-resolution, and recognition. in the training stage, firstly, lp detection model needs to be trained alone and then its detection results will be used to successively train the three subsequent modules. during the test phase, for each input image, the network can get its lp number automatically. we also collect an applicable and challenging lpr dataset called srlp, which is collected from real remote traffic surveillance. the experimental results demonstrate that our method achieves comprehensive quality of sr images and higher recognition accuracy compared with state-of-the-art methods. the srlp dataset and the code for training and testing srlpr network are available at https://pan.baidu.com/s/1vnhra-c-dbj6jlfbzv5w4g.",AB_0246
