AB,NO
"motivation: high-quality computational structural models are now precomputed and available for nearly every protein in uniprot. however, the best way to leverage these models to predict which pairs of proteins interact in a high-throughput manner is not immediately clear. the recent foldseek method of van kempen et al. encodes the structural information of distances and angles along the protein backbone into a linear string of the same length as the protein string, using tokens from a 21-letter discretized structural alphabet (3di). results: we show that using both the amino acid sequence and the 3di sequence generated by foldseek as inputs to our recent deep-learning method, topsy-turvy, substantially improves the performance of predicting protein-protein interactions cross-species. thus tt3d (topsy-turvy 3d) presents a way to reuse all the computational effort going into producing high-quality structural models from sequence, while being sufficiently lightweight so that high-quality binary protein-protein interaction predictions across all protein pairs can be made genome-wide. availability and implementation: tt3d is available at https://github.com/samsledje/d-script. an archived version of the code at time of submission can be found at https://zenodo.org/records/10037674.",AB_0597
"there are compelling reasons to test compositional hypotheses about microbiome data. we present here linear decomposition model-centered log ratio (ldm-clr), an extension of our ldm approach to allow fitting linear models to centered-log-ratio-transformed taxa count data. as ldm-clr is implemented within the existing ldm program, this extension enjoys all the features supported by ldm, including a compositional analysis of differential abundance at both the taxon and community levels, while allowing for a wide range of covariates and study designs for either association or mediation analysis. availability and implementation: ldm-clr has been added to the r package ldm, which is available on github at https://github.com/yijuanhu/ldm.",AB_0597
"many tools and algorithms are available for analyzing transcriptomics data. these include algorithms for performing sequence alignment, data normalization and imputation, clustering, identifying differentially expressed genes, and performing gene set enrichment analysis. to make the best choice about which tools to use, objective benchmarks can be developed to compare the quality of different algorithms to extract biological knowledge maximally and accurately from these data. the dexamethasone benchmark (dex-benchmark) resource aims to fill this need by providing the community with datasets and code templates for benchmarking different gene expression analysis tools and algorithms. the resource provides access to a collection of curated rna-seq, l1000, and chip-seq data from dexamethasone treatment as well as genetic perturbations of its known targets. in addition, the website provides jupyter notebooks that use these pre-processed curated datasets to demonstrate how to benchmark the different steps in gene expression analysis. by comparing two independent data sources and data types with some expected concordance, we can assess which tools and algorithms best recover such associations. to demonstrate the usefulness of the resource for discovering novel drug targets, we applied it to optimize data processing strategies for the chemical perturbations and crispr single gene knockouts from the l1000 transcriptomics data from the library of integrated network cellular signatures (lincs) program, with a focus on understudied proteins from the illuminating the druggable genome (idg) program. overall, the dex-benchmark resource can be utilized to assess the quality of transcriptomics and other related bioinformatics data analysis workflows. the resource is available from: https://maayanlab.github.io/dex-benchmark.",AB_0597
"the analysis of stable isotope labeling experiments requires accurate, efficient, and reproducible quantification of mass isotopomer distributions (mids), which is not a core feature of general-purpose metabolomics software tools that are optimized to quantify metabolite abundance. here, we present piramid (program for integration and rapid analysis of mass isotopomer distributions), a matlab-based tool that addresses this need by offering a user-friendly, graphical user interface-driven program to automate the extraction of isotopic information from mass spectrometry (ms) datasets. this tool can simultaneously extract ion chromatograms for various metabolites from multiple data files in common vendor-agnostic file formats, locate chromatographic peaks based on a targeted list of characteristic ions and retention times, and integrate mids for each target ion. these mids can be corrected for natural isotopic background based on the user-defined molecular formula of each ion. piramid offers support for datasets acquired from low- or high-resolution ms, and single (ms) or tandem (ms/ms) instruments. it also enables the analysis of single or dual labeling experiments using a variety of isotopes (i.e. h-2, c-13, n-15, o-18, s-34). data availability and implementation: matlab p-code files are freely available for non-commercial use and can be downloaded from https://mfa.vueinnovations.com/. commerciallicenses are also available. all the data presented in this publication are available under the help_menu folder of the piramid software. [graphics] .",AB_0597
"backgroundpatients experience atrial fibrillation (af) as a complex disease given its adversity, chronicity, and necessity for long-term treatments. few studies have examined the experience of rural individuals with af. we conducted qualitative assessments of patients with af residing in rural, western pennsylvania to identify barriers and facilitators to care.methods and resultswe conducted 8 semistructured virtual focus groups with 42 individuals living in rural western pennsylvania using contextually tailored questions to assess participant perspectives. we inductively analyzed focus group transcripts using paragraph-by-paragraph and focused coding to identify themes with the qualitative description approach. we used krippendorff alpha scoring to determine interreviewer reliability. we harnessed investigator triangulation to augment the reliability of our findings. we reached thematic saturation after coding 8 focus groups. participants were 52.4% women, with a median age of 70.9 years (range, 54.5-82.0 years), and most were white race (92.9%). participants identified medication costliness, invisibility of af to others, and lack of emergent transportation as barriers to care. participants described interpersonal support and use of technology as important for af self-care, and expressed ambivalence about how relationships with health care providers affected af care.conclusionsfocus group participants described multiple social and structural barriers to care for af. our findings highlight the complexity of the experience of individuals with af residing in rural western pennsylvania.registrationurl: https://www.clinicaltrials.gov; unique identifier: nct 04076020.",AB_0597
"the big-data analysis of complex data associated with maize genomes accelerates genetic research and improves agronomic traits. as a result, efforts have increased to integrate diverse datasets and extract meaning from these measurements. machine learning models are a powerful tool for gaining knowledge from large and complex datasets. however, these models must be trained on high-quality features to succeed. currently, there are no solutions to host maize multi-omics datasets with end-to-end solutions for evaluating and linking features to target gene annotations. our work presents the maize feature store (mfs), a versatile application that combines features built on complex data to facilitate exploration, modeling and analysis. feature stores allow researchers to rapidly deploy machine learning applications by managing and providing access to frequently used features. we populated the mfs for the maize reference genome with over 14 000 gene-based features based on published genomic, transcriptomic, epigenomic, variomic and proteomics datasets. using the mfs, we created an accurate pan-genome classification model with an auc-roc score of 0.87. the mfs is publicly available through the maize genetics and genomics database.database url https://mfs.maizegdb.org/",AB_0597
"motivation while there are software packages that analyze boolean, ternary, or other multi-state models, none compute the complete state space of function-based models over any finite set. results: we propose cyclone, a simple light-weight software package which simulates the complete state space for a finite dynamical system over any finite set.availability and implementation source code is freely available at https://github.com/discretedynamics/cyclone under the apache-2.0 license.",AB_0597
"motivation phecodes are widely used and easily adapted phenotypes based on international classification of diseases codes. the current version of phecodes (v1.2) was designed primarily to study common/complex diseases diagnosed in adults; however, there are numerous limitations in the codes and their structure.results here, we present phecodex, an expanded version of phecodes with a revised structure and 1,761 new codes. phecodex adds granularity to phenotypes in key disease domains that are under-represented in the current phecode structure-including infectious disease, pregnancy, congenital anomalies, and neonatology-and is a more robust representation of the medical phenome for global use in discovery research.availability and implementation phecodex is available at https://github.com/phewas/phecodex.",AB_0597
"backgroundmicrohaplotypes have the potential to be more cost-effective than snps for applications that require genetic panels of highly variable loci. however, development of microhaplotype panels is hindered by a lack of methods for estimating microhaplotype allele frequency from low-coverage whole genome sequencing or pooled sequencing (pool-seq) data.resultswe developed new methods for estimating microhaplotype allele frequency from low-coverage whole genome sequence and pool-seq data. we validated these methods using datasets from three non-model organisms. these methods allowed estimation of allele frequency and expected heterozygosity at depths routinely achieved from pooled sequencing.conclusionsthese new methods will allow microhaplotype panels to be designed using low-coverage wgs and pool-seq data to discover and evaluate candidate loci. the python script implementing the two methods and documentation are available at https://www.github.com/delomast/mhfromlowdepseq.",AB_0597
"progressive supranuclear palsy (psp) is a neurodegenerative parkinsonian disorder characterized by cell-type-specific tau lesions in neurons and glia. prior work uncovered transcriptome changes in human psp brains, although their cell-specificity is unknown. further, systematic data integration and experimental validation platforms to prioritize brain transcriptional perturbations as therapeutic targets in psp are currently lacking. in this study, we combine bulk tissue (n = 408) and single nucleus rnaseq (n = 34) data from psp and control brains with transcriptome data from a mouse tauopathy and experimental validations in drosophila tau models for systematic discovery of high-confidence expression changes in psp with therapeutic potential. we discover, replicate, and annotate thousands of differentially expressed genes in psp, many of which reside in glia-enriched co-expression modules and cells. we prioritize ddr2, stom, and kank2 as promising therapeutic targets in psp with striking cross-species validations. we share our findings and data via our interactive application tool psp rnaseq atlas (https://rtools.mayo.edu/psp_rnaseq_atlas/). our findings reveal robust glial transcriptome changes in psp, provide a cross-species systems biology approach, and a tool for therapeutic target discoveries in psp with potential application in other neurodegenerative diseases.",AB_0597
