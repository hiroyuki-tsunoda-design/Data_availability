AB,NO
"we present gegnn, a learning-based method for computing the approximate geodesic distance between two arbitrary points on discrete polyhedra surfaces with constant time complexity after fast precomputation. previous relevant methods either focus on computing the geodesic distance between a single source and all destinations, which has linear complexity at least or require a long precomputation time. our key idea is to train a graph neural network to embed an input mesh into a high-dimensional embedding space and compute the geodesic distance between a pair of points using the corresponding embedding vectors and a lightweight decoding function. to facilitate the learning of the embedding, we propose novel graph convolution and graph pooling modules that incorporate local geodesic information and are verified to be much more effective than previous designs. after training, our method requires only one forward pass of the network per mesh as precomputation. then, we can compute the geodesic distance between a pair of points using our decoding function, which requires only several matrix multiplications and can be massively parallelized on gpus. we verify the efficiency and effectiveness of our method on shapenet and demonstrate that our method is faster than existing methods by orders of magnitude while achieving comparable or better accuracy. additionally, our method exhibits robustness on noisy and incomplete meshes and strong generalization ability on out-of-distribution meshes. the code and pretrained model can be found on https://github.com/intelligentgeometry/gegnn.",AB_0213
"this paper addresses the challenging task of reconstructing the poses of multiple individuals engaged in close interactions, captured by multiple calibrated cameras. the difficulty arises from the noisy or false 2d keypoint detections due to inter-person occlusion, the heavy ambiguity in associating keypoints to individuals due to the close interactions, and the scarcity of training data as collecting and annotating motion data in crowded scenes is resource-intensive. we introduce a novel system to address these challenges. our system integrates a learning-based pose estimation component and its corresponding training and inference strategies. the pose estimation component takes multi-view 2d keypoint heatmaps as input and reconstructs the pose of each individual using a 3d conditional volumetric network. as the network doesn't need images as input, we can leverage known camera parameters from test scenes and a large quantity of existing motion capture data to synthesize massive training data that mimics the real data distribution in test scenes. extensive experiments demonstrate that our approach significantly surpasses previous approaches in terms of pose accuracy and is generalizable across various camera setups and population sizes. the code is available on our project page: https://github.com/zju3dv/closemocap.",AB_0213
"this paper presents a new text-guided technique for generating 3d shapes. the technique leverages a hybrid 3d shape representation, namely exim, combining the strengths of explicit and implicit representations. specifically, the explicit stage controls the topology of the generated 3d shapes and enables local modifications, whereas the implicit stage refines the shape and paints it with plausible colors. also, the hybrid approach separates the shape and color and generates color conditioned on shape to ensure shape-color consistency. unlike the existing state-of-the-art methods, we achieve high-fidelity shape generation from natural-language descriptions without the need for time-consuming per-shape optimization or reliance on human-annotated texts during training or test-time optimization. further, we demonstrate the applicability of our approach to generate indoor scenes with consistent styles using text-induced 3d shapes. through extensive experiments, we demonstrate the compelling quality of our results and the high coherency of our generated shapes with the input texts, surpassing the performance of existing methods by a significant margin. codes and models are released at https://github.com/liuzhengzhe/exim.",AB_0213
"human aging is a natural and inevitable biological process that leads to an increased risk of aging-related diseases. developing anti-aging therapies for aging-related diseases requires a comprehensive understanding of the mechanisms and effects of aging and longevity from a multi-modal and multi-faceted perspective. however, most of the relevant knowledge is scattered in the biomedical literature, the volume of which reached 36 million in pubmed. here, we presented hald, a text mining-based human aging and longevity dataset of the biomedical knowledge graph from all published literature related to human aging and longevity in pubmed. hald integrated multiple state-of-the-art natural language processing (nlp) techniques to improve the accuracy and coverage of the knowledge graph for precision gerontology and geroscience analyses. up to september 2023, hald had contained 12,227 entities in 10 types (gene, rna, protein, carbohydrate, lipid, peptide, pharmaceutical preparations, toxin, mutation, and disease), 115,522 relations, 1,855 aging biomarkers, and 525 longevity biomarkers from 339,918 biomedical articles in pubmed. hald is available at https://bis.zju.edu.cn/hald.",AB_0213
"numerous patch-based methods have recently been proposed for histological image based breast cancer classification. however, their performance could be highly affected by ignoring spatial contextual information in the whole slide image (wsi). to address this issue, we propose a novel hierarchical graph v-net by integrating 1) patch-level pre-training and 2) context-based fine-tuning, with a hierarchical graph network. specifically, a semi-supervised framework based on knowledge distillation is first developed to pre-train a patch encoder for extracting disease-relevant features. then, a hierarchical graph v-net is designed to construct a hierarchical graph representation from neighboring/similar individual patches for coarse-to-fine classification, where each graph node (corresponding to one patch) is attached with extracted disease-relevant features and its target label during training is the average label of all pixels in the corresponding patch. to evaluate the performance of our proposed hierarchical graph v-net, we collect a large wsi dataset of 560 wsis, with 30 labeled wsis from the bach dataset (through our further refinement), 30 labeled wsis and 500 unlabeled wsis from yunnan cancer hospital. those 500 unlabeled wsis are employed for patch-level pre-training to improve feature representation, while 60 labeled wsis are used to train and test our proposed hierarchical graph v-net. both comparative assessment and ablation studies demonstrate the superiority of our proposed hierarchical graph v-net over state-of-the-art methods in classifying breast cancer from wsis. the source code and our annotations for the bach dataset have been released at https://github.com/lyhkevin/graph-v-net.",AB_0213
"view synthesis methods using implicit continuous shape representations learned from a set of images, such as the neural radiance field (nerf) method, have gained increasing attention due to their high quality imagery and scalability to high resolution. however, the heavy computation required by its volumetric approach prevents nerf from being useful in practice; minutes are taken to render a single image of a few megapixels. now, an image of a scene can be rendered in a level-of-detail manner, so we posit that a complicated region of the scene should be represented by a large neural network while a small neural network is capable of encoding a simple region, enabling a balance between efficiency and quality. recursive-nerf is our embodiment of this idea, providing an efficient and adaptive rendering and training approach for nerf. the core of recursive-nerf learns uncertainties for query coordinates, representing the quality of the predicted color and volumetric intensity at each level. only query coordinates with high uncertainties are forwarded to the next level to a bigger neural network with a more powerful representational capability. the final rendered image is a composition of results from neural networks of all levels. our evaluation on public datasets and a large-scale scene dataset we collected shows that recursive-nerf is more efficient than nerf while providing state-of-the-art quality. the code will be available at https://github.com/gword/recursive-nerf",AB_0213
"the blockchain technology, initially created for cryptocurrency, has been re-purposed for recording state transitions of smart contracts-decentralized applications that can be invoked through external transactions. smart contracts gained popularity and accrued hundreds of billions of dollars in market capitalization in recent years. unfortunately, like all other computer programs, smart contracts are prone to security vulnerabilities that have incurred multibillion-dollar damages over the past decade. as a result, many automated threat mitigation solutions have been proposed to counter the security issues of smart contracts. these threat mitigation solutions include various tools and methods that are challenging to compare. this survey develops a comprehensive classification taxonomy of smart contract threat mitigation solutions within five orthogonal dimensions: defense modality, core method, targeted contracts, input-output data mapping, and threat model. we classify 133 existing threat mitigation solutions using our taxonomy and confirm that the proposed five dimensions allow us to concisely and accurately describe any smart contract threat mitigation solution. in addition to learning what the threat mitigation solutions do, we also show how these solutions work by synthesizing their actual designs into a set of uniform workflows corresponding to the eight existing defense core methods. we further create an integrated coverage map for the known smart contract vulnerabilities by the existing threat mitigation solutions. finally, we perform the evidence-based evolutionary analysis, in which we identify trends and future perspectives of threat mitigation in smart contracts and pinpoint major weaknesses of the existing methodologies. for the convenience of smart contract security developers, auditors, users, and researchers, we deploy and maintain a regularly updated comprehensive open-source online registry of threat mitigation solutions, called security threat mitigation (stm) registry at https://seit.egr.msu.edu/research/stmregistry/.",AB_0213
"benefiting from the massive labeled samples, deep learning-based segmentation methods have achieved great success for two dimensional natural images. however, it is still a challenging task to segment high dimensional medical volumes and sequences, due to the considerable efforts for clinical expertise to make large scale annotations. self/semi-supervised learning methods have been shown to improve the performance by exploiting unlabeled data. however, they are still lack of mining local semantic discrimination and exploitation of volume/sequence structures. in this work, we propose a semi-supervised representation learning method with two novel modules to enhance the features in the encoder and decoder, respectively. for the encoder, based on the continuity between slices/frames and the common spatial layout of organs across subjects, we propose an asymmetric network with an attention-guided predictor to enable prediction between feature maps of different slices of unlabeled data. for the decoder, based on the semantic consistency between labeled data and unlabeled data, we introduce a novel semantic contrastive learning to regularize the feature maps in the decoder. the two parts are trained jointly with both labeled and unlabeled volumes/sequences in a semi-supervised manner. when evaluated on three benchmark datasets of medical volumes and sequences, our model outperforms existing methods with a large margin of 7.3% dsc on acdc, 6.5% on prostate, and 3.2% on camus when only a few labeled data is available. further, results on the m&m dataset show that the proposed method yields improvement without using any domain adaption techniques for data from unknown domain. intensive evaluations reveal the effectiveness of representation mining, and superiority on performance of our method. the code is available at https://github.com/ccchenzj/bootstraprepresentation.",AB_0213
"unsupervised domain adaptation (uda) aims to train a model on a labeled source domain and adapt it to an unlabeled target domain. in medical image segmentation field, most existing uda methods rely on adversarial learning to address the domain gap between different image modalities. however, this process is complicated and inefficient. in this paper, we propose a simple yet effective uda method based on both frequency and spatial domain transfer under a multi-teacher distillation framework. in the frequency domain, we introduce non-subsampled contourlet transform for identifying domain-invariant and domain-variant frequency components (difs and dvfs) and replace the dvfs of the source domain images with those of the target domain images while keeping the difs unchanged to narrow the domain gap. in the spatial domain, we propose a batch momentum update-based histogram matching strategy to minimize the domain-variant image style bias. additionally, we further propose a dual contrastive learning module at both image and pixel levels to learn structure-related information. our proposed method outperforms state-of-the-art methods on two cross-modality medical image segmentation datasets (cardiac and abdominal). codes are avaliable at https://github.com/slliueric/fsuda.",AB_0213
"guided depth map super-resolution (gdsr), which aims to reconstruct a high-resolution depth map from a low-resolution observation with the help of a paired high-resolution color image, is a longstanding and fundamental problem that has attracted considerable attention from computer vision and image processing communities. myriad novel and effective approaches have been proposed recently, especially with powerful deep learning techniques. this survey is an effort to present a comprehensive survey of recent progress in gdsr. we start by summarizing the problem of gdsr and explaining why it is challenging. next, we introduce some commonly used datasets and image quality assessment methods. in addition, we roughly classify existing gdsr methods into three categories: filtering-based methods, prior-based methods, and learningbased methods. in each category, we introduce the general description of the published algorithms and design principles, summarize the representativemethods, and discuss their highlights and limitations. moreover, depth-related applications are introduced. furthermore, we conduct experiments to evaluate the performance of some representative methods based on unified experimental configurations, so as to offer a systematic and fair performance evaluation to readers. finally, weconclude this survey with possible directions and open problems for further research. all related materials can be found at https://github.com/zhwzhong/guideddepth-map-super-resolution-a-survey.",AB_0213
