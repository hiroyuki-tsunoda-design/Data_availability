AB,NO
"compilation, curation, digitization, and exploration of the phytochemical space of indian medicinal plants can expedite ongoing efforts toward natural product and traditional knowledge based drug discovery. to this end, we present imppat 2.0, an enhanced and expanded database compiling manually curated information on 4010 indian medicinal plants, 17,967 phytochemicals, and 1095 therapeutic uses. notably, imppat 2.0 compiles associations at the level of plant parts and provides a fair compliant nonredundant in silico stereo-aware library of 17,967 phytochemicals from indian medicinal plants. the phytochemical library has been annotated with several useful properties to enable easier exploration of the chemical space. we have also filtered a subset of 1335 drug-like phytochemicals of which majority have no similarity to existing approved drugs. using cheminformatics, we have characterized the molecular complexity and molecular scaffold based structural diversity of the phytochemical space of indian medicinal plants and performed a comparative analysis with other chemical libraries. altogether, imppat 2.0 is a manually curated extensive phytochemical atlas of indian medicinal plants that is accessible at https://cb.imsc.res.in/imppat/.",AB_0499
"stripe rust (caused by puccinia striiformis f. sp. tritici) is one of the most devastating diseases of wheat and causes large-scale epidemics and severe yield loss. applying fungicides during early epidemic development is crucial to controlling the disease but is often challenged by resource-limited human visual scouting. deep learning has the potential to process images and videos captured from affordable devices to empower high-throughput pheno-typing for early detection of stripe rust for timely application of fungicides and improve control efficiency. here, we developed rustnet, a neural network-based image classifier, for efficiently monitoring fields for stripe rust. rustnet was built on a resnet-18 architecture pre-trained with imagenet large-scale visual recognition challenge (ilsvrc) dataset using transfer learning. rgb images and videos of multiple wheat fields with different wheat types (winter and spring wheat), conditions (irrigated and non-irrigated), and locations were acquired using smartphones or unmanned aerial vehicles near the canopy. a semi-automated image labeling approach was conducted to improve labeling efficiency by combining automated machine labeling and human correction. cross-validations across multiple categories (sensor platforms, wheat types, and locations) achieved area under curve, the area under the receiver operating characteristic (roc) curves, from 0.72 to 0.87. inde-pendent validation on a published dataset from germany achieved accuracies ranging from 0.79 to 0.86. the visualization of the last convolutional layer of rustnet demonstrated the identification of pixels with stripe rust. rustnet is freely available at https://zzlab.net/rustnet/.",AB_0499
"gene regulatory networks define the interactions between dna products and other substances in cells. increasing knowledge of these networks improves the level of detail with which the processes that trigger different diseases are described and fosters the development of new therapeutic targets. these networks are usually represented by graphs, and the primary sources for their correct construction are usually time series from differential expression data. the inference of networks from this data type has been approached differently in the literature. mostly, computational learning techniques have been implemented, which have finally shown some specialization in specific datasets. for this reason, the need arises to create new and more robust strategies for reaching a consensus based on previous results to gain a particular capacity for generalization. this paper presents geneci (gene network consensus inference), an evolutionary machine learning approach that acts as an organizer for constructing ensembles to process the results of the main inference techniques reported in the literature and to optimize the consensus network derived from them, according to their confidence levels and topological characteristics. after its design, the proposal was confronted with datasets collected from academic benchmarks (dream challenges and irma network) to quantify its accuracy. subsequently, it was applied to a real-world biological network of melanoma patients whose results could be contrasted with medical research collected in the literature. finally, it has been proved that its ability to optimize the consensus of several networks leads to outstanding robustness and accuracy, gaining a certain generalization capacity after facing the inference of multiple datasets. the source code is hosted in a public repository at github under mit license: https://github.com/adrianseguraortiz/geneci. moreover, to facilitate its installation and use, the software associated with this implementation has been encapsulated in a python package available at pypi: https://pypi.org/project/geneci/.",AB_0499
"motivation: identifying regulatory regions in the genome is of great interest for understanding the epigenomic landscape in cells. one fundamental challenge in this context is to find the target genes whose expression is affected by the regulatory regions. a recent successful method is the activity-by-contact (abc) model which scores enhancer-gene interactions based on enhancer activity and the contact frequency of an enhancer to its target gene. however, it describes regulatory interactions entirely from a gene's perspective, and does not account for all the candidate target genes of an enhancer. in addition, the abc model requires two types of assays to measure enhancer activity, which limits the applicability. moreover, there is neither implementation available that could allow for an integration with transcription factor (tf) binding information nor an efficient analysis of single-cell data. results: we demonstrate that the abc score can yield a higher accuracy by adapting the enhancer activity according to the number of contacts the enhancer has to its candidate target genes and also by considering all annotated transcription start sites of a gene. further, we show that the model is comparably accurate with only one assay to measure enhancer activity. we combined our generalized abc model with tf binding information and illustrated an analysis of a single-cell atac-seq dataset of the human heart, where we were able to characterize cell type-specific regulatory interactions and predict gene expression based on tf affinities. all executed processing steps are incorporated into our new computational pipeline stare. availability and implementation: the software is available at https://github.com/schulzlab/stare contact: marcel.schulz@em.uni-frankfurt.de supplementary information: supplementary data are available at bioinformatics online.",AB_0499
"background: recent years have seen a surge of novel neural network architectures for the integration of multi-omics data for prediction. most of the architectures include either encoders alone or encoders and decoders, i.e., autoencoders of various sorts, to transform multi-omics data into latent representations. one important parameter is the depth of integration: the point at which the latent representations are computed or merged, which can be either early, intermediate, or late. the literature on integration methods is growing steadily, however, close to nothing is known about the relative performance of these methods under fair experimental conditions and under consideration of different use cases.results: we developed a comparison framework that trains and optimizes multi-omics integration methods under equal conditions. we incorporated early integration, pca and four recently published deep learning methods: moli, super.felt, omiembed, and moma. further, we devised a novel method, omics stacking, that combines the advantages of intermediate and late integration. experiments were conducted on a public drug response data set with multiple omics data (somatic point mutations, somatic copy number profiles and gene expression profiles) that was obtained from cell lines, patient-derived xenografts, and patient samples. our experiments confirmed that early integration has the lowest predictive performance. overall, architectures that integrate triplet loss achieved the best results. statistical differences can, overall, rarely be observed, however, in terms of the average ranks of methods, super.felt is consistently performing best in a cross-validation setting and omics stacking best in an external test set setting.conclusions: we recommend researchers to follow fair comparison protocols, as suggested in the paper. when faced with a new data set, super.felt is a good option in the cross-validation setting as well as omics stacking in the external test set setting. statistical significances are hardly observable, despite trends in the algorithms' rankings. future work on refined methods for transfer learning tailored for this domain may improve the situation for external test sets. the source code of all experiments is available under https://github.com/kramerlab/multi-omics_analysis",AB_0499
"airborne and spaceborne platforms are the primary data sources for large-scale forest mapping, but visual interpretation for individual species determination is labor-intensive. hence, various studies focusing on forests have investigated the benefits of multiple sensors for automated tree species classification. however, transferable deep learning approaches for large-scale applications are still lacking. this gap motivated us to create a novel dataset for tree species classification in central europe based on multi-sensor data from aerial, sentinel-1 and sentinel-2 imagery. in this paper, we introduce the treesatai benchmark archive, which contains labels of 20 european tree species (i.e., 15 tree genera) derived from forest administration data of the federal state of lower saxony, germany. we propose models and guidelines for the application of the latest machine learning techniques for the task of tree species classification with multi-label data. finally, we provide various benchmark experiments showcasing the information which can be derived from the different sensors including artificial neural networks and tree-based machine learning methods. we found that residual neural networks (resnet) perform sufficiently well with weighted precision scores up to 79 % only by using the rgb bands of aerial imagery. this result indicates that the spatial content present within the 0.2 m resolution data is very informative for tree species classification. with the incorporation of sentinel-1 and sentinel-2 imagery, performance improved marginally. however, the sole use of sentinel-2 still allows for weighted precision scores of up to 74 % using either multi-layer perceptron (mlp) or light gradient boosting machine (lightgbm) models. since the dataset is derived from real-world reference data, it contains high class imbalances. we found that this dataset attribute negatively affects the models' performances for many of the underrepresented classes (i.e., scarce tree species). however, the class-wise precision of the best-performing late fusion model still reached values ranging from 54 % (acer) to 88 % (pinus). based on our results, we conclude that deep learning techniques using aerial imagery could considerably support forestry administration in the provision of large-scale tree species maps at a very high resolution to plan for challenges driven by global environmental change. the original dataset used in this paper is shared via zenodo (https://doi.org/10.5281/zenodo.6598390, ). for citation of the dataset, we refer to this article.",AB_0499
"explainable artificial intelligence ()cai) makes al understandable to the human user particularly when the model is complex and opaque. local interpretable model-agnostic explanations (lime) has an image explainer package that is used to explain deep learning models. the image explainer of lime needs some parameters to be manually tuned by the expert in advance, including the number of top features to be seen and the number of superpixels in the segmented input image. this parameter tuning is a time-consuming task. hence, with the aim of developing an image explainer that automizes image segmentation, this paper proposes ensemble -based genetic algorithm explainer (egae) for melanoma cancer detection that automatically detects and presents the informative sections of the image to the user. egae has three phases. first, the sparsity of chromosomes in gas is determined heuristically. then, multiple gas are executed consecutively. however, the difference between these gas are in different number of superpixels in the input image that result in different chromosome lengths. finally, the results of gm are ensembled using consensus and majority votings. this paper also introduces how euclidean distance can be used to calculate the distance between the actual explanation (delineated by experts) and the calculated explanation (computed by the explainer) for accuracy measurement. experimental results on a melanoma dataset show that egae automatically detects informative lesions, and it also improves the accuracy of explanation in comparison with lime efficiently. the python codes for egae, the ground truths delineated by clinicians, and the melanoma detection dataset are available at https://github.com/lchaosresearch/egae.",AB_0499
"motivation: microbial metagenomic profiling software and databases are advancing rapidly for development of novel disease biomarkers and therapeutics yet three problems impede analyses: 1) the conflation of genome assembly and strain in reference databases; 2) difficulty connecting dna biomarkers to a procurable strain for laboratory experimentation; and 3) absence of a comprehensive and unified strain-resolved reference database for integrating both shotgun metagenomics and 16s rrna gene data.results: we demarcated 681,087 strains, the largest collection of its kind, by filtering public data into a knowledge graph of vertices representing contiguous dna sequences, genome assemblies, strain monikers and bio-resource center (brc) catalog numbers then adding inter-vertex edges only for synonyms or direct derivatives. surprisingly, for 10,043 important strains, we found replicate refseq genome assemblies obstructing interpretation of database searches. we organized each strain into eight taxonomic ranks with bootstrap confidence inversely correlated with genome assembly contamination. the strainselect database is suited for applications where a taxonomic, functional or procurement reference is needed for shotgun or amplicon metagenomics since 636,568 strains have at least one 16s rrna gene, 245,005 have at least one annotated genome assembly, and 36,671 are procurable from at least one brc. the database overcomes all three aforementioned problems since it disambiguates strains from assemblies, locates strains at brcs, and unifies a taxonomic reference for both 16s rrna and shotgun metagenomics.availability: the strainselect database is available in igraph and tabular vertex-edge formats compatible with neo4j. dereplicated minhash and fasta databases are distributed for sourmash and usearch pipelines at http://strainselect .secondgenome .com.contact: todd .desantis @gmail .com. supplementary information: supplementary data are available online.",AB_0499
"state-of-the-art (sota) convolutional neural network models have been widely adapted in medical imaging and applied to address different clinical problems. however, the complexity and scale of such models may not be justified in medical imaging and subject to the available resource budget. further increasing the number of representative feature maps for the classification task decreases the model explainability. the current data normalization practice is fixed prior to model development and discounting the specification of the data domain. acknowledging these issues, the current work proposed a new scalable model family called plexusnet; the block architecture and model scaling by the network's depth, width, and branch regulate plexusnet's architecture. the efficient computation costs outlined the dimensions of plexusnet scaling and design. plexusnet includes a new learnable data normalization algorithm for better data generalization. we applied a simple yet effective neural architecture search to design plexusnet tailored to five clinical classification problems that achieve a perfor-mance noninferior to the sota models resnet-18 and efficientnet b0/1. it also does so with lower parameter capacity and representative feature maps in ten-fold ranges than the smallest sota models with comparable performance. the visualization of representative features revealed distinguishable clusters associated with cat-egories based on latent features generated by plexusnet. the package and source code are at https://github.com /oeminaga/plexusnet.git.",AB_0499
"voluntary participation is thought to promote the well-being of engaged individuals, especially in old age, but prior evidence on this link is mixed. in the present studies, we used the cross-sectional data from round 6 (2012) of the european social survey (ess) to investigate the variation in the associations between voluntary participation and eudaimonic (e.g., sense of direction) and social (e.g., perceived social support) well-being across types of participation (nonpolitical volunteering vs. political participation), age groups, and european countries. study 1 addressed individual-level associations and age differences therein (pre-registered at https://osf.io/2p9sz and https://osf.io/6twqe). two-level multiple regression with an extensive set of control variables showed that at the within-country level, the associ-ations between voluntary participation and well-being indicators were small on average. nonpolitical volunteering had significantly more positive effects than did political participa-tion, whereas few significant age differences emerged. study 2 focused on the country-level variables that might explain the substantial cross-national variation in the main effects of voluntary participation (preregistered at https://osf.io/mq3dx). only gdp per capita was a significant moderator at the country level: the associations of nonpolitical volunteering with eudaimonic well-being were more positive in the european countries with lower gdp. other country-level variables (gini coefficient, social welfare spending, and democracy indices) yielded no consistent moderation effects. study 3 considered potential country-level expla-nations for the substantial cross-national variation in whether younger or older adults appeared to benefit more (preregistered at https://osf.io/7ks45). none of the country-level variables considered (effective retirement age in men, life expectancy at 65, average age of members of the national parliament and cabinet, and youth unemployment rate) could account for this variation. we conclude that, given the large cross-national variation in the effects of voluntary participation on well-being and in age differences therein, more attention to national specifics is warranted.",AB_0499
