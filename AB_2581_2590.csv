AB,NO
"multi-label classification (mlc) can attach multiple labels on single image, and has achieved promising results on medical images. but existing mlc methods still face challenging clinical realities in practical use, such as: (1) medical risks arising from misclassification, (2) sample imbalance problem among different diseases, (3) inability to classify the diseases that are not pre-defined (unseen diseases). here, we design a hybrid label to improve the flexibility of mlc methods and alleviate the sample imbalance problem. specifically, in the labeled training set, we remain independent labels for high-frequency diseases with enough samples and use a hybrid label to merge low-frequency diseases with fewer samples. the hybrid label can also be used to put unseen diseases in practical use. in this paper, we propose triplet attention and dual-pool contrastive learning (ta-dcl) for multi-label medical image classification based on the aforementioned label representation. ta-dcl architecture is a triplet attention network (tan), which combines category-attention, self-attention and cross -attention together to learn high-quality label embeddings for all disease labels by mining effective information from medical images. dcl includes dual-pool contrastive training (dct) and dual-pool contrastive inference (dci). dct optimizes the clustering centers of label embeddings belonging to different disease labels to improve the discrimination of label embeddings. dci relieves the error classification of sick cases for reducing the clinical risk and improving the ability to detect unseen diseases by contrast of differences. ta-dcl is validated on two public medical image datasets, odir and nih-chestxray14, showing superior performance than other state-of-the-art mlc methods. code is available at https://github.com/zhangyh0502/ta-dcl.",AB_0259
"the segmentation of cranial nerves (cns) tracts based on diffusion magnetic resonance imaging (dmri) provides a valuable quantitative tool for the analysis of the morphology and course of individual cns. tractography-based approaches can describe and analyze the anatomical area of cns by selecting the reference streamlines in combination with rois-based (regions-of-interests) or clustering-based. however, due to the slender structure of cns and the complex anatomical environment, single-modality data based on dmri cannot provide a complete and accurate description, resulting in low accuracy or even failure of current algorithms in performing individualized cns segmentation. in this work, we propose a novel multimodal deep-learning-based multi-class network for automated cranial nerves tract segmentation without using tractography, roi placement or clustering, called cntseg. specifically, we introduced t1w images, fractional anisotropy (fa) images, and fiber orientation distribution function (fodf) peaks into the training data set, and design the back -end fusion module which uses the complementary information of the interphase feature fusion to improve the segmentation performance. cntseg has achieved the segmentation of 5 pairs of cns (i.e. optic nerve cn ii, oculomotor nerve cn iii, trigeminal nerve cn v, and facial-vestibulocochlear nerve cn vii/viii). extensive comparisons and ablation experiments show promising results and are anatomically convincing even for difficult tracts. the code will be openly available at https://github.com/ipis-xielei/cntseg.",AB_0259
"manual acupuncture (ma) is a widely used type of therapy method in the world, its treatment result and clinical safety are highly related to the selection of stimulation parameters (needling amplitude and frequency) of acupuncturists. however, to date, there is no stimulation parameter measurement solution that can be conveniently used in the clinic. thus, there is an urgent need to develop a single camera-based real-time monitoring system for ma operation. this monitoring system is expected to give the result of both the amplitude and frequency of ma. considering that constructing the labeled ma monitoring dataset is laborious and time-consuming and that there is a large amount of unlabeled data, we propose an adaptive orientation-based domain adaptation framework to alleviate the domain shift and achieve better performance. moreover, we contribute a benchmark that contains 20 videos of on-body ma operation and 30 videos of on -simulator ma operation with 3d coordinates to facilitate the future development of real-time ma monitoring. extensive experiments on the proposed benchmark demonstrate the superiority of the proposed methods on both movement estimation and frequency estimation of hand acupuncture. the application prospects of this framework for the clinical work of ma included the investigation of dose-effect relationship of ma, enhancement of its operation safety, etc. our data is publicly available at https://github.com/shutcm-tcme/sutcm-am.",AB_0259
"as the fair (findable, accessible, interoperable, reusable) principles have become widely accepted in the proteomics field, under the guidance of proteomexchange and the human proteome organization proteomics standards initiative, proteomics public databases have been providing application programming interfaces for programmatic access. based on generating logic from proteomics data, we present patpat, an extensible framework for searching public datasets, merging results from multiple databases to help researchers find their proteins of interest in the vast mass spectrometry. patpat's 2d strategy of combining results from multiple databases allows users to provide only protein identifiers to obtain metadata for relevant datasets, improving the 'findable' of proteomics data. availability and implementation: the patpat framework is released under the apache 2.0 license open source, and the source code is stored on github (https://github.com/henry-leo/patpat) and is freely available. contact: xuelianzhang@fudan.edu.cn supplementary information: supplementary data are available at bioinformatics online.",AB_0259
"functional classification of genetic variants is a key for their clinical applications in patient care. however, abundant variant data generated by the next-generation dna sequencing technologies limit the use of experimental methods for their classification. here, we developed a protein structure and deep learning (dl)-based system for genetic variant classification, dl-rp-mds, which comprises two principles: 1) extracting protein structural and thermodynamics information using the ramachandran plot-molecular dynamics simulation (rp-mds) method, 2) combining those data with an unsupervised learning model of auto-encoder and a neural network classifier to identify the statistical significance patterns of the structural changes. we observed that dl-rp-mds provided higher specificity than over 20 widely used in silico methods in classifying the variants of three dna damage repair genes: tp53, mlh1, and msh2. dl-rp-mds offers a powerful platform for high-throughput genetic variant classification. the software and online application are available at https://genemutation.fhs.um.edu.mo/dl-rp-mds/.",AB_0259
"a grey predictive evolutionary algorithm, which is attracting more and more attention, regards the population series of evolutionary algorithms as an equidistant time series. the population evolution is essentially regarded as a process in which the function values have variable-speed decrease with the increase of the number of iterations (for minimization problems). therefore, a fitness-driven evolutionary population sequence with the property of variable-speed evolution should be more appropriately modelled as a non-equidistant time series. a novel meta-heuristic optimization algorithm, non-equidistant grey prediction evolution algorithm is proposed in this paper. the proposed algorithm is identified by its reproduction operator which is developed by the following two steps. firstly, a non-equidistant grey model (negm (1,1)) based on the average fitness value of each generation population to preserve the non-equidistant nature is modelled. secondly, the interval in the fitting stage of the negm (1,1) is defined as an increasing time interval. the performance of the proposed algorithm is evaluated on cec2019 and cec2020 benchmark functions. experimental results show that the proposed algorithm is superior to other more complex and notable approaches, in terms of solving accuracy as well as the rate of convergence.the matlab code of this paper is availabled on https://github.com/zhongbo-hu/prediction-evolutionary-algorithm-homepage.",AB_0259
"translational displacement between source images from different sensors is a general phenomenon, which will cause performance degradation on image fusion. to tackle this issue, a straightforward way is to make source images registration first. however, due to the large modality-gap between the infrared image and the visible image, it is too challenging to achieve completely registered images. in this paper, a novel registration -free fusion method is primarily proposed for infrared and visible images with translational displacement, which transforms the problem of image registration to feature alignment in an end-to-end framework. specifically, we propose a cross-modulation strategy followed by feature dynamic alignment, so that the spatial correlation of shifts is adaptively measured and the aligned features can be dynamically extracted. a feature refinement module is additionally designed based on the local similarity, which enhances the textures related information while suppresses artifacts related information. thanks to these strategies, our experimental results on infrared-visible images with translational displacement achieve dramatic enhancement compared with state-of-the-arts. to the best of our knowledge, this is the first work on infrared-visible image fusion without strict registration. it does break the constraint of existing image-registration based two-step strategies and provide a simple but efficient way for multi-modal image fusion. the source code will be released at https://github.com/lhf12278/rfvif.",AB_0259
"prior studies for the task of severity assessment of covid-19 (sa-covid) usually suffer from domain-specific cognitive deficits. they mainly focus on visual cues based on single cognitive functions but fail to reconcile the valuable information from other alternative views. inspired by the cognitive process of radiologists, this paper shifts naturally from single-symptom measurements to a multi-view analysis, and proposes a novel self-paced multi-view learning (spml) framework for automated sa-covid. specifically, the proposed spml framework first comprehensively aggregates multi-view contexts in lung infection with different measure paradigms, i.e., global feature branch, texture feature branch, and volume feature branch. in this way, multiple-perspective clues are taken into account to reflect the most essential pathological manifestation on ct images. to alleviate small-sample learning problems, we also introduce an optimization with self-paced learning strategy to cognitively increase the characterization capabilities of training samples by learning from simple to complex. in contrast to traditional batch-wise learning, a pure self-paced way can further guarantee the efficiency and accuracy of spml when dealing with small and biased samples. furthermore, we construct a well-established sa-covid dataset that contains 300 ct images with fine annotations. extensive experiments on this dataset demonstrate that spml consistently outperforms the state-of-the-art baselines. the sa-covid dataset is publicly released at https://github.com/yishuliu/sa-covid.",AB_0259
"to evaluate the performance of machine learning (ml) models and to compare it with logistic regression (lr) technique in predicting cognitive impairment related to post intensive care syndrome (pics-ci). we conducted a prospective observational study of icu patients at two tertiary hospitals. a cohort of 2079 patients was screened, and finally 481 patients were included. seven different ml models were considered, decision tree (dt), random forest (rf), xgboost, neural network (nn), naive bayes (nb), and support vector machine (svm), and compared with logistic regression (lr). discriminative ability was evaluated by area under the receiver operating characteristic curve (auc), calibration belt plots, and hosmer-lemeshow test was used to assess calibration. decision curve analysis was performed to quantify clinical utility. duration of delirium, poor richards-campbell sleep questionnaire (rcsq) score, advanced age, and sepsis were the most frequent and important candidates risk factors for pics-ci. all ml models showed good performance (auc range: 0.822- 0.906). nn model had the highest auc (0.906 [95% ci 0.857-0.955]), which was slightly higher than, but not significantly different from that of lr (0.898 [95% ci 0.847-0.949]) (p > 0.05, delong test). given the overfitting and complexity of some ml models, the lr model was then used to develop a web-based risk calculator to aid decision-making (https:// model 871010. shiny apps. io/ dynno mapp/). in a low dimensional data, lr may yield as good performance as other complex ml models to predict cognitive impairment after icu hospitalization.",AB_0259
"a major challenge in the application of the crispr-cas13d system is to accurately predict its guide-dependent on-target and off-target effect. here, we perform crispr-cas13d proliferation screens and design a deep learning model, named deepcas13, to predict the on-target activity from guide sequences and secondary structures. deepcas13 outperforms existing methods to predict the efficiency of guides targeting both protein-coding and non-coding rnas. guides targeting non-essential genes display off-target viability effects, which are closely related to their on-target efficiencies. choosing proper negative control guides during normalization mitigates the associated false positives in proliferation screens. we apply deepcas13 to the guides targeting lncrnas, and identify lncrnas that affect cell viability and proliferation in multiple cell lines. the higher prediction accuracy of deepcas13 over existing methods is extensively confirmed via a secondary crispr-cas13d screen and quantitative rt-pcr experiments. deepcas13 is freely accessible via http://deepcas13.weililab.org.",AB_0259
