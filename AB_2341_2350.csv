AB,NO
"the ongoing pandemic of the coronavirus disease 2019(covid-19)caused by the severe acute respiratory syndrome coronavirus 2 stillhas limited treatment options. our understanding of the moleculardysregulations that occur in response to infection remains incomplete.we developed a web application covidpro (https://www.guomics.com/covidpro/) that includes proteomics data obtained from 41 original studiesconducted in 32 hospitals worldwide, involving 3077 patients and covering19 types of clinical specimens, predominantly plasma and serum. thedata set encompasses 53 protein expression matrices, comprising atotal of 5434 samples and 14,403 unique proteins. we identified apanel of proteins that exhibit significant dysregulation, enablingthe classification of covid-19 patients into severe and non-severedisease categories. the proteomic signatures achieved promising resultsin distinguishing severe cases, with a mean area under the curve of0.87 and accuracy of 0.80 across five independent test sets. covidproserves as a valuable resource for testing hypotheses and exploringpotential targets for novel treatments in covid-19 patients.",AB_0235
"multimodal sentiment analysis is an active research field that aims to recognize the user's sentiment information from multimodal data. the primary challenge in this field is to develop a high-quality fusion framework that effectively addresses the heterogeneity among different modalities. however, prior research has primarily concentrated on intermodal interactions while neglecting the semantic sentiment information conveyed by words in the text modality. in this paper, we propose the sentiment knowledge enhanced attention fusion network (skeafn), a novel end-to-end fusion network that enhances multimodal fusion by incorporating additional sentiment knowledge representations from an external knowledge base. firstly, we construct an external knowledge enhancement module to acquire additional representations for the text modality. then, we design a text-guided interaction module that facilitates the interaction between text and the visual/acoustic modality. finally, we propose a feature-wised attention fusion module that achieves multimodal fusion by dynamically adjusting the weights of the additional and each modality's representations. we evaluate our method on three challenging multimodal sentiment analysis datasets: cmu-mosi, cmu-mosei, and twitter2019. the experiment results demonstrate that our model significantly outperforms the state-of-the-art models. the source code is publicly available at https://github.com/doubibobo/skeafn.",AB_0235
"with the development of chromosome conformation capture technology, the genome-wide investigation of higher-order chromatin structure by using high-throughput chromatin conformation capture (hi-c) technology is emerging as an important component for understanding the mechanism of gene regulation. considering genetic and epigenetic differences are typically used to explore the pathological reasons on the chromosome and gene level, visualizing multi-omics data and performing an intuitive analysis by using an interactive browser become a powerful and welcomed way. in this paper, we develop an effective sequence and chromatin interaction data display browser called hibrowser for visualizing and analyzing hi-c data and their associated genetic and epigenetic annotations. the advantages of hibrowser are flexible multi-omics navigation, novel multidimensional synchronization comparisons and dynamic interaction system. in particular, hibrowser first provides an out of the box web service and allows flexible and dynamic reconstruction of custom annotation tracks on demand during running. in order to conveniently and intuitively analyze the similarities and differences among multiple samples, such as visual comparisons of normal and tumor tissue samples, and pan genomes of multiple (consanguineous) species, hibrowser develops a clone mode to synchronously display the genome coordinate positions or the same regions of multiple samples on the same page of visualization. hibrowser also supports a pluralistic and precise search on correlation data of distal cis-regulatory elements and navigation to any region on hi-c heatmap of interest according to the searching results. hibrowser is a no-build tool, and could be easily deployed in local server. the source code is available at https://github.com/lyotvincent/hibrowser.",AB_0235
"in the field of traffic forecasting, methods based on graph convolutional network (gcn) are emerging. but existing methods still have limitations due to insufficient sharing patterns, inflexible temporal relations and static relation assumptions. to address these issues, a generic dynamic graph convolutional network (gdgcn) for traffic flow forecasting is proposed. a generic framework with both parameter-sharing and independent blocks across stacked layers is proposed to explore parameter sharing systematically in all data dimensions, which can exploit distinct patterns from layer to layer and stable patterns across layers simultaneously. then, we design a novel temporal graph convolutional block to view historical time slots as nodes in graph perspective and handle temporal dynamics with graph convolution. this temporal convolutional block can capture flexible and global temporal relations to have a better understanding of current traffic conditions. lastly, a dynamic graph constructor is proposed to model not only the time-specific spatial dependencies between nodes, but also the changing temporal interactions between time slots to discover dynamic relations from data thoroughly. experimental results on four real-world datasets show that gdgcn not only outperforms state-of-the-art methods, but also obtains interpretable dynamic spatial relations of segments. codes are available at https://anonymous.4open.science/r/gdgcn.",AB_0235
"genotype-to-phenotype (g2p) prediction has become a mainstream paradigm to facilitate genomic selection (gs)-assisted breeding in the seed industry. many methods have been introduced for building gs models, but their prediction precision may vary depending on species and specific traits. therefore, evaluation of multiple models and selection of the appropriate one is crucial to effective gs analysis. here, we present the g2p container developed for the singularity platform, which not only contains a library of 16 state-of-the-art gs models and 13 evaluation metrics. g2p works as an integrative environment offering comprehensive, unbiased evaluation analyses of the 16 gs models, which may be run in parallel on high-performance computing clusters. based on the evaluation outcome, g2p performs auto-ensemble algorithms that not only can automatically select the most precise models but also can integrate prediction results from multiple models. this functionality should further improve the precision of g2p prediction. another noteworthy function is the refinement design of the training set, in which g2p optimizes the training set based on the genetic diversity analysis of a studied population. although the training samples in the optimized set are fewer than in the original set, the prediction precision is almost equivalent to that obtained when using the whole set. this functionality is quite useful in practice, as it reduces the cost of phenotyping when constructing training population. the g2p container and source codes are freely accessible at https://g2p-env.github.io/.",AB_0235
"good proposal initials are critical for 3d object detection applications. however, due to the significant geometry variation of indoor scenes, incomplete and noisy proposals are inevitable in most cases. mining feature information among these bad proposals may mislead the detection. contrastive learning provides a feasible way for representing proposals, which can align complete and incomplete/noisy proposals in feature space. the aligned feature space can help us build robust 3d representation even if bad proposals are given. therefore, we devise a new contrast learning framework for indoor 3d object detection, called efecl, that learns robust 3d representations by contrastive learning of proposals on two different levels. specifically, we optimize both instance-level and category-level contrasts to align features by capturing instance-specific characteristics and semantic-aware common patterns. furthermore, we propose an enhanced feature aggregation module to extract more general and informative features for contrastive learning. evaluations on scannet v2 and sun rgb-d benchmarks demonstrate the generalizability and effectiveness of our method, and our method can achieve 12.3% and 7.3% improvements on both datasets over the benchmark alternatives. the code andmodels are publicly available at https://github.com/yaraduan/efecl.",AB_0235
"motivation: analyzing genetic data to identify markers and construct predictive models is of great interest in biomedical research. however, limited by cost and sample availability, genetic studies often suffer from the small sample size, high dimensionality problem. to tackle this problem, an integrative analysis that collectively analyzes multiple datasets with compatible designs is often conducted. for regularizing estimation and selecting relevant variables, penalization and other regularization techniques are routinely adopted. blindly searching over a vast number of variables may not be efficient. results: we propose incorporating prior information to assist integrative analysis of multiple genetic datasets. to obtain accurate prior information, we adopt a convolutional neural network with an active learning strategy to label textual information from previous studies. then the extracted prior information is incorporated using a group lasso-based technique. we conducted a series of simulation studies that demonstrated the satisfactory performance of the proposedmethod. finally, data on skin cutaneous melanoma are analyzed to establish practical utility. availability and implementation: code is available at https://github.com/ldz7/paia. the data that support the findings in this article are openly available in tcga (the cancer genome atlas) at https://portal.gdc.cancer.gov/.",AB_0235
"to address the ill-posed problem of hyperspectral image super-resolution (hsisr), a commonly employed technique is to design a regularization term based on the prior information of hyperspectral images (hsis) to effectively constrain the objective function. traditional model-based methods that rely on manually crafted priors are insufficient in fully characterizing the properties of hsis. learning-based methods usually use a convolutional neural network (cnn) to learn the implicit priors of hsis. however, the learning ability of cnn is limited, it only considers the spatial characteristics of the hsis and ignores the spectral characteristics, and convolution is not effective for long-range dependency modeling. there is still a lot of room for improvement. in this paper, we propose a novel hsisr method that leverages the transformer architecture instead of the cnn to learn the prior of hsis. specifically, we employ the proximal gradient algorithm to solve the hsisr model and simulate the iterative solution process using an unfolding network. the self-attention layer of the transformer enables global spatial interaction, while a 3d-cnn is added behind the transformer layers to better capture the spatio-spectral correlation of hsis. both quantitative and visual results on three widely used hsi datasets and the real-world dataset demonstrate that the proposed method achieves a considerable gain compared to all the mainstream algorithms including the most competitive conventional methods and the recently proposed deep learning-based methods. the source code and trained models are made publicly available at https://github.com/qingma2016/3dt-net.",AB_0235
"reliable and automated 3-dimensional (3d) plant shoot segmentation is a core prerequisite for the extraction of plant phenotypic traits at the organ level. combining deep learning and point clouds can provide effective ways to address the challenge. however, fully supervised deep learning methods require datasets to be point-wise annotated, which is extremely expensive and time-consuming. in our work, we proposed a novel weakly supervised framework, eff-3dpseg, for 3d plant shoot segmentation. first, high-resolution point clouds of soybean were reconstructed using a low-cost photogrammetry system, and the meshlab-based plant annotator was developed for plant point cloud annotation. second, a weakly supervised deep learning method was proposed for plant organ segmentation. the method contained (a) pretraining a self-supervised network using viewpoint bottleneck loss to learn meaningful intrinsic structure representation from the raw point clouds and (b) fine-tuning the pretrained model with about only 0.5% points being annotated to implement plant organ segmentation. after, 3 phenotypic traits (stem diameter, leaf width, and leaf length) were extracted. to test the generality of the proposed method, the public dataset pheno4d was included in this study. experimental results showed that the weakly supervised network obtained similar segmentation performance compared with the fully supervised setting. our method achieved 95.1%, 96.6%, 95.8%, and 92.2% in the precision, recall, f1 score, and miou for stem-leaf segmentation for the soybean dataset and 53%, 62.8%, and 70.3% in the ap, ap@25, and ap@50 for leaf instance segmentation for the pheno4d dataset. this study provides an effective way for characterizing 3d plant architecture, which will become useful for plant breeders to enhance selection processes. the trained networks are available at https://github.com/jieyi-one/eff-3dpseg.",AB_0235
"nowadays, apache hive has been widely used for large-scale data analysis applications in many organizations. various visual analytical tools are developed to help hive users quickly analyze the query execution process and identify the performance bottleneck of executed queries. however, existing tools mostly focus on showing the time usage of query sub-components (jobs and operators) but fail to provide enough evidence to analyze the root reasons for the slow execution progress. to tackle this problem, we develop a visual analytical system dhive to visualize and analyze the query execution progress via dataflow analysis. dhive shows the dataflow during query execution at multiple levels: query level, job level and task level, which enable users to identify the key jobs/tasks and explain their time usage by linking them to the auxiliary information such as the system configuration and hardware status. we demonstrate the effectiveness of dhive by two cases in a production cluster. dhive is open-source at https://github.com/dbgroupsustech/dhive.git.",AB_0235
