AB,NO
"background: pancreas transplant alone (pta) recipients are more affected by pancreas graft thrombosis, and graft loss compared to simultaneous pancreaskidney (spk) recipients. the pathophysiology is unknown, but an increased immune response has been suggested in the pta recipients. in this observational study, we compared perioperative thromboinflammation between pta (n=32) and spk (n=35) recipients, and between pta recipients with (n=14) versus without (n=18) early graft thrombosis. methods: we measured c-reactive protein (crp), plasma markers of activated coagulation and complement, and cytokines preoperatively and daily during the first postoperative week. results: preoperatively, coagulation and complement activation markers were comparable between pta and spk recipients, while cytokine concentrations were higher in spk recipients (tnf, il-8, ip-10, mcp-1, mip-1a; all p<0.05). on the first postoperative day, pta recipients had higher coagulation activation, measured as thrombin-antithrombin complex (tat), than spk recipients (p= 0.008). in the first postoperative week, pta recipients showed higher relative cytokine release (il-6, il-8, g-csf, ip-10, mcp-1, and mip-1a; all p<0.05) while spk recipients showed higher absolute cytokine concentrations (tnf, il1ra, il-8, mip-1a, and il-4; all p<0.05). pta and spk recipients showed similar terminal complement complex (tcc, sc5b- 9) activation. on the first postoperative day, tcc (or 1.2 [ 95% ci 1.0-1.5] for 0.1 cau/ml increase, p=0.02) and crp (or 1.2 [95% ci 1.0-1.3] for 10 mg/l increase, p=0.04) were associated with an increased risk of early graft thrombosis. tcc was specific for graft thrombosis, while crp increased with several complications. pta recipients with compared to those without graft thrombosis had higher tcc pre- (p=0.04) and postoperatively (p=0.03). conclusion: the relative increase in postoperative thromboinflammatory response was more pronounced in pta recipients. complement activation was associated with an increased risk of graft thrombosis. this study indicates that innate immune activation rather than elevated levels may affect early postoperative pancreas graft thrombosis. clinical trial registration: https://clinicaltrials.gov/ct2/show/nct01957696, identifier nct01957696",AB_0539
"data stream prediction is challenging when concepts drift, processing time, and memory constraints come into account. concept drift refers to changes in data distribution over time that reduces prediction systems' accuracy. we present a method for handling concept drift with a domain adaptation approach (cdda) in a data stream. the proposed method passively deals with the concept drift by using the domain adaptation approaches with multiple sources while reducing the model execution time and memory consumption. we introduce two variants of cdda to transfer the information in the multi-source windows to the target window: weighted multi-source cdda and multi-source feature alignment cdda. then, we theoretically study the behavior of cdda and find the generalization bound of cdda for the data stream prediction problem. moreover, an extensive set of experiments conducted on both synthetic and real-world data streams confirms the validity and excellent performance of the proposed approach. our code is available at https://github.com/mahan66/cdda.",AB_0539
"3d hand pose estimation methods have made significant progress recently. however, estimation accuracy is often far from sufficient for specific real-world applications, and thus there is significant room for improvement. this paper proposes trihorn-net, a novel model that uses specific innovations to improve hand pose estimation accuracy on depth images. the first innovation is decomposition of the 3d hand pose estimation into the estimation of 2d joint locations in the depth image space (uv), and the estimation of their corresponding depths aided by two complementary attention maps. this decomposition prevents depth estimation, which is a more difficult task, from interfering with the uv estimations at both the prediction and feature levels. the second innovation is pixdropout, which is, to the best of our knowledge, the first appearance-based data augmentation method for hand depth images. experimental results demonstrate that the proposed model outperforms the state-of-the-art methods on three public benchmark datasets, achieving 5.73 mm, 7.13 mm, and 7.68 mm on the icvl, msra, and nyu datasets, respectively. the proposed model achieves this performance with a relatively fast average inference speed of 9.25 ms per frame on an nvidia 1080ti gpu, which, as discussed in the paper, places the proposed model among the fastest-performing 3d hand pose estimation models. our implementation is available at https://github.com/mrezaei92/trihorn-net.",AB_0539
"cardiovascular disease is one of the leading causes of mortality worldwide and is responsible for millions of deaths annually. one of the most promising approaches to deal with this problem, which has spread recently, is cardiac tissue engineering (cte). many researchers have tried developing scaffolds with different materials, cell lines, and fabrication methods to help regenerate heart tissue. machine learning (ml) is one of the hottest topics in science and technology, revolutionizing many fields and changing our perspective on solving problems. as a result of using ml, some scientific issues have been resolved, including protein-folding, a challenging problem in biology that remained unsolved for 50 years. however, it is not well addressed in tissue engineering. an ai-based software was developed by our group called mlate (machine learning applications in tissue engineering) to tackle tissue engineering challenges, which highly depend on conducting costly and time-consuming experiments. for the first time, to the best of our knowledge, a cte scaffold dataset was created by collecting specifications from the literature, including different materials, cell lines, and fabrication methods commonly used in cte scaffold development. these specifications were used as variables in the study. then, the cte scaffolds were rated based on cell behaviors such as cell viability, growth, proliferation, and differentiation on the scaffold on a scale of 0-3. these ratings were considered a function of the variables in the gathered dataset. it should be stated that this study was merely based on information available in the literature. then, twenty-eight ml algorithms were applied to determine the most effective one for predicting cell behavior on cte scaffolds fabricated by different materials, compositions, and methods. the results indicated the high performance of xgboost with an accuracy of 87%. also, by implementing ensemble learning algorithms and using five algorithms with the best performance, an accuracy of 93% with the adaboost classifier and voting classifier was achieved. finally, the open-source software developed in this study was made available for everyone by publishing the best model along with a step-by-step guide to using it online at: https://github.com/saeedrafieyan/mlate.",AB_0539
"as the outbreak of novel coronavirus disease (covid-19) continues to spread throughout the world, steps are being taken to limit the impact on public health. in the realm of infectious diseases like covid-19, social distancing is one of the effective measures to avoid exposure to the virus and reduce its spread.traveling on public transport can meaningfully facilitate the propagation of the transmission of infectious diseases. accordingly, responsive actions taken by public transit agencies against risk factors can effectively limit the risk and make transit systems safe. among the multitude of risk factors that can affect infection spread on public transport, the likelihood of exposure is a major factor that depends on the number of people riding the public transport and can be reduced by socially distanced settings. considering that many individuals may not act in the socially optimal manner, the necessity of public transit agencies to implement measures and restrictions is vital.in this study, we present a novel web-based application, t-ridership, based on a hybrid optimized dynamic programming inspired by neural networks algorithm to optimize public transit for safety with respect to covid-19. two main steps are taken in the analysis through metropolitan transportation authority (mta): detecting high-density stations by input data normalization, and then, using these results, the t-ridership tool automatically determines optimal station order to avoid overcrowded transit vehicles. effectively our proposed web tool helps public transit to be safe to ride under risk of infections by reducing the density of riders on public transit vehicles as well as trip duration. these results can be used in expanding on and improving policy in public transit, to better plan the scheduled time of trains and buses in a way that prevents high-volume human contact, increases social distance, and reduces the possibility of disease transmission (available at:http://t-ridership.com and github at: https://github.com/imani-saba/tridership).(c) 2023 the authors. published by elsevier b.v. this is an open access article under the cc by license ().",AB_0539
"background and purpose: covid-19, which emerged in wuhan (china), is one of the deadliest and fastest -spreading pandemics as of the end of 2019. according to the world health organization (who), there are more than 100 million infectious cases worldwide. therefore, research models are crucial for managing the pandemic scenario. however, because the behavior of this epidemic is so complex and difficult to understand, an effective model must not only produce accurate predictive results but must also have a clear explanation that enables human experts to act proactively. for this reason, an innovative study has been planned to diagnose troponin levels in the covid-19 process with explainable white box algorithms to reach a clear explanation.methods: using the pandemic data provided by erzurum training and research hospital (decision num-ber: 2022/13-145), an interpretable explanation of troponin data was provided in the covid-19 process with shapley additive explanations (shap) algorithms. five machine learning (ml) algorithms were de-veloped. model performances were determined based on training, test accuracies, precision, f1-score, re-call, and auc (area under the curve) values. feature importance was estimated according to shapley values by applying the shapley additive explanations (shap) method to the model with high accuracy. the model created with streamlit v.3.9 was integrated into the interface with the name cvd22.results: among the five-machine learning (ml) models created with pandemic data, the best model was selected with the values of 1.0, 0.83, 0.86, 0.83, 0.80, and 0.91 in train and test accuracy, precision, f1 -score, recall, and auc values, respectively. as a result of feature selection and shapley additive explana-tions (shap) algorithms applied to the xgboost model, it was determined that ddimer mean, mortality, ckmb (creatine kinase myocardial band), and glucose were the features with the highest importance over the model estimation.conclusions: recent advances in new explainable artificial intelligence (xai) models have successfully made it possible to predict the future using large historical datasets. therefore, throughout the ongoing pandemic, cvd22 ( https://cvd22covid.streamlitapp.com/ ) can be used as a guide to help authorities or medical professionals make the best decisions quickly.(c) 2023 elsevier b.v. all rights reserved.",AB_0539
"objective. reducing plan complexity in intensity modulated radiation therapy (imrt) to ensure dosimetric accuracy and delivery efficiency of the radiation treatment plans. we propose a novel approach by representing the beamlet intensities using an incomplete wavelet basis that explicitly excludes fluctuating intensity maps from the decision space (explicit hard constraint). this technique provides a built-in wavelet-induced smoothness that improves both dosimetric plan quality and delivery efficiency. approach. the beamlet intensity maps need to be especially smooth in the leaf travel direction (referred to as the x-direction). we treat the intensity map of each beam as a 2d image and represent it using the wavelets corresponding to low-frequency changes in the x-direction (i.e. approximation and horizontal). the absence of wavelets corresponding to high-frequency changes (i.e. vertical and diagonal) induces built-in smoothness. we still utilize a regularization term in the objective function to promote smoothness in the y-direction (perpendicular to the x-direction) and further possible smoothness in the x-direction. this technique has been tested on three patient cases of different disease sites (paraspinal, lung, prostate) and all final evaluations and comparisons have been performed on an fda-approved commercial treatment planning system (varian eclipsetm). main results. wavelet-induced smoothness reduced monitor units by about 10%, 45%, and 14% for paraspinal, lung, and prostate cases, respectively. it also improved organ at risk sparing, especially on the complex paraspinal case where it resulted in about 7%, 13%, and 14% less mean dose to esophagus, lung, and cord, respectively. moreover, built-in wavelet-induced smoothness desensitizes the results to changing the weight associated to the regularization term, and thereby mitigates the weight fine-tuning difficulty. significance. fluence smoothness is often achieved by smoothing the beamlet intensity maps using a proper regularization term in the objective function aiming at disincentivizing fluctuation in the beamlet intensities (implicit soft constraint). this work reports a novel application of wavelets in imposing an explicit smoothness hard constraint in the search space using an incomplete wavelet basis. this idea has been successfully applied to exclude complex and clinically irrelevant radiation plans from the search space. the code and pertained models along with a sample dataset are released on our lowdimrt github (https://github.com/portpy-project/ lowdimrt).",AB_0539
"sorption is here proposed as a promising approach for metal pre-concentration and re-covery from wastewater. a study was carried out on the simultaneous sorption of co2+, cu2+, ni2+ and zn2+ on macroalgae, microalgae and cyanobacteria. the effect of ph, initial metal concentration, metal competition and time of contact on metal sorption were evaluated. metal competition hampers sorption at the studied metal concentration ranges. the metal counterion (sulfate, chloride or acetate) did not influence metal sorp-tion. the brown algae sargassum sp. was the most promising sorbent (qmax = 0.66 +/- 0.03 mmol center dot g-1), followed by the microalgae phaeodactylum tricornutum (qmax = 0.36 +/- 0.02 mmol center dot g-1) and the cyanobacteria spirulina sp. (qmax = 0.216 +/- 0.007 mmol center dot g-1). all biomass samples showed preferential sorption of cu2+. the experimental kinetic data were well described by ho's model, showing chemisorption to be the main sorption me-chanism. ion-exchange of ca2+, k+ and h+ also played a significant role in metal sorption. after sorption, metal recovery was achieved resorting to incineration. the metal content of the obtained biochar was 4639-fold higher when compared to the initial aqueous so-lution concentration.(c) 2023 the author(s). published by elsevier ltd on behalf of institution of chemical engineers. this is an open access article under the cc by-nc-nd license (http://creati-vecommons.org/licenses/by-nc-nd/4.0/).",AB_0539
"this work presents a framework for developing physics-informed recurrent neural net-work (pirnn) models and pirnn-based predictive control schemes for batch crystal-lization processes. the population balance model of the aspirin crystallization process is first developed to describe the formation of crystals through nucleation and growth. then, the pirnn modeling scheme is introduced to integrate observational data and mechan-istic models for the development of machine learning models. additionally, the physical constraints on process states are embedded in the machine learning models to prevent physically unreasonable predictions. subsequently, the pirnn model that captures the dynamic behavior of the batch crystallization process is utilized in the design of model predictive controller that optimizes the operation of the crystallizer. through open-loop and closed-loop simulations, it is demonstrated that the pirnn models using less training data achieve prediction accuracy and closed-loop performance comparable to the purely data-driven model.(c) 2023 the authors. published by elsevier ltd on behalf of institution of chemical engineers. this is an open access article under the cc by-nc-nd license (http://creati-vecommons.org/licenses/by-nc-nd/4.0/).",AB_0539
"airport ground handling (agh) offers necessary operations to flights during their turnarounds and is of great importance to the efficiency of airport management and the economics of aviation. such a problem involves the interplay among the operations that leads to np-hard problems with complex constraints. hence, existing methods for agh are usually designed with massive domain knowledge but still fail to yield high-quality solutions efficiently. in this paper, we aim to enhance the solution quality and computation efficiency for solving agh. particularly, we first model agh as a multiple-fleet vehicle routing problem (vrp) with miscellaneous constraints including precedence, time windows, and capacity. then we propose a construction framework that decomposes agh into sub-problems (i.e., vrps) in fleets and present a neural method to construct the routing solutions to these sub-problems. in specific, we resort to deep learning and parameterize the construction heuristic policy with an attention-based neural network trained with reinforcement learning, which is shared across all sub-problems. extensive experiments demonstrate that our method significantly outperforms classic meta-heuristics, construction heuristics and the specialized methods for agh. besides, we empirically verify that our neural method generalizes well to instances with large numbers of flights or varying parameters, and can be readily adapted to solve real-time agh with stochastic flight arrivals. our code is publicly available at: https://github.com/royalskye/agh.",AB_0539
