AB,NO
"mechanistic models are important tools to describe and understand biological processes. however, they typically rely on unknown parameters, the estimation of which can be challenging for large and complex systems. pypesto is a modular framework for systematic parameter estimation, with scalable algorithms for optimization and uncertainty quantification. while tailored to ordinary differential equation problems, pypesto is broadly applicable to black-box parameter estimation problems. besides own implementations, it provides a unified interface to various popular simulation and inference methods. availability and implementation: pypesto is implemented in python, open-source under a 3-clause bsd license. code and documentation are available on github (https://github.com/icb-dcm/pypesto).",AB_0477
"patients on acute psychiatric wards desire more psychosocial treatment than they receive, according to recent studies, but evidence-based interventions tailored to this setting are currently lacking. metacognitive training for psychosis (mct) is a flexible, easy-to-administer group therapy that has been adapted to meet this demand (mct-acute). thirty-seven patients with severe mental illness took part in mct-acute twice a week during their stay on a locked acute ward and were interviewed before, during, and after the intervention period regarding subjective utility, subjective adverse events, and symptom severity; attendance rates and reasons for absence were recorded. in addition, staff rated adverse events, symptom severity, and functioning (german clinical trial register id: drks00020551). overall, most patients evaluated mct-acute positively and reported symptom stabilization. staff also reported improvement in functioning. no clinician-rated adverse events related to participation in mct-acute were reported. conducting mct-acute is feasible and safe and may contribute to meeting patients', practitioners', and researchers' demands for more evidence-based psychotherapeutic interventions for the acute psychiatric care setting.clinical trial registrationid: drks00020551, https://drks.de/search/de/trial/drks00020551",AB_0477
"it is getting increasingly challenging to efficiently exploit drug-related information described in the growing amount of scientific literature. indeed, for drug-gene/protein interactions, the challenge is even bigger, considering the scattered information sources and types of interactions. however, their systematic, large-scale exploitation is key for developing tools, impacting knowledge fields as diverse as drug design or metabolic pathway research. previous efforts in the extraction of drug-gene/protein interactions from the literature did not address these scalability and granularity issues. to tackle them, we have organized the drugprot track at biocreative vii. in the context of the track, we have released the drugprot gold standard corpus, a collection of 5000 pubmed abstracts, manually annotated with granular drug-gene/protein interactions. we have proposed a novel large-scale track to evaluate the capacity of natural language processing systems to scale to the range of millions of documents, and generate with their predictions a silver standard knowledge graph of 53 993 602 nodes and 19 367 406 edges. its use exceeds the shared task and points toward pharmacological and biological applications such as drug discovery or continuous database curation. finally, we have created a persistent evaluation scenario on codalab to continuously evaluate new relation extraction systems that may arise. thirty teams from four continents, which involved 110 people, sent 107 submission runs for the main drugprot track, and nine teams submitted 21 runs for the large scale drugprot track. most participants implemented deep learning approaches based on pretrained transformer-like language models (lms) such as bert or biobert, reaching precision and recall values as high as 0.9167 and 0.9542 for some relation types. finally, some initial explorations of the applicability of the knowledge graph have shown its potential to explore the chemical-protein relations described in the literature, or chemical compound-enzyme interactions.database url: https://doi.org/10.5281/zenodo.4955410",AB_0477
"navigating robots with precision in complex environments remains a significant challenge. in this article, we present an innovative approach to enhance robot localization in dynamic and intricate spaces like homes and offices. we leverage visual question answering (vqa) techniques to integrate semantic insights into traditional mapping methods, formulating a novel position hypothesis generation to assist localization methods, while also addressing challenges related to mapping accuracy and localization reliability. our methodology combines a probabilistic approach with the latest advances in monte carlo localization methods and visual language models. the integration of our hypothesis generation mechanism results in more robust robot localization compared to existing approaches. experimental validation demonstrates the effectiveness of our approach, surpassing state-of-the-art multi-hypothesis algorithms in both position estimation and particle quality. this highlights the potential for accurate self-localization, even in symmetric environments with large corridor spaces. furthermore, our approach exhibits a high recovery rate from deliberate position alterations, showcasing its robustness. by merging visual sensing, semantic mapping, and advanced localization techniques, we open new horizons for robot navigation. our work bridges the gap between visual perception, semantic understanding, and traditional mapping, enabling robots to interact with their environment through questions and enrich their map with valuable insights. the code for this project is available on github https://github.com/juandpenan/topology_nav_ros2.",AB_0477
"backgroundgalaxy is a web-based open-source platform for scientific analyses. researchers use thousands of high-quality tools and workflows for their respective analyses in galaxy. tool recommender system predicts a collection of tools that can be used to extend an analysis. in this work, a tool recommender system is developed by training a transformer on workflows available on galaxy europe and its performance is compared to other neural networks such as recurrent, convolutional and dense neural networks.resultsthe transformer neural network achieves two times faster convergence, has significantly lower model usage (model reconstruction and prediction) time and shows a better generalisation that goes beyond training workflows than the older tool recommender system created using rnn in galaxy. in addition, the transformer also outperforms cnn and dnn on several key indicators. it achieves a faster convergence time, lower model usage time, and higher quality tool recommendations than cnn. compared to dnn, it converges faster to a higher precision@k metric (approximately 0.98 by transformer compared to approximately 0.9 by dnn) and shows higher quality tool recommendations.conclusionour work shows a novel usage of transformers to recommend tools for extending scientific workflows. a more robust tool recommendation model, created using a transformer, having significantly lower usage time than rnn and cnn, higher precision@k than dnn, and higher quality tool recommendations than all three neural networks, will benefit researchers in creating scientifically significant workflows and exploratory data analysis in galaxy. additionally, the ability to train faster than all three neural networks imparts more scalability for training on larger datasets consisting of millions of tool sequences. open-source scripts to create the recommendation model are available under mit licence at https://github.com/anuprulez/galaxy_tool_recommendation_transformers",AB_0477
"parkinson's disease (pd) is the second most prevalent neurodegenerative disorder, yet effective treatments able to stop or delay disease progression remain elusive. the aggregation of a presynaptic protein, alpha-synuclein (asyn), is the primary neurological hallmark of pd and, thus, a promising target for therapeutic intervention. however, the lack of consensus on the molecular properties required to specifically bind the toxic species formed during asyn aggregation has hindered the development of therapeutic molecules. recently, we defined and experimentally validated a peptide architecture that demonstrated high affinity and selectivity in binding to asyn toxic oligomers and fibrils, effectively preventing asyn pathogenic aggregation. human peptides with such properties may have neuroprotective activities and hold a huge therapeutic interest. driven by this idea, here, we developed a discriminative algorithm for the screening of human endogenous neuropeptides, antimicrobial peptides and diet-derived bioactive peptides with the potential to inhibit asyn aggregation. we identified over 100 unique biogenic peptide candidates and ensembled a comprehensive database (asynpep-db) that collects their physicochemical features, source datasets and additional therapeutic-relevant information, including their sites of expression and associated pathways. besides, we provide access to the discriminative algorithm to extend its application to the screening of artificial peptides or new peptide datasets. asynpep-db is a unique repository of peptides with the potential to modulate asyn aggregation, serving as a platform for the identification of previously unexplored therapeutic agents.database url: https://asynpepdb.ppmclab.com/",AB_0477
"motivation: next-generation sequencing methods continue improving the annotation of genomes in part by determining the distribution of features such as epigenetic marks. evaluating and interpreting the association between genomic regions and their features has become a common and challenging analysis in genomic and epigenomic studies. results: with regioner we provided an r package allowing to assess the statistical significance of pairwise associations between genomic region sets using permutation tests. we now present the r package regionereloaded that builds upon regioner's statistical foundation and extends the functionality for the simultaneous analysis and visualization of the associations between multiple genomic region sets. thus, we provide a novel discovery tool for the identification of significant associations that warrant to be tested for functional interdependence. availability and implementation: regionereloaded is an r package released under an artistic-2.0 license. the source code and documentation are freely available through bioconductor: http://www.bioconductor.org/packages/regionereloaded.",AB_0477
"motivation biomedical entity linking (bel) is the task of grounding entity mentions to a knowledge base (kb). it plays a vital role in information extraction pipelines for the life sciences literature. we review recent work in the field and find that, as the task is absent from existing benchmarks for biomedical text mining, different studies adopt different experimental setups making comparisons based on published numbers problematic. furthermore, neural systems are tested primarily on instances linked to the broad coverage kb umls, leaving their performance to more specialized ones, e.g. genes or variants, understudied.results we therefore developed belb, a biomedical entity linking benchmark, providing access in a unified format to 11 corpora linked to 7 kbs and spanning six entity types: gene, disease, chemical, species, cell line, and variant. belb greatly reduces preprocessing overhead in testing bel systems on multiple corpora offering a standardized testbed for reproducible experiments. using belb, we perform an extensive evaluation of six rule-based entity-specific systems and three recent neural approaches leveraging pre-trained language models. our results reveal a mixed picture showing that neural approaches fail to perform consistently across entity types, highlighting the need of further studies towards entity-agnostic models.availability and implementation the source code of belb is available at: https://github.com/sg-wbi/belb. the code to reproduce our experiments can be found at: https://github.com/sg-wbi/belb-exp.",AB_0477
"background: the optimal placement of a chest drain after video-assisted minimally invasive lobectomy should facilitate the aspiration of air and drainage of fluid. typically, a conventional 24ch polyvinyl chloride chest drain is used for this purpose. however, there is currently no scientific literature available on the impact of drain diameter on postoperative outcomes following anatomical lung resection. methods: this is a prospective, randomized, phase-1 trial that will include 40 patients, which will be randomly assigned into two groups. group 1 will receive a 24 french chest drain according to current standards, while group 2 will receive a 14 french drain. primary endpoint of the trial is the incidence of postoperative drainage-related complications, such as obstruction, dislocation, pleural effusion, and reintervention. secondary endpoints are postoperative pain, chest drainage duration, incidence of complications, and hospital length of stay. the study aims to determine the number of subjects needed to achieve a sufficient test power of 0.8 for a non-inferiority study. discussion: thoracic surgery is becoming more and more minimally invasive. one of the remaining unresolved problems is postoperative pain, with the intercostal drain being one of the main contributing factors. previous data from other studies suggest that the use of small-bore drains can reduce pain and speed up recovery without an increase in drain-related complications. however, no studies have been conducted on patients undergoing anatomic lung resections to date. the initial step in transitioning from larger to smaller drains is to establish the safety of this approach, which is the primary objective of this trial. trial registration: the study has been registered in the german clinical trials register. registration number: drks00029982. url: https://drks.de/search/de/trial/drks00029982.",AB_0477
"the human microbiome has emerged as a rich source of diverse and bioactive natural products, harboring immense potential for therapeutic applications. to facilitate systematic exploration and analysis of its biosynthetic landscape, we present abc-humi: the atlas of biosynthetic gene clusters (bgcs) in the human microbiome. abc-humi integrates data from major human microbiome sequence databases and provides an expansive repository of bgcs compared to the limited coverage offered by existing resources. employing state-of-the-art bgc prediction and analysis tools, our database ensures accurate annotation and enhanced prediction capabilities. abc-humi empowers researchers with advanced browsing, filtering, and search functionality, enabling efficient exploration of the resource. at present, abc-humi boasts a catalog of 19 218 representative bgcs derived from the human gut, oral, skin, respiratory and urogenital systems. by capturing the intricate biosynthetic potential across diverse human body sites, our database fosters profound insights into the molecular repertoire encoded within the human microbiome and offers a comprehensive resource for the discovery and characterization of novel bioactive compounds. the database is freely accessible at https://www.ccb.uni-saarland.de/abc_humi/. graphical abstract",AB_0477
