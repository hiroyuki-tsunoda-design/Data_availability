AB,NO
"accurately and timely detecting multiscale small objects that contain tens of pixels from remote sensing images (rsi) remains challenging. most of the existing solutions primarily design complex deep neural networks to learn strong feature representations for objects separated from the background, which often results in a heavy computation burden. in this article, we propose an accurate yet fast object detection method for rsi, named superyolo, which fuses multimodal data and performs high-resolution (hr) object detection on multiscale objects by utilizing the assisted super resolution (sr) learning and considering both the detection accuracy and computation cost. first, we utilize a symmetric compact multimodal fusion (mf) to extract supplementary information from various data for improving small object detection in rsi. furthermore, we design a simple and flexible sr branch to learn hr feature representations that can discriminate small objects from vast backgrounds with low-resolution (lr) input, thus further improving the detection accuracy. moreover, to avoid introducing additional computation, the sr branch is discarded in the inference stage, and the computation of the network model is reduced due to the lr input. experimental results show that, on the widely used vedai rs dataset, superyolo achieves an accuracy of 75.09% (in terms of map(50)), which is more than 10% higher than the sota large models, such as yolov5l, yolov5x, and rs designed yolors. meanwhile, the parameter size and gflops of superyolo are about 18x and 3.8x less than yolov5x. our proposed model shows a favorable accuracy-speed tradeoff compared to the state-of-the-art models. the code will be open-sourced at https://github.com/icey-zhang/superyolo.",AB_0294
"recent deep-learning-based works have made remarkable progress in remote-sensing image super-resolution (rsisr). however, the complicated network architecture and a huge amount of parameters increase the computational cost, hindering their practical deployment. to alleviate this problem, we propose a novel re-parameterized feature distillation network (refdn) for lightweight and efficient rsisr tasks. feature distillation, refinement, condensation, and enhancement are efficiently integrated into the re-parameterized feature distillation block named refdb for lighter and stronger feature extraction. with the help of elaborate re-parameterized convolution (reconv) design, we further boost the feature refinement capability without extra inference costs. in addition, we design an efficient channel and spatial attention module (ecsa) to enhance the important objects and regions of the intermediate features adaptively. conducted on both commonly used datasets and additional google earth data, the experimental results demonstrate that our method can achieve a good tradeoff between sr performance and network complexity. our code will be publicly available at https://github.com/daxingz/refdn.",AB_0294
"hyperspectral image change detection (hsi-cd) is a technique to accurately detect land cover changes by using hsis with rich spatial-spectral information. in recent years, the hsi-cd methods based on convolutional neural networks (cnns) have achieved great success because of their flexible and effective feature extraction ability. however, these methods often take the hsi patches as the input of the networks, which undoubtedly hinders the overall perception of the hsis. meanwhile, the valuable temporal information in hsis is often underutilized. for this end, a triplet transformer framework (tritf) based on parents-temporal attention (pta) and brother-spatial attention (bsa) is proposed for hsi-cd. the proposed framework mainly contains the following three parts: 1) transformer-based network backbone, which uses the self-attention to capture the correlation between arbitrarily two pixels in the same patch and extracts the global spatial correlation in the unit of encoded input patches; 2) pta branch; unlike the previous cross-temporal attention mechanisms of the t1 -> t2 which only consider the interaction between bitemporal hsis, this article constructs a novel pta of the t1 -> t2 -> t3mode, which takes the difference-temporal image t3 as the core and the impact of bitemporal hsis on the land cover changes is more concerned in the pta; and 3) bsa branch. the most similar patch in the current training batch of each patch is defined as its brother patch. furthermore, cross-spatial attention is applied to propagate the features of the brother patch to the current patch. thus, the middle- and long-range dependencies can be utilized and the scope of feature propagation can be extended. in this article, the experiments under low and high sampling rates are conducted and proved the outstanding change detection performance of the proposed tritf when compared with abundant state-of-the-art (sota) cd algorithms. the source code of this article will be released at https://github.com/zkylnnu/tritf.",AB_0294
"dynamic hand gesture is an emerging and promising biometric trait. it contains both physiological and behavioral characteristics, which on the one hand can theoretically make authentication systems more accurate and more secure, and on the other hand can increase the difficulty of model design because it is essentially a fine-grained video understanding task. for authentication systems, equal error rate (eer) and real-time performance are two vital metrics. current video understanding-based hand gesture authentication methods mainly focus on lowering the eer while neglecting to reduce the computational cost. in this paper, we propose a 2d cnn-based depthwise temporal non-local network (dwtnl-net) that can take into account both eer and running efficiency. to enable the dwtnl-net with spatiotemporal information processing capability, we design a temporal sharpening (ts) module and a dwtnl module for short- and long-term identity feature modeling, respectively. the ts module can assist the backbone in local behavioral characteristic understanding and can simultaneously reduce redundant information and highlight behavioral cues while retaining sufficient physiological characteristics. in contrast, the dwtnl module focuses on summarizing global information and discovering stable patterns, which are finally used for local information enhancement. the complementary combination of our ts and dwtnl modules makes dwtnl-net achieve substantial performance improvements. extensive experiments on the scut-dhga dataset and sufficient statistical analyses fully demonstrate the superiority and efficiency of our dwtnl-net. the code is available at https://github.com/scut-bip-lab/dwtnl-net.",AB_0294
"occlusion poses a major challenge for person re-identification (reid). existing approaches typically rely on outside tools to infer visible body parts, which may be suboptimal in terms of both computational efficiency and reid accuracy. in particular, they may fail when facing complex occlusions, such as those between pedestrians. accordingly, in this paper, we propose a novel method named quality-aware part models (qpm) for occlusion-robust reid. first, we propose to jointly learn part features and predict part quality scores. as no quality annotation is available, we introduce a strategy that automatically assigns low scores to occluded body parts, thereby weakening the impact of occluded body parts on reid results. second, based on the predicted part quality scores, we propose a novel identity-aware spatial attention (isa) module. in this module, a coarse identity-aware feature is utilized to highlight pixels of the target pedestrian, so as to handle the occlusion between pedestrians. third, we design an adaptive and efficient approach for generating global features from common non-occluded regions with respect to each image pair. this design is crucial, but is often ignored by existing methods. qpm has three key advantages: 1) it does not rely on any outside tools in either the training or inference stages; 2) it handles occlusions caused by both objects and other pedestrians; 3) it is highly computationally efficient. experimental results on four popular databases for occluded reid demonstrate that qpm consistently outperforms state-of-the-art methods by significant margins. the code of qpm is available at https://github.com/wang-pengfei/qpm.",AB_0294
"hyperspectral image (hsi) classification based on neural architecture search (nas) is a currently attractive frontier as it not only automatically searches complex neural network architecture but also avoids professional knowledge and experience design and alleviates the lacking of generalization ability as well when dealing with a new classification task. however, the existing hsi classification based on nas has some drawbacks: 1) a huge number of training parameters and high calculations are inductive to overfitting and high complexity and 2) efficient operators are lacking in the search space, which can distinguish spatial locations and spectral features in different bands. furthermore, as the category samples in hsi data show a serious long-tail distribution phenomenon, hsi classification remains challenging. to address these issues, we propose a lightweight multiscale nas with spatial-spectral attention (lmss-nas) for hsi classification. the main work includes threefold: 1) in order to reduce the number of model parameters and promote spectral-spatial feature fusion, a new lightweight efficient search space is designed, which consists of three equivalent lightweight convolution operators with multiple receptive fields; 2) to fully use the spectral-spatial correlation of hsi, a cube-to-pixel classification framework is designed to mine the local spatial and spectral context; and 3) focal loss and label smoothing loss in computer vision tasks are jointly migrated to lmss-nas to improve the unbalanced samples' classification and model robustness. experimental results on four public hyperspectral datasets show that the proposed method can achieve competitive classification performance as well as low computational cost. the code is available at https://github.com/xh-captain/lmss-nas.",AB_0294
"semantic segmentation is an extremely challenging task in high-resolution remote sensing (hrrs) images as objects have complex spatial layouts and enormous variations in appearance. convolutional neural networks (cnns) have an excellent ability to extract local features and have been widely applied as a feature extractor for various vision tasks. however, due to the inherent inductive bias of convolution operation, cnns inevitably have limitations in modeling long-range dependencies. transformer can capture global representations well but unfortunately ignores the details of local features and has high computational and spatial complexity in processing high-resolution feature maps. in this article, we propose a novel hybrid architecture for hrrs image segmentation, termed enhancing multiscale representations with transformer (emrt), to exploit the advantages of convolution operations and transformer to enhance multiscale representation learning. we incorporate the deformable self-attention mechanism in the transformer to automatically adjust the receptive field and design an encoder-decoder architecture accordingly to achieve efficient context modeling. specifically, cnn is constructed to extract feature representations. in the encoder, local features and global representations at different resolutions are extracted by the cnn and transformer, respectively, and fused in an interactive manner. moreover, a separate spatial branch is designed to extract multiscale contextual information as queries, and global dependencies between features at different scales are efficiently established by the decoder. extensive experiments on three public remote sensing datasets demonstrate the superiority of emrt and indicate that the overall performance of our method outperforms state-of-the-art methods. code is available at https://github.com/peach-xiao/emrt.",AB_0294
"in this article, we propose a novel multipatch and multistage pansharpening method with knowledge distillation, termed psdnet. different from the existing pansharpening methods that typically input single-size patches to the network and implement pansharpening in an overall stage, we design multipatch inputs and a multistage network for more accurate and finer learning. first, multipatch inputs allow the network to learn more accurate spatial and spectral information by reducing the number of object types. we employ small patches in the early part to learn accurate local information, as small patches contain fewer object types. then, the later part exploits large patches to fine-tune it for the overall information. second, the multistage network is designed to reduce the difficulty of the previous single-step pansharpening and progressively generate elaborate results. in addition, instead of the traditional perceptual loss, which hardly relates to the specific task or the designed network, we introduce distillation loss to reinforce the guidance of the ground truth. extensive experiments are conducted to demonstrate the superior performance of our proposed psdnet to the existing state-of-the-art methods. our code is available at https://github.com/meiqi-gong/psdnet.",AB_0294
"the detection of electrical insulators in unmanned aerial vehicle (uav) images using deep learning has made great progress in recent years, but little research has been conducted in the same field in remote sensing (rs) images. in this article, a novel method was proposed to detect insulators on 500-kv transmission towers in rs images. the proposed method consists of three components including 1) a super-resolution (sr) network to improve image resolution; 2) an object detection model to detect 110-, 220-, and 500-kv electrical power towers along transmission pipelines; and 3) a semantic segmentation network to identify insulators on the detected 500-kv towers. in addition, the online hard example mining (ohem) method and class weight calculation method were utilized to handle the imbalanced data among different classes during training. the proposed model was evaluated on superview-1 and worldview-3 satellite images collected in four regions. experimental results show that the proposed method can effectively detect insulators in high-resolution satellite images and achieved the highest f1 score of 0.7952. the codes are available at https://github.com/hardworking-jws/insulator-detection-remote-sensing",AB_0294
"the interpolation and reconstruction of missing traces are crucial steps in seismic data processing; moreover, it is also a highly ill-posed problem, especially for complex cases such as high-ratio random discrete missing, continuous missing, and missing in fault-rich or salt body surveys. these complex cases are rarely mentioned in current works. to cope with complex missing cases, we propose multidimensional adversarial generative adversarial network (mda gan), a novel 3-d gan framework. it keeps the anisotropy and spatial continuity of the data after 3-d complex missing reconstruction using three discriminators. the feature splicing module is designed and embedded in the generator to retain more information of the input data. the tanh cross entropy (tce) loss is derived, which provides the generator with the optimal reconstruction gradient to make the generated data smoother and continuous. we experimentally verified the effectiveness of the individual components of the study and then tested the method on multiple publicly available data. the method achieves reasonable reconstructions for up to 95% of random discrete missing and 100 traces of continuous missing. in fault and salt body enriched surveys, mda gan still yields promising results for complex cases. experimentally, it has been demonstrated that our method achieves better performance than other methods in both simple and complex cases. moreover, our network does not require training weights for each survey, the same weights it uses are applied to multiple surveys, significantly reducing time and computational costs, and we make the model publicly available on https://github.com/douyimin/mda_gan.",AB_0294
