AB,NO
"phasic small interfering rnas are plant secondary small interference rnas that typically generated by the convergence of mirnas and polyadenylated mrnas. a growing number of studies have shown that mirna-initiated phasirna plays crucial roles in regulating plant growth and stress responses. experimental verification of mirna-initiated phasirna loci may take considerable time, energy and labor. therefore, computational methods capable of processing high throughput data have been proposed one by one. in this work, we proposed a predictor (digital) for identifying mirna-initiated phasirnas in plant, which combined a multi-scale residual network with a bi-directional long-short term memory network. the negative dataset was constructed based on positive data, through replacing 60% of nucleotides randomly in each positive sample. our predictor achieved the accuracy of 98.48% and 94.02% respectively on two independent test datasets with different sequence length. these independent testing results indicate the effectiveness of our model. furthermore, digital is of robustness and generalization ability, and thus can be easily extended and applied for mirna target recognition of other species. we provide the source code of digital, which is freely available at https://github.com/yuanyuanbu/digital.",AB_0295
"the coronavirus (covid-19) outbreak of december 2019 has become a serious threat to people around the world, creating a health crisis that infected millions of lives, as well as destroying the global economy. early detection and diagnosis are essential to prevent further transmission. the detection of covid-19 computed tomography images is one of the important approaches to rapid di-agnosis. many different branches of deep learning methods have played an important role in this area, including transfer learning, contrastive learning, ensemble strategy, etc. however, these works require a large number of samples of expensive manual labels, so in order to save costs, scholars adopted semi -supervised learning that applies only a few labels to classify covid-19 ct images. nevertheless, the existing semi-supervised methods focus primarily on class imbalance and pseudo-label filtering rather than on pseudo-label generation. accordingly, in this paper, we organized a semi-supervised classifi-cation framework based on data augmentation to classify the ct images of covid-19. we revised the classic teacher-student framework and introduced the popular data augmentation method mixup, which widened the distribution of high confidence to improve the accuracy of selected pseudo-labels and ulti-mately obtain a model with better performance. for the covid-ct dataset, our method makes preci-sion, f1 score, accuracy and specificity 21.04%, 12.95%, 17.13% and 38.29% higher than average val-ues for other methods respectively, for the sars-cov-2 dataset, these increases were 8.40%, 7.59%, 9.35% and 12.80% respectively. for the harvard dataverse dataset, growth was 17.64%, 18.89%, 19.81% and 20.20% respectively. the codes are available at https://github.com/yutingbai99/covid-19-ssl.",AB_0295
"captured images of outdoor scenes usually exhibit low visibility in cases of severe haze, which interferes with optical imaging and degrades image quality. most of the existing methods solve the single-image dehazing problem by applying supervised training on paired images; however, in practice, the pairing of real-world images is not viable. additionally, the processing speed of individual dehazing models is important in practical applications. in this study, a novel unsupervised single image dehazing network (usid-net) based on disentangled representations without paired training images is explored. furthermore, considering the trade-off between performance and memory storage, a compact multi-scale feature attention (mfa) module is developed, integrating multi-scale feature representation and attention mechanism to facilitate feature representation. to effectively extract haze information, a mechanism referred to as octencoder is designed to include multi-frequency representations that can capture more global information. extensive experiments show that usid-net achieves competitive dehazing results and a relatively high processing speed compared to state-of-the-art methods. the source code is available at https://github.com/dehazing/usid-net.",AB_0295
"building extraction from satellite images has been a hot research topic in the field of remote-sensing image analysis. most of the related studies are focusing on urban areas with dense populations, while solutions for underpopulated mountainous areas are still missing. given the scarcity of research materials, it is still an important topic for applications like mountain hazard damage management. to fill this gap, we present a new dataset for scattered mountainous area building segmentation, consisting of the manual labels and the coordinates of latitude and longitude for 2125 satellite images of 303 diverse human settlements in the mountainous areas of southwest china. compared with the public remote-sensing image datasets, our dataset is very challenging with relatively low resolution (2.2 m/pixel) and small-object, blurry-boundary, and high-imbalance features. in this letter, we propose a novel copy-fusion (cf) data augmentation strategy and designed a vgg-16+u-net with dice focal loss to address the difficulties in this building extraction task. experimental results have shown that our approach has achieved 81.79% mean intersection over union (iou) and outperformed the baseline building segmentation methods like hrnet, deeplabv3+, and u-net+resnet by 6.29%. our dataset and model will be available at https://github.com/angcv/smab_dataset.",AB_0295
"deep learning models often fit undesired dataset bias in training. in this paper, we formulate the bias using causal inference, which helps us uncover the ever-elusive causalities among the key factors in training, and thus pursue the desired causal effect without the bias. we start from revisiting the process of building a visual recognition system, and then propose a structural causal model (scm) for the key variables involved in dataset collection and recognition model: object, common sense, bias, context, and label prediction. based on the scm, one can observe that there are good and bad biases. intuitively, in the image where a car is driving on a high way in a desert, the good bias denoting the common-sense context is the highway, and the bad bias accounting for the noisy context factor is the desert. we tackle this problem with a novel causal interventional training (cit) approach, where we control the observed context in each object class. we offer theoretical justifications for cit and validate it with extensive classification experiments on cifar-10, cifar-100 and imagenet, e.g., surpassing the standard deep neural networks resnet-34 and resnet-50, respectively, by 0.95% and 0.70% accuracies on the imagenet. our code is open-sourced on the github https://github.com/qinwei-hfut/cit.",AB_0295
"deepfake detection aims to differentiate falsified faces from real ones. most approaches formulate it as a binary classification problem by solely mining the local artifacts and inconsistencies of face forgery, which neglect the relation across local regions. although several recent works explore local relation learning for deepfake detection, they overlook the propagation of relational information and lead to limited performance gains. to address these issues, this paper provides a new perspective by formulating deepfake detection as a graph classification problem, in which each facial region corresponds to a vertex. but relational information with large redundancy hinders the expressiveness of graphs. inspired by the success of masked modeling, we propose masked relation learning which decreases the redundancy to learn informative relational features. specifically, a spatiotemporal attention module is exploited to learn the attention features of multiple facial regions. a relation learning module masks partial correlations between regions to reduce redundancy and then propagates the relational information across regions to capture the irregularity from a global view of the graph. we empirically discover that a moderate masking rate (e.g., 50%) brings the best performance gain. experiments verify the effectiveness of masked relation learning and demonstrate that our approach outperforms the state of the art by 2% auc on the cross-dataset deepfake video detection. code will be available at https://github.com/zimyang/maskrelation.",AB_0295
"in recent years, binary hashing methods have been widely used in large-scale multimedia retrieval because of the low computational complexity and memory cost. generally, better retrieval accuracy can be achieved with a longer hash code, which, however, may suffer redundancy. in this paper, we propose a novel hash bit selection method, called hash bit selection with reinforcement learning (hbs-rl), which aims to adaptively select the most informative bits from the database binary codes. in our approach, the hash bit selection problem is firstly modeled as a markov decision process (mdp), which is solved with reinforcement learning. hbs-rl learns a policy for bit selection, which effectively identifies the most informative bits by directly maximizing mean average precision (map) during training. specially, given a generated bit pool, our hbs-rl can sequentially select bits with different code lengths with a very lightweight fully-connected policy network. the proposed method is evaluated on the mnist, cifar-10, imagenet and nus-wide datasets, and the results show that it significantly improves the retrieval performance of the existing unsupervised and deep supervised hashing methods. it also outperforms the state-of-the-art bit selection methods. for convenience of repeating our results, we release our source code at: https://github.com/ xyez/ hbs- rl.",AB_0295
"weakly supervised image segmentation trained with image-level labels usually suffers from inaccurate coverage of object areas during the generation of the pseudo groundtruth. this is because the object activation maps are trained with the classification objective and lack the ability to generalize. to improve the generality of the object activation maps, we propose a region prototypical network (rpnet) to explore the cross-image object diversity of the training set. similar object parts across images are identified via region feature comparison. object confidence is propagated between regions to discover new object areas while background regions are suppressed. experiments show that the proposed method generates more complete and accurate pseudo object masks while achieving state-of-the-art performance on pascal voc 2012 and ms coco. in addition, we investigate the robustness of the proposed method on reduced training sets. the code is available at https://github.com/liuweide01/rpnet-weakly-supervised-segmentation.",AB_0295
"stereo matching of high-resolution satellite images (hrsis) is still a fundamental but challenging task in the field of photogrammetry and remote sensing. recently, deep learning (dl) methods have demonstrated the potential for stereo matching on public benchmark datasets. currently, mainstream stereo matching models depend on quantities of training data with ground truth. however, datasets for stereo matching of satellite images are scarce, which profoundly blocks the application of dl in this field. to facilitate further research, this article publishes a large-scale dataset, termed whu-stereo, for stereo matching dl network training and testing. this dataset is created by using airborne light detection and ranging (lidar) point clouds and high-resolution stereo imageries taken from the chinese gaofen-7 (gf-7) satellite. occlusions should be seriously considered in the generation of ground-truth disparities. we propose an occlusion removal technique, which can adapt to point clouds with different densities and shows high potential in training data preparation. the whu-stereo dataset contains more than 1700 epipolar rectified image pairs, which cover six areas in china and includes various kinds of landscapes. we have assessed the accuracy of ground-truth disparity maps, and it is shown that our dataset achieves comparable precision compared with existing state-of-the-art stereo matching datasets. to verify its feasibility, in experiments, the handcrafted semiglobal matching (sgm) algorithm and recent dl networks have been tested on the dataset. experimental results show that the whu-stereo dataset can serve as a challenging benchmark for stereo matching of hrsis and performance evaluation of dl models. our dataset is available at https://github.com/sheng029/whu-stereo.",AB_0295
"deep learning is being increasingly employed for hyperspectral classification, although such use is often predicated on the availability of a sufficiently large set of labeled samples for training. to improve classification performance under a limited training-set size, a semi-supervised network with end-to-end local-global active learning (al) based on graph convolutional networks (gcns) is proposed. the proposed al extracts both global as well as local graph-based features to gauge the discriminative information in unlabeled samples, while semi-supervised classification expands the training set of a fully supervised classifier by attaching pseudo-labels to high-confidence unlabeled samples. experimental results demonstrate that the proposed network outperforms not only other approaches to semi-supervised classification but also several existing fully supervised methods. the source code of this method can be found at https://github.com/xtaos/semi-lg-agcn.",AB_0295
