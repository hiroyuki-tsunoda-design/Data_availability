AB,NO
"background: assessing the performance of machine learning (ml) models requires careful consideration of the evaluation metrics used. it is often necessary to utilize multiple metrics to gain a comprehensive understanding of a trained model's performance, as each metric focuses on a specific aspect. however, comparing the scores of these individual metrics for each model to determine the best-performing model can be time-consuming and susceptible to subjective user preferences, potentially introducing bias. results: we propose the machine learning cumulative performance score (mlcps), a novel evaluation metric for classification problems. mlcps integrates several precomputed evaluation metrics into a unified score, enabling a comprehensive assessment of the trained model's strengths and weaknesses. we tested mlcps on 4 publicly available datasets, and the results demonstrate that mlcps provides a holistic evaluation of the model's robustness, ensuring a thorough understanding of its overall performance. conclusions: by utilizing mlcps, researchers and practitioners no longer need to individually examine and compare multiple metrics to identify the best-performing models. instead, they can rely on a single mlcps value to assess the overall performance of their ml models. this streamlined evaluation process saves valuable time and effort, enhancing the efficiency of model evaluation. mlcps is available as a python package at https://pypi.org/project/mlcps/.",AB_0476
"chromosome conformation capture (3c) sequencing approaches, like hi-c or micro-c, allow for an unbiased view of chromatin interactions. most analysis methods rely on so-called interaction matrices, which are derived from counting read pairs in bins of fixed size. here, we propose the voronoi diagram, as implemented in voronoi for chromosome conformation capture data visualization (v3c-viz) to visualize 3c data. the voronoi diagram corresponds to an adaptive-binning strategy that adapts to the local densities of points. in this way, visualization of data obtained by moderate sequencing depth pinpoint many, if not most, interesting features such as high frequency contacts. the favorable visualization properties of the voronoi diagram indicate that the voronoi diagram as density estimator can be used to identify high frequency contacts at a resolution approaching the typical size of enhancers and promoters. v3c-viz is available at https://github.com/imbblab/v3c-viz.",AB_0476
"background: probable sarcopenia is determined by a reduction in muscle strength assessed with the handgrip strength test or 5 times sit-to-stand test, and it is confirmed with a reduction in muscle quantity determined by dual-energy x-ray absorptiometry or bioelectrical impedance analysis. however, these parameters are not implemented in clinical practice mainly due to a lack of equipment and time constraints. nowadays, the technical innovations incorporated in most smartphone devices, such as high-speed video cameras, provide the opportunity to develop specific smartphone apps for measuring kinematic parameters related with sarcopenia during a simple sit-to-stand transition. objective: we aimed to create and validate a sit-to-stand video analysis-based app for diagnosing sarcopenia in community-dwelling older adults and to analyze its construct validity with health-related risk factors and frailty.methods: a total of 686 community-dwelling older adults (median age: 72 years; 59.2% [406/686] female) were recruited from elderly social centers. the index test was a sit-to-stand video analysis-based app using muscle power and calf circumference as proxies of muscle strength and muscle quantity, respectively. the reference standard was obtained by different combinations of muscle strength (handgrip strength or 5 times sit-to-stand test result) and muscle quantity (appendicular skeletal mass or skeletal muscle index) as recommended by the european working group on sarcopenia in older people-2 (ewgsop2). sensitivity, specificity, positive and negative predictive values, and area under the curve (auc) of the receiver operating characteristic curve were calculated to determine the diagnostic accuracy of the app. construct validity was evaluated using logistic regression to identify the risks associated with health-related outcomes and frailty (fried phenotype) among those individuals who were classified as having sarcopenia by the index test. results: sarcopenia prevalence varied from 2% to 11% according to the different combinations proposed by the ewgsop2 guideline. sensitivity, specificity, and auc were 70%-83.3%, 77%-94.9%, and 80.5%-87.1%, respectively, depending on the diagnostic criteria used. likewise, positive and negative predictive values were 10.6%-43.6% and 92.2%-99.4%, respectively. these results proved that the app was reliable to rule out the disease. moreover, those individuals who were diagnosed with sarcopenia according to the index test showed more odds of having health-related adverse outcomes and frailty compared to their respective counterparts, regardless of the definition proposed by the ewgsop2. conclusions: the app showed good diagnostic performance for detecting sarcopenia in well-functioning spanish community-dwelling older adults. individuals with sarcopenia diagnosed by the app showed more odds of having health-relatedrisk factors and frailty compared to their respective counterparts. these results highlight the potential use of this app in clinical settings. trial registration: clinicaltrials.gov nct05148351; https://clinicaltrials.gov/study/nct05148351international registered report identifier (irrid): rr2-10.3390/s22166010",AB_0476
"we introduce promoter-enhancer-guided interaction networks (penguin), a method for studying protein-protein interaction (ppi) networks within enhancer-promoter interactions. penguin integrates h3k27ac-hichip data with tissue-specific ppis to define enhancer-promoter ppi networks (epins). we validated penguin using cancer (lncap) and benign (lhsar) prostate cell lines. our analysis detected epin clusters enriched with the architectural protein ctcf, a regulator of enhancer-promoter interactions. ctcf presence was coupled with the prevalence of prostate cancer (prca) single nucleotide polymorphisms (snps) within the same epin clusters, suggesting functional implications in prca. within the epins displaying enrichments in both ctcf and prca snps, we also show enrichment in oncogenes. we substantiated our identified snps through crispr/cas9 knockout and rnai screens experiments. here we show that penguin provides insights into the intricate interplay between enhancer-promoter interactions and ppi networks, which are crucial for identifying key genes and potential intervention targets. a dedicated server is available at https://penguin.life.bsc.es/. the authors reconstruct high fidelity networks of protein-protein interactions between promoters and enhancers in prostate cancer and demonstrate the potential of such an analytical framework to obtain actionable insights into the disease and potential therapeutic targets.",AB_0476
"virtual drug screening (vds) tackles the problem of drug discovery by computationally reducing the number of potential pharmacological molecules that need to be tested experimentally to find a new drug. to do so, several approaches have been developed through the years, typically focusing on either the physicochemical characteristics of the receptor structure (structure-based virtual screening) or those of the potential ligands (ligand-based virtual screening). scipion is a workflow engine well suited for structural studies of biological macromolecules. here, we present scipion-chem, a new branch oriented to vds. a total of 11 plugins have already been integrated from the most common programs used in the field. they can be used through the scipion graphical user interface to execute and analyze typical vds tasks. in addition, we have developed several consensus protocols that combine results from the different integrated programs to generate more robust predictions. backstage, scipion also facilitates the interoperability of those different software packages while tracking all of the intermediate files, parameters, and user decisions. in summary, in this article, we present scipion-chem. this accessible, interoperable, and traceable platform provides the user with all of the tools to carry out a successful vds workflow. scipion-chem is openly available at https://github.com/scipion-chem.",AB_0476
"motivation advances in genomics and sequencing technologies demand faster and more scalable analysis methods that can process longer sequences with higher accuracy. however, classical pairwise alignment methods, based on dynamic programming (dp), impose impractical computational requirements to align long and noisy sequences like those produced by pacbio and nanopore technologies. the recently proposed wavefront alignment (wfa) algorithm paves the way for more efficient alignment tools, improving time and memory complexity over previous methods. however, high-performance computing (hpc) platforms require efficient parallel algorithms and tools to exploit the computing resources available on modern accelerator-based architectures.results this paper presents wfa-gpu, a gpu (graphics processing unit)-accelerated tool to compute exact gap-affine alignments based on the wfa algorithm. we present the algorithmic adaptations and performance optimizations that allow exploiting the massively parallel capabilities of modern gpu devices to accelerate the alignment computations. in particular, we propose a cpu-gpu co-design capable of performing inter-sequence and intra-sequence parallel sequence alignment, combining a succinct wfa-data representation with an efficient gpu implementation. as a result, we demonstrate that our implementation outperforms the original multi-threaded wfa implementation by up to 4.3x and up to 18.2x when using heuristic methods on long and noisy sequences. compared to other state-of-the-art tools and libraries, the wfa-gpu is up to 29x faster than other gpu implementations and up to four orders of magnitude faster than other cpu implementations. furthermore, wfa-gpu is the only gpu solution capable of correctly aligning long reads using a commodity gpu.availability and implementation wfa-gpu code and documentation are publicly available at https://github.com/quim0/wfa-gpu.",AB_0476
"background. taxonomic identification through dna barcodes gained considerable traction through the invention of next-generation sequencing and dna metabarcoding. metabarcoding allows for the simultaneous identification of thousands of organisms from bulk samples with high taxonomic resolution. however, reliable identifications can only be achieved with comprehensive and curated reference databases. therefore, custom reference databases are often created to meet the needs of specific research questions. due to taxonomic inconsistencies, formatting issues, and technical difficulties, building a custom reference database requires tremendous effort. here, we present taxalogue, an easy-to-use software for creating comprehensive and customized reference databases that provide clean and taxonomically harmonized records. in combination with extensive geographical filtering options, taxalogue opens up new possibilities for generating and testing evolutionary hypotheses.methods. taxalogue collects dna sequences from several online sources and combines them into a reference database. taxonomic incongruencies between the different data sources can be harmonized according to available taxonomies. dereplication and various filtering options are available regarding sequence quality or metadata information. taxalogue is implemented in the open-source ruby programming language, and the source code is available at https://github.com/nwnoll/taxalogue. we benchmark four reference databases by sequence identity against eight queries from different localities and trapping devices. subsamples from each reference database were used to compare how well another one is covered. results. taxalogue produces reference databases with the best coverage at high identities for most tested queries, enabling more accurate, reliable predictions with higher certainty than the other benchmarked reference databases. additionally, the performance of taxalogue is more consistent while providing good coverage for a variety of habitats, regions, and sampling methods. taxalogue simplifies the creation of reference databases and makes the process reproducible and transparent. multiple available output formats for commonly used downstream applications facilitate the easy adoption of taxalogue in many different software pipelines. the resulting reference databases improve the taxonomic classification accuracy through high coverage of the query sequences at high identities.",AB_0476
"as one of the leading causes for dementia in the population, it is imperative that we discern exactly why alzheimer's disease (ad) has a strong molecular association with beta-amyloid and tau. although a clear understanding about etiology and pathogenesis of ad remains unsolved, scientists worldwide have dedicated significant efforts to discovering the molecular interactions linked to the pathological characteristics and potential treatments. knowledge representations, such as domain ontologies encompassing our current understanding about ad, could greatly assist and contribute to disease research. this paper describes the construction and application of the integrated alzheimer's disease ontology (ado), combining selected concepts from the former version of the ado and the alzheimer's disease mapping ontology (admo). in addition to the existing entities available from these knowledge models, essential knowledge about ad from public sources, such as newly discovered risk factor genes and novel treatments, was also integrated. the ado can also be leveraged in text mining scenarios given that it is conceptually enriched with domain-specific knowledge as well as their relations. the integrated ado consists of 39 855 total axioms. the ontology covers many aspects of the ad domain, including risk factor genes, clinical features, treatments and experimental models. the ontology complies with the open biological and biomedical ontology principles and was accepted by the foundry. in this paper, we illustrate the role of the presented ontology in extracting textual information from the scaiview database and key measures in an ado-based corpus.database url: https://academic.oup.com/database",AB_0476
"the international tables symmetry database (https://symmdb.iucr.org/), which is part of international tables for crystallography, is a collection of individual databases of crystallographic space-group and point-group information with associated programs. the programs let the user access and in some cases interactively visualize the data, and some also allow new data to be calculated 'on the fly'. together these databases and programs expand upon and complement the symmetry information provided in international tables for crystallography volume a, space-group symmetry, and volume a1, symmetry relations between space groups. the symmetry database allows users to learn about and explore the space and point groups, and facilitates the study of group-subgroup relations between space groups, with applications in determining crystal-structure relationships, in studying phase transitions and in domain-structure analysis. the use of the international tables symmetry database in all these areas is demonstrated using several examples.",AB_0476
"background incontinence and sexual dysfunction are long-lasting side effects after surgical treatment (radical prostatectomy, rp) of prostate cancer (pc). for an informed treatment decision, physicians and patients should discuss expected impairments. therefore, this paper firstly aims to develop and validate prognostic models that predict incontinence and sexual function of pc patients one year after rp and secondly to provide an online decision making tool.methods observational cohorts of pc patients treated between july 2016 and march 2021 in germany were used. models to predict functional outcomes one year after rp measured by the epic-26 questionnaire were developed using lasso regression, 80-20 splitting of the data set and 10-fold cross validation. to assess performance, r-2, rmse, analysis of residuals and calibration-in-the-large were applied. final models were externally temporally validated. additionally, percentages of functional impairment (pad use for incontinence and firmness of erection for sexual score) per score decile were calculated to be used together with the prediction models.results for model development and internal as well as external validation, samples of 11 355 and 8 809 patients were analysed. results from the internal validation (incontinence: r-2 = 0.12, rmse = 25.40, sexual function: r-2 = 0.23, rmse = 21.44) were comparable with those of the external validation. residual analysis and calibration-in-the-large showed good results. the prediction tool is freely accessible: https://nora-tabea.shinyapps.io/epic-26-prediction/.conclusion the final models showed appropriate predictive properties and can be used together with the calculated risks for specific functional impairments. main strengths are the large study sample (> 20 000) and the inclusion of an external validation. the models incorporate meaningful and clinically available predictors ensuring an easy implementation. all predictions are displayed together with risks of frequent impairments such as pad use or erectile dysfunction such that the developed online tool provides a detailed and informative overview for clinicians as well as patients.",AB_0476
