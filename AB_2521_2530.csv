AB,NO
"full-reference (fr) point cloud quality assessment (pcqa) has achieved impressive progress in recent years. however, in many cases, obtaining the reference point clouds is difficult, so no-reference (nr) metrics have become a research hotspot. few researches about nr-pcqa are carried out due to the lack of a large-scale pcqa dataset. in this article, we first build a large-scale pcqa dataset named ls-pcqa, which includes 104 reference point clouds and more than 22,000 distorted samples. in the dataset, each reference point cloud is augmented with 31 types of impairments (e.g., gaussian noise, contrast distortion, local missing, and compression loss) at 7 distortion levels. besides, each distorted point cloud is assigned with a pseudo-quality score as its substitute of mean opinion score. inspired by the hierarchical perception system and considering the intrinsic attributes of point clouds, we propose a nr metric resscnn based on sparse convolutional neural network (cnn) to accurately estimate the subjective quality of point clouds. we conduct several experiments to evaluate the performance of the proposed nr metric. the results demonstrate that resscnn exhibits the state-of-the-art performance among all the existing nr-pcqa metrics and even outperforms some fr metrics. the dataset presented in this work will be made publicly accessible at http://smt.sjtu.edu.cn. the source code for the proposed resscnn can be found at https://github.com/lyp22/resscnn.",AB_0253
"most state-of-the-art deep networks proposed for biomedical image segmentation are developed based on u-net. while remarkable success has been achieved, its inherent limitations hinder it from yielding more precise segmentation. first, its receptive field is limited due to the fixed kernel size, which prevents the network from modeling global context information. second, when spatial information captured by shallower layer is directly transmitted to higher layers by skip connections, the process inevitably introduces noise and irrelevant information to feature maps and blurs their semantic meanings. in this article, we propose a novel segmentation network equipped with a new context prior guidance (cpg) module to overcome these limitations for biomedical image segmentation, namely context prior guidance network (cpg-net). specifically, we first extract a set of context priors under the supervision of a coarse segmentation and then employ these context priors to model the global context information and bridge the spatial-semantic gap between high-level features and low-level features. the cpg module contains two major components: context prior representation (cpr) and semantic complement flow (scf). cpr is used to extract pixels belonging to the same objects and hence produce more discriminative features to distinguish different objects. we further introduce deep semantic information for each cpr by the scf mechanism to compensate the semantic information diluted during the decoding. we extensively evaluate the proposed cpg-net on three famous biomedical image segmentation tasks with diverse imaging modalities and semantic environments. experimental results demonstrate the effectiveness of our network, consistently outperforming state-of-the-art segmentation networks in all the three tasks. codes are available at https://github.com/zzw- szu/cpgnet.",AB_0253
"mirrors are everywhere in our daily lives. existing computer vision systems do not consider mirrors, and hence may get confused by the reflected content inside a mirror, resulting in a severe performance degradation. however, separating the real content outside a mirror from the reflected content inside it is non-trivial. the key challenge is that mirrors typically reflect contents similar to their surroundings, making it very difficult to differentiate the two. in this article, we present a novel method to segment mirrors from a single rgb image. to the best of our knowledge, this is the first work to address the mirror segmentation problem with a computational approach. we make the following contributions: first, we propose a novel network, called mirrornet+, for mirror segmentation, by modeling both contextual contrasts and semantic associations. second, we construct the first large-scale mirror segmentation dataset, which consists of 4,018 pairs of images containing mirrors and their corresponding manually annotated mirror masks, covering a variety of daily-life scenes. third, we conduct extensive experiments to evaluate the proposed method and show that it outperforms the related state-of-the-art detection and segmentation methods. fourth, we further validate the effectiveness and generalization capability of the proposed semantic awareness contextual contrasted feature learning by applying mirrornet+ to other vision tasks, i.e., salient object detection and shadow detection. finally, we provide some applications of mirror segmentation and analyze possible future research directions. project homepage: https://mhaiyang.github.io/tomm2022-mirrornet+/index.html.",AB_0253
"we propose parametric gauss reconstruction (pgr) for surface reconstruction from point clouds without normals. our insight builds on the gauss formula in potential theory, which represents the indicator function of a region as an integral over its boundary. by viewing surface normals and surface element areas as unknown parameters, the gauss formula interprets the indicator as a member of some parametric function space. we can solve for the unknown parameters using the gauss formula and simultaneously obtain the indicator function. our method bypasses the need for accurate input normals as required by most existing non-data-driven methods, while also exhibiting superiority over data-driven methods, since no training is needed. moreover, by modifying the gauss formula and employing regularization, pgr also adapts to difficult cases such as noisy inputs, thin structures, sparse or nonuniform points, for which accurate normal estimation becomes quite difficult. our code is publicly available at https://github.com/jsnln/parametricgaussrecon.",AB_0253
"segmenting the fine structure of the mouse brain on magnetic resonance (mr) images is critical for delineating morphological regions, analyzing brain function, and understanding their relationships. compared to a single mri modality, multimodal mri data provide complementary tissue features that can be exploited by deep learning models, resulting in better segmentation results. however, multimodal mouse brain mri data is often lacking, making automatic segmentation of mouse brain fine structure a very challenging task. to address this issue, it is necessary to fuse multimodal mri data to produce distinguished contrasts in different brain structures. hence, we propose a novel disentangled and contrastive gan-based framework, named mousegan++, to synthesize multiple mr modalities from single ones in a structure-preserving manner, thus improving the segmentation performance by imputing missing modalities and multi-modality fusion. our results demonstrate that the translation performance of our method outperforms the state-of-the-art methods. using the subsequently learned modality-invariant information as well as the modality-translated images, mousegan++ can segment fine brain structures with averaged dice coefficients of 90.0% (t2w) and 87.9% (t1w), respectively, achieving around +10% performance improvement compared to the state-of-the-art algorithms. our results demonstrate that mousegan++, as a simultaneous image synthesis and segmentation method, can be used to fuse cross-modality information in an unpaired manner and yield more robust performance in the absence of multimodal data. we release our method as a mouse brain structural segmentation tool for free academic usage at https://github.com/yu02019.",AB_0253
"face image manipulation via three-dimensional guidance has been widely applied in various interactive scenarios due to its semantically-meaningful understanding and user-friendly controllability. however, existing 3d-morphable-model-based manipulation methods are not directly applicable to out-of-domain faces, such as non-photorealistic paintings, cartoon portraits, or even animals, mainly due to the formidable difficulties in building the model for each specific face domain. to overcome this challenge, we propose, as far as we know, the first method to manipulate faces in arbitrary domains using human 3dmm. this is achieved through two major steps: 1) disentangled mapping from 3dmm parameters to the latent space embedding of a pre-trained stylegan2 [1] that guarantees disentangled and precise controls for each semantic attribute; and 2) cross-domain adaptation that bridges domain discrepancies and makes human 3dmm applicable to out-of-domain faces by enforcing a consistent latent space embedding. experiments and comparisons demonstrate the superiority of our high-quality semantic manipulation method on a variety of face domains with all major 3d facial attributes controllable - pose, expression, shape, albedo, and illumination. moreover, we develop an intuitive editing interface to support user-friendly control and instant feedback. our project page is https://cassiepython.github.io/cddfm3d/index.html.",AB_0253
"sepsis usually leads to lethal multiorgan dysfunction including acute liver failure (alf) and acute lung injury (ali). this research sought to reveal the lipid alteration of anti-high mobility group box 1 (hmgb1) treatment in sepsis-induced alf and ali by lipidomics. the cecal ligation and puncture-induced mouse model was established and the anti-hmgb1 neutralizing antibody was administrated. the histopathological characteristics and inflammatory factors were determined to assess the efficacy of the antibody. utraperformance liquid chromatography coupled with quadrupole time-of-flight mass spectrometry was used to determine lipid metabolism profiles in the liver and lung. the underlying biomarkers were identified through multivariate statistical analysis and correlation analysis with traditional physiological indicators. the pathological and biochemical results demonstrated that anti-hmgb1 neutralizing antibodies mitigated alf and ali in mice. three differential metabolites in the liver and six various metabolites in the lung were significantly reversed by anti-hmgb1 treatment, mainly involved in arachidonic acid metabolism, glycerophospholipid metabolism, and sphingolipid metabolism. additionally, we investigated several traditional signaling pathways associated with hmgb1. however, the correlation between these traditional pathways and anti-hmgb1 intervention was not significant in the current study. in conclusion, our finding provided some scientific basis for targeting hmgb1 in sepsis-induced liver and lung injury. mass spectrometry data with identifier no. mtbls6466 have been uploaded to metabolights (http://www.ebi.ac.uk/metabolights/login).",AB_0253
"sensitive detection of mycobacterium tuberculosis (tb) in small percentages in metagenomic samples is essential for microbial classification and drug resistance prediction. however, traditional methods, such as bacterial culture and microscopy, are time-consuming and sometimes have limited tb detection sensitivity. oxford nanopore technologies (ont) minion sequencing allows rapid and simple sample preparation for sequencing. its recently developed adaptive sequencing selects reads from targets while allowing real-time base-calling to achieve sequence enrichment or depletion during sequencing. another common enrichment method is pcr amplification of the target tb genes. in this study, we compared both methods using ont minion sequencing for tb detection and variant calling in metagenomic samples using both simulation runs and those with synthetic and patient samples. we found that both methods effectively enrich tb reads from a high percentage of human (95%) and other microbial dna. adaptive sequencing with readfish and uncallde achieved a 3.9-fold and 2.2-fold enrichment compared to the control run. we provide a simple automatic analysis framework to support the detection of tb for clinical use, openly available at https://github.com/hku-bal/ont-tb-nf. depending on the patient's medical condition and sample type, we recommend users evaluate and optimize their workflow for different clinical specimens to improve the detection limit.",AB_0253
"single-cell crispr screens have been widely used to investigate gene regulatory circuits in diverse biological systems. the recent development of single-cell crispr screens has enabled multimodal profiling of perturbed cells with both gene expression, chromatin accessibility and protein levels. however, current methods cannot meet the analysis requirements of different types of data and have limited functions. here, we introduce single-cell crispr screens data analyses and perturbation modeling (scree) as a comprehensive and flexible pipeline to facilitate the analyses of various types of single-cell crispr screens data. scree performs read alignment, sgrna assignment, quality control, clustering and visualization, perturbation enrichment evaluation, perturbation efficiency modeling, gene regulatory score calculation and functional analyses of perturbations for single-cell crispr screens with both rna, atac and multimodal readout. scree is available at https://github.com/wanglabtongji/scree.",AB_0253
"background: genomic structural variant detection is a significant and challenging issue in genome analysis. the existing long-read based structural variant detection methods still have space for improvement in detecting multi-type structural variants. results: in this paper, we propose a method called cnnlsv to obtain detection results with higher quality by eliminating false positives in the detection results merged from the callsets of existing methods. we design an encoding strategy for four types of structural variants to represent long-read alignment information around structural variants into images, input the images into a constructed convolutional neural network to train a filter model, and load the trained model to remove the false positives to improve the detection performance. we also eliminate mislabeled training samples in the training model phase by using principal component analysis algorithm and unsupervised clustering algorithm k-means. experimental results on both simulated and real datasets show that our proposed method outperforms existing methods overall in detecting insertions, deletions, inversions, and duplications. the program of cnnlsv is available at https://github.com/mhuidong/cnnlsv. conclusions: the proposed cnnlsv can detect structural variants by using long-read alignment information and convolutional neural network to achieve overall higher performance, and effectively eliminate incorrectly labeled samples by using the principal component analysis and k-means algorithms in training model stage.",AB_0253
