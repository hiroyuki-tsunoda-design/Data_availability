AB,NO
"text-guided image retrieval integrates reference image and text feedback as a multimodal query to search the image corresponding to user intention. recent approaches employ multi-level matching, multiple accesses, or multiple subnetworks for better performance regardless of the heavy burden of storage and computation in the deployment. additionally, these models not only rely on expert knowledge to handcraft image-text composing modules but also do inference by the static computational graph. it limits the representation capability and generalization ability of networks in the face of challenges from complex and varied combinations of reference image and text feedback. to break the shackles of the static network concept, we introduce the dynamic router mechanism to achieve data-dependent expert activation and flexible collaboration of multiple experts to explore more implicit multimodal fusion patterns. specifically, we construct amc, our adaptive multi-expert collaborative network, by using the proposed router to activate the different experts with different levels of image-text interaction. since routers can dynamically adjust the activation of experts for the current samples, amc can achieve the adaptive fusion mode for the different reference image and text combinations and generate dynamic computational graphs according to varied multimodal queries. extensive experiments on two benchmark datasets demonstrate that due to benefits from the image-text composing representation produced by an adaptive multi-expert collaboration mechanism, amc has better retrieval performance and zero-shot generalization ability than the state-of-the-art method while keeping the lightweight model and fast retrieval speed. moreover, we analyze the visualization of path activation, attention map, and retrieval results to further understand the routing decisions and semantic localization ability of amc. the codes and pretrained models are available at https://github.com/kevinlight831/amc.",AB_0219
"cross-modality magnetic resonance (mr) image synthesis can be used to generate missing modalities from given ones. existing (supervised learning) methods often require a large number of paired multi-modal data to train an effective synthesis model. however, it is often challenging to obtain sufficient paired data for supervised training. in reality, we often have a small number of paired data while a large number of unpaired data. to take advantage of both paired and unpaired data, in this paper, we propose a multi-scale transformer network (mt-net) with edge-aware pre-training for cross-modality mr image synthesis. specifically, an edge-preserving masked autoencoder (edge-mae) is first pre-trained in a self-supervised manner to simultaneously perform 1) image imputation for randomly masked patches in each image and 2) whole edge map estimation, which effectively learns both contextual and structural information. besides, a novel patch-wise loss is proposed to enhance the performance of edge-mae by treating different masked patches differently according to the difficulties of their respective imputations. based on this proposed pre-training, in the subsequent fine-tuning stage, a dual-scale selective fusion (dsf) module is designed (in our mt-net) to synthesize missing-modality images by integrating multi-scale features extracted from the encoder of the pre-trained edge-mae. furthermore, this pre-trained encoder is also employed to extract high-level features from the synthesized image and corresponding ground-truth image, which are required to be similar (consistent) in the training. experimental results show that our mt-net achieves comparable performance to the competing methods even using 70% of all available paired data. our code will be released at https://github.com/lyhkevin/mt-net.",AB_0219
"the high-quality pathological microscopic images are essential for physicians or pathologists to make a correct diagnosis. image quality assessment (iqa) can quantify the visual distortion degree of images and guide the imaging system to improve image quality, thus raising the quality of pathological microscopic images. current iqa methods are not ideal for pathological microscopy images due to their specificity. in this paper, we present deep learning-based blind image quality assessment model with saliency block and patch block for pathological microscopic images. the saliency block and patch block can handle the local and global distortions, respectively. to better capture the area of interest of pathologists when viewing pathological images, the saliency block is fine-tuned by eye movement data of pathologists. the patch block can capture lots of global information strongly related to image quality via the interaction between different image patches from different positions. the performance of the developed model is validated by the home-made pathological microscopic image quality database under screen and immersion scenarios (pmiqd-sis) and cross-validated by the five public datasets. the results of ablation experiments demonstrate the contribution of the added blocks. the dataset and the corresponding code are publicly available at: https://github.com/mikugyf/pmiqd-sis.",AB_0219
"generative adversarial networks (gans) have been widely applied in different scenarios thanks to the development of deep neural networks. the original gan was proposed based on the non-parametric assumption of the infinite capacity of networks. however, it is still unknown whether gans can fit the target distribution without any prior information. due to the overconfident assumption, many issues remain unaddressed in gans training, such as non-convergence, mode collapses, and gradient vanishing. regularization and normalization are common methods of introducing prior information to stabilize training and improve discrimination. although a handful number of regularization and normalization methods have been proposed for gans, to the best of our knowledge, there exists no comprehensive survey that primarily focuses on objectives and development of these methods, apart from some incomprehensive and limited-scope studies. in this work, we conduct a comprehensive survey on the regularization and normalization techniques from different perspectives of gans training. first, we systematically describe different perspectives of gans training and thus obtain the different objectives of regularization and normalization. based on these objectives, we propose a new taxonomy. furthermore, we compare the performance of the mainstream methods on different datasets and investigate the applications of regularization and normalization techniques that have been frequently employed in state-of-the-art gans. finally, we highlight potential future directions of research in this domain. code and studies related to the regularization and normalization of gans in this work are summarized at https://github.com/iceli1007/gans-regularization-review.",AB_0219
"artificial intelligence (ai) approaches nowadays have gained remarkable success in single-modality-dominated remote sensing (rs) applications, especially with an emphasis on individual urban environments (e.g., single cities or regions). yet these ai models tend to meet the performance bottleneck in the case studies across cities or regions, due to the lack of diverse rs information and cutting-edge solutions with high generalization ability. to this end, we build a new set of multimodal remote sensing benchmark datasets (including hyperspectral, mul-tispectral, sar) for the study purpose of the cross-city semantic segmentation task (called c2seg dataset), which consists of two cross-city scenes, i.e., berlin-augsburg (in germany) and beijing-wuhan (in china). beyond the single city, we propose a high-resolution domain adaptation network, highdan for short, to promote the ai model's generalization ability from the multi-city environments. highdan is capable of retaining the spatially topological structure of the studied urban scene well in a parallel high-to-low resolution fusion fashion but also closing the gap derived from enormous differences of rs image representations between different cities by means of adversarial learning. in addition, the dice loss is considered in highdan to alleviate the class imbalance issue caused by factors across cities. extensive experiments conducted on the c2seg dataset show the superiority of our highdan in terms of segmentation performance and generalization ability, compared to state-of-the-art com-petitors. the c2seg dataset and the semantic segmentation toolbox (involving the proposed highdan) will be available publicly at https://github.com/danfenghong/rse_cross-city.",AB_0219
"aiming at enhancing the rationality and robustness of the results of single-view image-based human reconstruction and acquiring richer surface details, we propose a multi-level reconstruction framework based on implicit functions. this framework first utilizes the predicted smpl model (skinned multi-person linear model) as a prior to further predict consistent 2.5d sketches (depth map and normal map), and then obtains a coarse reconstruction result through an implicit function fitting network (if-net). subsequently, with a pixel-aligned feature extraction module and a fine if-net, the strong constraints imposed by smpl are relaxed to add more surface details to the reconstruction result and remove noise. finally, to address the trade-off between surface details and rationality under complex poses, we propose a novel fusion repair algorithm that reuses existing information. this algorithm compensates for the missing parts of the fine reconstruction results with the coarse reconstruction results, leading to a robust, rational, and richly detailed reconstruction. the final experiments prove the effectiveness of our method and demonstrate that it achieves the richest surface details while ensuring rationality. the project website can be found at https://github.com/mxkkk/2.5d-mlif.",AB_0219
"background prokinetic agents are currently considered the first-line therapy to improve gastric emptying when feeding intolerance occurred in critically ill adults. in this study, we developed a technique to assess the feasibility of predicting prokinetic agent efficacy in critically ill patients. methods the first images of each patient were obtained after efi had occurred but before the first dose of prokinetic agents was administered and additional images were obtained every morning until the seventh day. the gastric antrum echodensity was recorded based on grayscale values (50th percentile, ed50; 85th percentile, ed85; mean, edmean) and daily energy and protein intake was collected as the judgment for effective and ineffective group. a receiver operating characteristic curve was analyzed to distinguish the thresholds between the two groups and thus determine the ability of the gastric antrum echodensity to predict the efficacy of prokinetic agents. results in total, 83 patients were analyzed. patients in the ineffective group had a higher ed50 (58.13 +/- 14.48 vs. 49.88 +/- 13.78, p < 0.001, difference 95% ci: 5.68, 10.82), ed85 (74.81 +/- 16.41 vs. 65.70 +/- 16.05, p < 0.001, difference 95% ci:6.16, 12.05), and edmean (60.18 +/- 14.31 vs. 51.76 +/- 14.08, p < 0.001, difference 95% ci: 5.85, 11.00) than those in the effective group. patients in the effective group more easily reached the target energy 16.21 +/- 7.98 kcal/kg vs. 9.17 +/- 6.43 kcal/kg (p < 0.001), 0.72 +/- 0.38 g/kg vs. 0.42 +/- 0.31 g/kg (p < 0.001) than in the ineffective group intake by day. conclusion the gastric antrum echodensity might serve as a tool for judging the efficacy of prokinetic agents, helping clinicians to decide whether to use prokinetic agents or place a post-pyloric tube when feeding intolerance occurs in critically ill patients. clinical trial registration:http://www.chictr.org.cn/addproject2.aspx, chictr2200058373. registered 7 april 2022.",AB_0219
"various diseases, including huntington's disease, alzheimer's disease, and parkinson's disease, have been reported to be linked to amyloid. therefore, it is crucial to distinguish amyloid from non-amyloid proteins or peptides. while experimental approaches are typically preferred, they are costly and time-consuming. in this study, we have developed a machine learning framework called iamy-recmff to discriminate amyloidgenic from non-amyloidgenic peptides. in our model, we first encoded the peptide sequences using the residue pairwise energy content matrix. we then utilized pearson's correlation coefficient and distance correlation to extract useful information from this matrix. additionally, we employed an improved similarity network fusion algorithm to integrate features from different perspectives. the fisher approach was adopted to select the optimal feature subset. finally, the selected features were inputted into a support vector machine for identifying amyloidgenic peptides. experimental results demonstrate that our proposed method significantly improves the identification of amyloidgenic peptides compared to existing predictors. this suggests that our method may serve as a powerful tool in identifying amyloidgenic peptides. to facilitate academic use, the dataset and codes used in the current study are accessible at https://figshare.com/articles/online_resource/iamy-recmff/22816916.",AB_0219
"prostate cancer (pca) patients with lymph node involvement (lni) constitute a single-risk group with varied prognoses. existing studies on this group have focused solely on those who underwent prostatectomy (rp), using statistical models to predict prognosis. this study aimed to develop an easily accessible individual survival prediction tool based on multiple machine learning (ml) algorithms to predict survival probability for pca patients with lni. a total of 3280 pca patients with lni were identified from the surveillance, epidemiology, and end results (seer) database, covering the years 2000-2019. the primary endpoint was overall survival (os). gradient boosting survival analysis (gbsa), random survival forest (rsf), and extra survival trees (est) were used to develop prognosis models, which were compared to cox regression. discrimination was evaluated using the time-dependent areas under the receiver operating characteristic curve (time-dependent auc) and the concordance index (c-index). calibration was assessed using the time-dependent brier score (time-dependent bs) and the integrated brier score (ibs). moreover, the beeswarm summary plot in shap (shapley additive explanations) was used to display the contribution of variables to the results. the 3280 patients were randomly split into a training cohort (n = 2624) and a validation cohort (n = 656). nine variables including age at diagnosis, race, marital status, clinical t stage, prostate-specific antigen (psa) level at diagnosis, gleason score (gs), number of positive lymph nodes, radical prostatectomy (rp), and radiotherapy (rt) were used to develop models. the mean time-dependent auc for gbsa, rsf, and est was 0.782 (95% confidence interval [ci] 0.779-0.783), 0.779 (95% ci 0.776-0.780), and 0.781 (95% ci 0.778-0.782), respectively, which were higher than the cox regression model of 0.770 (95% ci 0.769-0.773). additionally, all models demonstrated almost similar calibration, with low ibs. a web-based prediction tool was developed using the best-performing gbsa, which is accessible at https://pengzihexjtu-pca-n1.streamlit.app/. ml algorithms showed better performance compared with cox regression and we developed a web-based tool, which may help to guide patient treatment and follow-up.",AB_0219
"motivation gene name normalization is an important yet highly complex task in biomedical text mining research, as gene names can be highly ambiguous and may refer to different genes in different species or share similar names with other bioconcepts. this poses a challenge for accurately identifying and linking gene mentions to their corresponding entries in databases such as ncbi gene or uniprot. while there has been a body of literature on the gene normalization task, few have addressed all of these challenges or make their solutions publicly available to the scientific community.results building on the success of gnormplus, we have created gnorm2: a more advanced tool with optimized functions and improved performance. gnorm2 integrates a range of advanced deep learning-based methods, resulting in the highest levels of accuracy and efficiency for gene recognition and normalization to date. our tool is freely available for download.availability and implementation https://github.com/ncbi/gnorm2.",AB_0219
