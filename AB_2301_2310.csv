AB,NO
"a bottom-up and top-down attention mechanism has led to the revolutionizing of image captioning techniques, which enables object-level attention for multi-step reasoning over all the detected objects. however, when humans describe an image, they often apply their own subjective experience to focus on only a few salient objects that areworthy of mention, rather than all objects in this image. the focused objects are further allocated in linguistic order, yielding the object sequence of interest to compose an enriched description. in this work, we present the bottom-up and top-down object inference network (bto-net), which novelly exploits the object sequence of interest as top-down signals to guide image captioning. technically, conditioned on the bottom-up signals (all detected objects), an lstm-based object inference module is first learned to produce the object sequence of interest, which acts as the top-down prior to mimic the subjective experience of humans. next, both of the bottom-up and top-down signals are dynamically integrated via an attention mechanism for sentence generation. furthermore, to prevent the cacophony of intermixed cross-modal signals, a contrastive learning-based objective is involved to restrict the interaction between bottom-up and top-down signals, and thus leads to reliable and explainable cross-modal reasoning. our bto-net obtains competitive performances on the coco benchmark, in particular, 134.1% cider on the coco karpathy test split. source code is available at https://github.com/yehli/bto-net.",AB_0231
"the 2d virtual try-on task aims to transfer a target clothing image to the corresponding region of a person image. although an extensive amount of research has been conducted due to its immense applications, this task still remains a great challenge to handle some complicated issues (e.g., non-rigid shapes, large occlusions and arbitrary poses). to this end, we propose a novel network with structural and textural consistency-preserving mechanism for producing high-fidelity try-on images. specifically, we first generate the semantic layout of a clothing-agnostic person to obtain the segmentation map, which is used as the transforming conditions of the target clothes. based on a recurrent network structure, the transform lookup is performed to iteratively update a dense flow. then, we adopt a thin-plate-spline-based warping method to estimate the coarse offset flow for all key-point positions. guided by this sparse flow, a multi-scale deformable convolution module is designed to further iteratively predict the fine offsets for densely sampled positions, by which the clothing item and person shape can be accurately aligned. finally, we develop a refinement module to effectively fuse the global and local features, which can render accurate geometric structures of the body parts and maintain texture sharpness of the clothes. extensive experiments on benchmark datasets demonstrate that our method outperforms other state-of-the-art methods in terms of quantitative and qualitative try-on results. the code is available on: https://github.com/tju- weihao/mlcn.",AB_0231
"generative adversarial networks (gans) have the ability to generate images that are visually indistinguishable from real images. however, recent studies have revealed that generated and real images share significant differences in the frequency domain. in this article, we argue that the frequency gap is caused by the high-frequency sensitivity of the discriminator. according to our observation, during the training of most gans, severe high-frequency differences make the discriminator focus on high-frequency components excessively, which hinders the generator from fitting the low-frequency components that are important for learning images' content. then, we propose two simple yet effective image pre-processing operations in the frequency domain for eliminating the side effects caused by high-frequency differences in gans training: high-frequency confusion (hfc) and high-frequency filter (hff). the proposed operations are general and can be applied to most existing gans at a fraction of the cost. the advanced performance of the proposed operations is verified on multiple loss functions, network architectures, and datasets. specifically, the proposed hff achieves significant improvements of 42.5% fid on celeba (128*128) unconditional generation based on sngan, 30.2% fid on celeba unconditional generation based on ssgan, and 69.3% fid on celeba unconditional generation based on infomaxgan. furthermore, we also adopt hff as the first attempt at data augmentation in the frequency domain for contrastive learning, achieving state-of-the-art performance on unconditional generation. code is available at https://github.com/iceli1007/hfc-and-hff.",AB_0231
"automatic and accurate classification of retinal optical coherence tomography (oct) images is essential to assist physicians in diagnosing and grading pathological changes in pathologic myopia (pm). clinically, due to the obvious differences in the position, shape, and size of the lesion structure in different scanning directions, ophthalmologists usually need to combine the lesion structure in the oct images in the horizontal and vertical scanning directions to diagnose the type of pathological changes in pm. to address these challenges, we propose a novel feature interaction transformer network (fit-net) to diagnose pm using oct images, which consists of two dual-scale transformer (dst) blocks and an interactive attention (ia) unit. specifically, fit-net divides image features of different scales into a series of feature block sequences. in order to enrich the feature representation, we propose an ia unit to realize the interactive learning of class token in feature sequences of different scales. the interaction between feature sequences of different scales can effectively integrate different scale image features, and hence fit-net can focus on meaningful lesion regions to improve the pm classification performance. finally, by fusing the dual-view image features in the horizontal and vertical scanning directions, we propose six dual-view feature fusion methods for pm diagnosis. the extensive experimental results based on the clinically obtained datasets and three publicly available datasets demonstrate the effectiveness and superiority of the proposed method. our code is avaiable at: https://github.com/chenshaobin/fitnet.",AB_0231
"in clinical practice, it is desirable for medical image segmentation models to be able to continually learn on a sequential data stream from multiple sites, rather than a consolidated dataset, due to storage cost and privacy restrictions. however, when learning on a new site, existing methods struggle with a weak memorizability for previous sites with complex shape and semantic information, and a poor explainability for the memory consolidation process. in this work, we propose a novel shape and semantics-based selective regularization ((sr)-r-3) method for explainable cross-site continual segmentation to maintain both shape and semantic knowledge of previously learned sites. specifically, (sr)-r-3 method adopts a selective regularization scheme to penalize changes of parameters with high joint shape and semantics-based importance (jssi) weights, which are estimated based on the parameter sensitivity to shape properties and reliable semantics of the segmentation object. this helps to prevent the related shape and semantic knowledge from being forgotten. moreover, we propose an importance activation mapping (iam) method for memory interpretation, which indicates the spatial support for important parameters to visualize the memorized content. we have extensively evaluated our method on prostate segmentation and optic cup and disc segmentation tasks. our method outperforms other comparison methods in reducing model forgetting and increasing explainability. our code is available at https://github.com/jingyzhang/s3r.",AB_0231
"deep learning is frequently recommended for standard defect detection because of its ace accuracy and robustness. unfortunately, current deep learning methods exist several challenges in detecting printed surface defects with multi-scale textures. firstly, the existing methods only highlight the texture of defects, but concealed the color information of defects. secondly, since the subtle defects of printed contained with weak semantic, it is difficult for current multi-scale network to locate the defects. finally, current metric methods cannot measure the similarity between each of defect under class-imbalanced precisely. therefore, bi-deformation-unet (bi-dunet) is designed for automatic printed surface defect detection. in bi-dunet, the template-defect image pairs are first enhanced by our proposed pre-processing module recombination of the differential channels. this module can highlight the texture and maintain the color information simultaneously. then, the preprocessed image pairs are fed into the dual-fusion module (dm) and generated the output features with edge information and contextual information. the dm consists of two branches: the template branch and the defect branch. the two branches are identical in structure and multi-channel edge attention module. besides, an automatic dual-margin metric loss is proposed to alleviate the situation of class-imbalance when measuring similarity of output features. moreover, a 2020 assembly line defective product dataset (aldp2020) is proposed, which contains 4000 images with different environment styles. finally, our proposed bi-dunet achieves 3.97% higher than the state-of-the-arts in aldp2020 in map50. the code is available at https://github.com/mrziyang/defectdetection.git.",AB_0231
"in recent years, clustering methods based on deep generative models have received great attention in various unsupervised applications, due to their capabilities for learning promising latent embeddings from original data. this article proposes a novel clustering method based on variational autoencoder (vae) with spherical latent embeddings. the merits of our clustering method can be summarized as follows. first, instead of considering the gaussian mixture model (gmm) as the prior over latent space as in a variety of existing vae-based deep clustering methods, the von mises-fisher mixture model prior is deployed in our method, leading to spherical latent embeddings that can explicitly control the balance between the capacity of decoder and the utilization of latent embedding in a principled way. second, a dual vae structure is leveraged to impose the reconstruction constraint for the latent embedding and its corresponding noise counterpart, which embeds the input data into a hyperspherical latent space for clustering. third, an augmented loss function is proposed to enhance the robustness of our model, which results in a self-supervised manner through the mutual guidance between the original data and the augmented ones. the effectiveness of the proposed deep generative clustering method is validated through comparisons with state-of-the-art deep clustering methods on benchmark datasets. the source code of the proposed model is available at https://github.com/fwt-team/dsvae.",AB_0231
"the minority people panmicrobial community database (mppcd website: http://mppmcdb.cloudna.cn/) is the first microbe-disease association database of chinese ethnic minorities. to research the relationships between intestinal microbes and diseases/health in the ethnic minorities, we collected the microbes of the han people for comparison. based on the data, such as age, among the different ethnic groups of the different regions of sichuan province, mppcd not only provided the gut microbial composition but also presented the relative abundance value at the phylum, class, order, family and genus levels in different groups. in addition, differential analysis was performed in different microbes in the two different groups, which contributed to exploring the difference in intestinal microbe structures between the two groups. meanwhile, a series of related factors, including age, sex, body mass index, ethnicity, physical condition, and living altitude, were included in the mppcd, with special focus on living altitude. to date, this is the first intestinal microbe database to introduce altitude features. in conclusion, we hope that mppcd will serve as a fundamental research support for the relationship between human gut microbes and host health and disease, especially in ethnic minorities.",AB_0231
"protein function prediction based on amino acid sequence alone is an extremely challenging but important task, especially in metagenomics/metatranscriptomics field, in which novel proteins have been uncovered exponentially from new microorganisms. many of them are extremely low homology to known proteins and cannot be annotated with homology-based or information integrative methods. to overcome this problem, we proposed a homology independent protein function annotation method (hifun) based on a unified deep-learning model by reassembling the sequence as protein language. the robustness of hifun was evaluated using the benchmark datasets and metrics in the cafa3 challenge. to navigate the utility of hifun, we annotated 2 212 663 unknown proteins and discovered novel motifs in the uhgp-50 catalog. we proved that hifun can extract latent function related structure features which empowers it ability to achieve function annotation for non-homology proteins. hifun can substantially improve newly proteins annotation and expand our understanding of microorganisms' adaptation in various ecological niches. moreover, we provided a free and accessible webservice at http://www.unimd.org/hifun, requiring only protein sequences as input, offering researchers an efficient and practical platform for predicting protein functions.",AB_0231
"mass spectrometry (ms)-based proteomics has become the most powerful approach to study the proteome of given biological and clinical samples. advancements in sample preparation and ms detection have extended the application of proteomics but have also brought new demands on data analysis. appropriate proteomics data analysis workflow mainly requires quality control, hypothesis testing, functional mining, and visualization. although there are numerous tools for each process, an efficient and universal tandem analysis toolkit to obtain a quick overall view of various proteomics data is still urgently needed. here, we present dep2, an updated version of dep we previously established, for proteomics data analysis. we amended the analysis workflow by incorporating alternative approaches to accommodate diverse proteomics data, introducing peptide-protein summarization and coupling biological function exploration. in summary, dep2 is a well-rounded toolkit designed for protein- and peptide-level quantitative proteomics data. it features a more flexible differential analysis workflow and includes a userfriendly shiny application to facilitate data analysis. availability and implementation: dep2 is available at https://github.com/mildpiggy/dep2, released under the mit license. for further information and usage details, please refer to the package website at https://mildpiggy.github.io/dep2/.",AB_0231
