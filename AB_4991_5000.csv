AB,NO
"research highlight: wu, d., xu, c., wang, s., zhang, l., & kortsch, s. (2022). why are biodiversity- ecosystem functioning relationships so elusive? trophic interactions may amplify ecosystem function variability. journal of animal ecology, https://doi. org/10.1111/1365-2656.13808. there is consensus that average trends of ecosystem functions increase with species diversity. however, large variations in ecosystem function (vef) in systems with similar diversity levels are commonly observed, yet not understood. in this study, wu et al. (2022) integrate empirical aquatic food webs with a multitrophic model to show that vef generally shows a hump-shaped pattern along the species richness gradient. this pattern is related to changes in taxa composition across trophic levels- the proportion of consumer species relative to basal species- along the gradient of species richness. thus, vef dependence on species diversity is driven by both bottom up and top down control that regulate taxa composition and taxa dominance. these results are corroborated with an independent food web data set from the gulf of riga. an important implication of this study is that biodiversity loss may not only reduce the mean levels of ecosystem functioning, but also increase unpredictability of functions by generating greater function variability.",AB_0500
"research highlight: ogilvie, j. e., & caradonna, p. j. (2022). the shifting importance of abiotic and biotic factors across the life cycles of wild pollinators. journal of animal ecology, 91, 2412-2423. https://doi.org/10.1111/1365-2656.13825. as global change and its multiple impacts continue to unfold across most of the planet, understanding how populations of wild species respond to changing conditions has become a major focus of ecological studies. ogilvie and caradonna (ogilvie & caradonna, 2022) focus on understanding how biotic and abiotic conditions affect bumblebee abundances. a major advance in their work is that, rather than focusing on a single measure of abundance at a particular life stage for each of the seven bumblebee species they survey (e.g. adult abundance), they focus on understanding the drivers of population abundance across the different stages of the species' life cycles. the authors specifically assess how three factors in particular, climate conditions, floral resource availability and previous life -stage abundances impact these abundances. a main finding in their study is that each of these three factors directly impacted a different life stage, showing that just focusing on a single life -stage would have resulted on a biased and incomplete picture of how abiotic and biotic factors affect bumblebee population dynamics. studies like this one emphasize the need to focus on understanding the demographic mechanisms that determine population abundances.",AB_0500
"audio-visual navigation combines sight and hearing to navigate to a sound-emitting source in an unmapped environment. while recent approaches have demonstrated the benefits of audio input to detect and find the goal, they focus on clean and static sound sources and struggle to generalize to unheard sounds. in this work, we propose the novel dynamic audio-visual navigation benchmark which requires catching a moving sound source in an environment with noisy and distracting sounds, posing a range of new challenges. we introduce a reinforcement learning approach that learns a robust navigation policy for these complex settings. to achieve this, we propose an architecture that fuses audio-visual information in the spatial feature space to learn correlations of geometric information inherent in both local maps and audio signals. we demonstrate that our approach consistently outperforms the current state-of-the-art by a large margin across all tasks of moving sounds, unheard sounds, and noisy environments, on two challenging 3d scanned real-world environments, namely matterport3d and replica. the benchmark is available at http://dav-nav.cs.uni-freiburg.de.",AB_0500
"objective diagnosis of traumatic axonal injury (tai) is challenging because of its underestimation by conventional mri and the technical requirements associated with the processing of diffusion tensor imaging (dti). serum biomark-ers seem to be able to identify patients with abnormal ct scanning findings, but their potential role to assess tai has seldomly been explored.methods patients with all severities of traumatic brain injury (tbi) were prospectively included in this study between 2016 and 2021. they underwent blood extraction within 24 hours after injury and imaging assessment, including dti. serum concentrations of glial fibrillary acidic protein, total microtubule-associated protein (t-tau), ubiquitin c-terminal hydrolase l1 (uch-l1), and neurofilament light chain (nfl) were measured using an ultrasensitive simoa multiplex assay panel, a digital form of enzyme-linked immunosorbent assay. the glasgow outcome scale-extended score was determined at 6 months after tbi. the relationships between biomarker concentrations, volumetric analysis of corpus callosum (cc) lesions, and fractional anisotropy (fa) were analyzed by nonparametric tests. the prognostic utility of the biomarker was determined by calculating the c-statistic and an ordinal regression analysis.results a total of 87 patients were included. concentrations of all biomarkers were significantly higher for patients compared with controls. although the concentration of the biomarkers was affected by the presence of mass lesions, fa of the cc was an independent factor influencing levels of uch-l1 and nfl, which positioned these two biomarkers as better surrogates of tai. biomarkers also performed well in determining patients who would have had unfavorable outcome. nfl and the fa of the cc are independent complementary factors related to outcome.conclusions uch-l1 and nfl seem to be the biomarkers more specific to detect tai. the concentration of nfl combined with the fa of the cc might help predict long-term outcome. https://thejns.org/doi/abs/10.3171/2022.5.jns22638 keywords serum; biomarker; traumatic axonal injury; fractional anisotropy; outcome; trauma; traumatic brain injury",AB_0500
"detecting recurrent patterns in time series data is an important capability. the reason is that repeating patterns on the one hand indicate well defined processes that can be further analyzed once detected and on the other hand are a reliable feature to predict future occurrences and adapt accordingly. the challenge in real data to define a period is that a time series is usually also influenced by non-periodic dynamics and noise. in this work, a mathematical framework is proved to define regular patterns. their properties are used within a suggested algorithm based on the concept of autocorrelation and function approximation to fit a model capturing the periodic part of the time series. based on that model and a corresponding autocorrelation, a new score is defined to evaluate how well a hypothesized period fits to the time series. this score is particularly useful in a big data scenario where decisions for periodic-ity are needed to be taken automatically, which is one of the main achievement of the presented work. the period analysis algorithm is applied to data from two different use cases. the first one is a data center scenario where the information of the periodic pattern is used to create a feature that improves a machine learning framework predicting future resource demands. the feature represents the phase of the repeating pattern. in a second scenario, expression data from mice liver cells are investigated con-cerning periodic rhythms. a python implementation of the presented algorithm is provided via a github repository under https://github.com/lauritzr/period-detection . (c) 2023 elsevier ltd. all rights reserved.",AB_0500
"redundant and complementary information from different types of sensors boosts the robustness of autonomous systems, making them more reliable and safer. in particular, inertial measurement units (imus) are increasingly being integrated with cameras for that purpose, since the information provided by the imu helps to simplify some visual problems and improves the accuracy of the results. in the context of estimating the motion of a camera, which is the problem we address in this work, the gravity vector delivers by the imu reduces the unknown rotation to only one degree of freedom instead of three, hence simplifying the relative pose problem (rpp). despite this simplification, the rpp is still nonconvex, therefore the quality (optimality) of the solution returned by iterative solvers cannot be guaranteed. these suboptimal solutions may have serious consequences for applications that have this solver as a key block, and may even cause their complete failure.in this paper, we contribute a certifiable solver for the rpp with gravity prior. we propose an iterative certifier that does not assume any condition on the problem, and returns an optimality certification even for an overconstrained formulation with 28 constraints in less than 1.5 milliseconds. since the certifier doesn't obtain the solution to the problem, we also provide a fast, iterative on-manifold estimation of the relative pose, which is shown to return solutions with lower costs than other nonminimal solvers in less time. we make the code available at https://www.github .com /mergarsal.(c) 2023 elsevier b.v. all rights reserved.",AB_0500
"the widespread use of high-throughput sequencing techniques is leading to a rapidly increasing number of disease-associated variants of unknown significance and candidate genes. integration of knowledge concerning their genetic, protein as well as functional and conservational aspects is necessary for an exhaustive assessment of their relevance and for prioritization of further clinical and functional studies investigating their role in human disease. to collect the necessary information, a multitude of different databases has to be accessed and data extraction from the original sources commonly is not user-friendly and requires advanced bioinformatics skills. this leads to a decreased data accessibility for a relevant number of potential users such as clinicians, geneticist, and clinical researchers. here, we present argus (https://argus.urz.uniheidelberg.de/), a standalone webtool for simple extraction and intuitive visualization of multi-layered gene, protein, variant, and variant effect prediction data. argus provides interactive exploitation of these data within seconds for any known gene of the human genome. in contrast to existing online platforms for compilation of variant data, argus complements visualization of chromosomal exon-intron structure and protein domain annotation with clinvar and gnomad variant distributions as well as position-specific variant effect prediction score modeling. argus thereby enables timely assessment of protein regions vulnerable to variation with single amino acid resolution and provides numerous applications in variant and protein domain interpretation as well as in the design of in vitro experiments. (c) 2023 published by elsevier b.v. on behalf of research network of computational and structural biotechnology. this is an open access article under the cc by-nc-nd license ().",AB_0500
"objectiveprevious symptom prevalence studies show a diverse spectrum of symptoms and a large diversity in symptom intensities in patients being just diagnosed as having incurable cancer. it is unclear, how physical symptoms and psychosocial burden should be recorded in order to determine the variable need for palliative care and further support. therefore, we compared two different strategies for detecting physical symptoms and psychosocial burden of patients with newly diagnosed incurable cancer and their effects on the further course of the disease. methodsscrebel is a controlled, randomized, non-blinded, longitudinal study of the research network of the palliative medicine working group (apm) of the german cancer society (dkg). we compared: a less complex repeated brief screening for symptoms and burden in patients using the nccn distress thermometer and ipos questionnaire versus a multidimensional comprehensive assessment using the fact-g and their entity-specific questionnaires, the phq4 scales, scns-34-sf, ipos and nccn distress thermometer. the primary study endpoint was quality of life (qol), measured using fact-g, after six months. secondary study endpoints were qol by using evaluation of secondary scores (nccn dt, ipos, phq4, scns-sf-34g) at time 6 months, the number of hospital days, the utilization of palliative care, emergency services, and psychosocial care structures. to assess effects and differences, multiple linear regression models were fitted and survival analyses were conducted. results504 patients were included in the study. 262 patients were lost to follow-up, including 155 fatalities. there were no significant differences between the low-threshold screening approach and a comprehensive assessment with respect to symptoms and other aspects of qol. using the ipos, we were able to measure an improvement in the quality of life in the low-threshold screening arm by a decrease of 0.67 points (95%-ci: 0.34 to 0.99) every 30 days. (p<0.001). data on the involvement of emergency facilities and on supportive services were insufficient for analysis. conclusiona comprehensive, multidimensional assessment did not significantly differ from brief screening in preserving several dimensions of quality of life. these findings may positively influence the implementation of structured low-threshold screening programs for supportive and palliative needs in dkg certified cancer centers.drks -no. drks00017774 https://drks.de/search/de/trial/drks00017774.",AB_0500
"background and objective: neurotechnologies have great potential to transform our society in ways that are yet to be uncovered. the rate of development in this field has increased significantly in recent years, but there are still barriers that need to be overcome before bringing neurotechnologies to the general public. one of these barriers is the difficulty of performing experiments that require complex software, such as brain-computer interfaces (bci) or cognitive neuroscience experiments. current platforms have limitations in terms of functionality and flexibility to meet the needs of researchers, who often need to implement new experimentation settings. this work was aimed to propose a novel software ecosystem, called medusa (c), to overcome these limitations. methods: we followed strict development practices to optimize medusa (c) for research in bci and cogni-tive neuroscience, making special emphasis in the modularity, flexibility and scalability of our solution. moreover, it was implemented in python, an open-source programming language that reduces the devel-opment cost by taking advantage from its high-level syntax and large number of community packages.results: medusa (c) provides a complete suite of signal processing functions, including several deep learn-ing architectures or connectivity analysis, and ready-to-use bci and neuroscience experiments, making it one of the most complete solutions nowadays. we also put special effort in providing tools to facilitate the development of custom experiments, which can be easily shared with the community through an app market available in our website to promote reproducibility.conclusions: medusa (c) is a novel software ecosystem for modern bci and neurotechnology experimen-tation that provides state-of-the-art tools and encourages the participation of the community to make a difference for the progress of these fields. visit the official website at https://www.medusabci.com/ to know more about this project.(c) 2023 the author(s). published by elsevier b.v. this is an open access article under the cc by license (  )",AB_0500
"motivation: structure-based stability prediction upon mutation is crucial for protein engineering and design, and for understanding genetic diseases or drug resistance events. for this task, we adopted a simple residue-based orientational potential that considers only three backbone atoms, previously applied in protein modeling. its application to stability prediction only requires parametrizing 12 amino acid-dependent weights using cross-validation strategies on a curated dataset in which we tried to reduce the mutations that belong to protein-protein or protein-ligand interfaces, extreme conditions and the alanine over-representation. results: our method, called korpm, accurately predicts mutational effects on an independent benchmark dataset, whether the wild-type or mutated structure is used as starting point. compared with state-of-the-art methods on this balanced dataset, our approach obtained the lowest root mean square error (rmse) and the highest correlation between predicted and experimental delta delta g measures, as well as better receiver operating characteristics and precision-recall curves. our method is almost anti-symmetric by construction, and it performs thus similarly for the direct and reverse mutations with the corresponding wild-type and mutated structures. despite the strong limitations of the available experimental mutation data in terms of size, variability, and heterogeneity, we show competitive results with a simple sum of energy terms, which is more efficient and less prone to overfitting. availability and implementation: https://github.com/chaconlab/korpm. contact: pablo@chaconlab.org supplementary information: supplementary data are available at bioinformatics online.",AB_0500
