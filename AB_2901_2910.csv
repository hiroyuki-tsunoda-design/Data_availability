AB,NO
"remote sensing object counting (rsoc) is finding applications in many fields. global regression is a long-ignored method for object counting, though it needs much less manual annotations than the alternatives. this work revisits global regression and improves it in two ways-one way is by replacing one single regressor with a deep ensemble, and the other is by breaking down global regression into two easier and smaller problems: learning to rank (l2r) and linear transformation (lt). to this end, we make a probably approximately correct (pac)-bayesian analysis of regression ensembles and give an upper bound for their generalization error, offering new theoretical insight into ensemble learning. we also adapt a ranking metric optimization scheme to suit object counting, elegantly handling the l2r problem with gradient descent. furthermore, based on our theoretical perspective, we provide a novel way of building deep regression ensembles, on which the ambiguity constraint is imposed. then, by incorporating l2r into a deep ensemble, we propose a new counting model called the ensemble of first-rank-then-estimate networks (efreenet). our extensive evaluation on six benchmarks shows that the efreenet exhibits compelling performance across the board while being more annotation-efficient than other methods. our source code is publicly available at https://github.com/huangyongbobo/efreenet.",AB_0291
"in recent years, deep learning has been widely used in synthetic aperture radar (sar) automatic target recognition (atr) and achieved excellent performance on the moving and stationary target acquisition and recognition (mstar) dataset. however, due to constrained imaging conditions, mstar has data biases such as background correlation, that is, background clutter properties have a spurious correlation with target classes. deep learning can overfit clutter to reduce training errors. therefore, the degree of overfitting for clutter reflects the noncausality of deep learning in sar atr. existing methods only qualitatively analyze this phenomenon. in this letter, we quantify the contributions of different regions to target recognition based on the shapley value. the shapley value of clutter measures the degree of overfitting. moreover, we explain how data bias and model bias contribute to noncausality. concisely, data bias leads to comparable signal-to-clutter ratios (scr) and clutter textures in training and test sets. and various model structures have different degrees of overfitting for these biases. the experimental results of various models under standard operating conditions (socs) on the mstar dataset support our conclusions. our code is available at https://github.com/waterdisappear/data-bias-in-mstar.",AB_0291
"learning-based multimodal data has attracted increasing interest in the remote sensing community owing to its robust performance. although it is preferable to collect multiple modalities for training, not all of them are available in practical scenarios due to the restriction of imaging conditions. therefore, how to assist the model inference with missing modalities is significant for multimodal remote sensing image processing. in this work, we propose a general framework called modality-shared hallucination network (msh-net) to address this issue by reconstructing complete modality-shared features from incomplete inference modalities. compared to conventional privilege modality hallucination methods, msh-net does not only help preserve the cross-modal interactions for model inference but also scales well with the increasing number of missing modalities. we further develop a novel joint adaptation distillation (jad) method that guides the hallucination model to learn the modality-shared knowledge from the multimodal model by matching the joint probability distributions between representation and groundtruth. this overcomes the representation heterogeneity caused by the discrepancy between inputs and structures of multimodal and hallucination model while preserving the decision boundaries refined by multimodal cues. finally, extensive experiments conducted on four common modality combinations demonstrate that the proposed msh-net can effectively address the problem of missing modalities and achieve state-of-the-art performance. code is available at: https://github.com/shicaiwei123/mshnet",AB_0291
"in practical applications, the generalization capability of face anti-spoofing (fas) models on unseen domains is of paramount importance to adapt to diverse camera sensors, device drift, environmental variation, and unpredictable attack types. recently, various domain generalization (dg) methods have been developed to improve the generalization capability of fas models via training on multiple source domains. these dg methods commonly require collecting sufficient real-world attack samples of different attack types for each source domain. this work aims to learn a fas model without using any real-world attack sample in any source domain but can generalize well to the unseen domain, which can significantly reduce the learning cost. toward this goal, we draw inspiration from the theoretical error bound of domain generalization to use negative data augmentation instead of real-world attack samples for training. we show that using only a few types of simple synthesized negative samples, e.g., color jitter and color mask, the learned model can achieve competitive performance over state-of-the-art dg methods trained using real-world attack samples. moreover, a dynamic global common loss and a local contrast loss are proposed to prompt the model to learn a compact and common feature representation for real face samples from different source domains, which can further improve the generalization capability. experimental results of extensive cross-dataset testing demonstrate that our method can even outperform state-of-the-art dg methods using real-world attack samples for training. the code for reproducing the results of our method is available at https://github.com/weihangwang/nda-fas.",AB_0291
"we formulate the registration as a function that maps the input reference and sensed images to eight displacement parameters between prescribed matching points, as opposed to the usual techniques (feature extraction-description-matching-geometric restrictions). the projection transformation matrix (ptm) is then computed in the neural network and used to warp the sensed image, uniting all matching tasks under one framework. in this article, we offer a multimodal image fusion network with self-attention to merge the feature representation of the reference and sensed images. the integration information is then utilized to regress the prescribed points' displacement parameters to get ptm between the reference and sensed images. finally, ptm is supplied into the spatial transformation network (stn), which warps the sensed image to the same coordinates as the reference image, achieving end-to-end matching. in addition, a dual-supervised loss function is proposed to optimize the network from both the prescribed point displacement and the overall pixel matching perspectives. the effectiveness of our method is validated by qualitative and quantitative experimental results on multimodal remote sensing image matching tasks. the code is available at: https://github.com/liliangzhi110/e2eir.",AB_0291
"automatic change detection of open-pit mines from high-resolution remote sensing images is of great significance for the mining and management of mineral resources. for this purpose, we propose a siamese multiscale change detection network (smcdnet) with an encoder-decoder structure. first, the multiscale low-level and high-level features of the bi-temporal image are extracted by a siamese network. second, a multilevel feature absolute difference (mfad) module is proposed to fuse the low-level and high-level change features. finally, convolution and up-sampling operations are used to recover the details of the changed areas. a self-made open-pit mine change detection (omcd) dataset is employed to conduct experiments. experimental results have demonstrated that the proposed method is superior to the comparison networks. f1 - score of 88.13% is achieved by the proposed smcdnet. the omcd dataset produced in this study has been made public at the following link: https://figshare.com/s/ae4e8c808b67543d41e9.",AB_0291
"identifying the surface topographic changes accurately plays a vital role in the task of planetary exploration. in this study, a lightweight mobile vision transformer-based planetary image change detection (mvit-pcd) was proposed for monitoring dynamic surface changes using bitemporal images. the mobile vision transformer (mobilevit) was first introduced to make the most of the spatial information available. subsequently, a multiscale feature differentiation and fusion (mfdf) block was adopted to improve the distinguishability of multilevel contextual information. moreover, the strategy of information maximization (im) was integrated to refine the model performance on the heterogeneous dataset. then, experiments were conducted on the public martian datasets. compared with other state-of-the-art (sota) methods, the mvit-pcd provides favorable performance, with the highest accuracy of 97.2% and 82.9%, respectively, under the speed of 43.4 frame per second (fps). code is available at https://github.com/lynn1023-max/mvitpcd.",AB_0291
"hyperspectral anomaly detection (had) plays a vital role in military and civilian applications. however, compared with target detection or classification tasks, had is more challenging due to insufficient anomaly information and the difficulty of extracting local and global discriminative features. in this letter, a convolutional transformer-inspired autoencoder (cta) is proposed for had. the cta consists of a clustering-based module and an autoencoder-based module. first, note that the number of anomalies is small, and distinct from their surroundings, a clustering-based module is proposed to detect the pseudo-background and anomaly samples. second, the autoencoder module is composed of an encoder and a decoder formed from several skip-connected convolutions and multihead attention-based transformers. the cta is trained not only to distinguish the anomalies from the background but also to reconstruct the input hyperspectral images (hsis). benefiting from integrating the convolution and transformer, the cta has local and global receptive fields. moreover, both background and anomaly information explored by the clustering-based module can be adopted to improve the separability of anomalies. experiments on two hyperspectral datasets demonstrate that the proposed cta achieves superior detection performance to its counterparts. the code is available at https://github.com/hzhdhz/cta.",AB_0291
"in presence of multiple objectives to be optimized in search-based software engineering (sbse), pareto search has been commonly adopted. it searches for a good approximation of the problem's pareto-optimal solutions, from which the stakeholders choose the most preferred solution according to their preferences. however, when clear preferences of the stakeholders (e.g., a set of weights that reflect relative importance between objectives) are available prior to the search, weighted search is believed to be the first choice, since it simplifies the search via converting the original multi-objective problem into a single-objective one and enables the search to focus on what only the stakeholders are interested in. this article questions such a weighted search first belief. we show that theweights can, in fact, be harmful to the search process even in the presence of clear preferences. specifically, we conduct a large-scale empirical study that consists of 38 systems/projects from three representative sbse problems, together with two types of search budget and nine sets of weights, leading to 604 cases of comparisons. our key finding is that weighted search reaches a certain level of solution quality by consuming relatively less resources at the early stage of the search; however, pareto search is significantly better than its weighted counterpart the majority of the time (up to 77% of the cases), as long as we allow a sufficient, but not unrealistic search budget. this is a beneficial result, as it discovers a potentially new rule-of-thumb for the sbse community: even when clear preferences are available, it is recommended to always consider pareto search by default for multi-objective sbse problems, provided that solution quality is more important. weighted search, in contrast, should only be preferred when the resource/search budget is limited, especially for expensive sbse problems. this, together with other findings and actionable suggestions in the article, allows us to codify pragmatic and comprehensive guidance on choosingweighted and pareto search for sbse under the circumstance that clear preferences are available. all code and data can be accessed at https://github.com/ideas-labo/pareto-vs- weight- for- sbse.",AB_0291
"patch-based physical attacks have increasingly aroused concerns. however, most existing methods focus on obscuring targets captured on the ground, and some of these methods are simply extended to deceive aerial detectors. they smear the targeted objects in the physical world with the elaborated adversarial patches, which can only slightly sway the aerial detectors' prediction and with weak attack transferability. to address the above issues, a novel contextual background attack (cba) framework is proposed to fool aerial detectors in the physical world, which can achieve strong attack efficacy and transferability in real-world scenarios even without smudging the interested objects at all. specifically, the targets of interest, i.e., the aircraft in aerial images, are adopted to mask adversarial patches. the pixels outside the mask area are optimized to make the generated adversarial patches closely cover the critical contextual background area for detection, which contributes to gifting adversarial patches with more robust and transferable attack potency in the real world. to further strengthen the attack performance, the adversarial patches are forced to be outside targets during training, by which the detected objects of interest, both on and outside patches, benefit the accumulation of attack efficacy. consequently, the sophisticatedly designed patches are gifted with solid fooling efficacy against objects both on and outside the adversarial patches simultaneously. extensive proportionally scaled experiments are performed in physical scenarios, demonstrating the superiority and potential of the proposed framework for physical attacks. we expect that the proposed physical attack method will serve as a benchmark for assessing the adversarial robustness of diverse aerial detectors and defense methods. the code has been released at https://github.com/jiaweilian/cba.",AB_0291
