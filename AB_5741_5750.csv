AB,NO
"in this article, we consider a category-level perception problem, where one is given 2-d or 3-d sensor data picturing an object of a given category (e.g., a car) and has to reconstruct the 3-d pose and shape of the object despite intraclass variability (i.e., different car models have different shapes). we consider an active shape model, where-for an object category-we are given a library of potential computer-aided design models describing objects in that category, and we adopt a standard formulation where pose and shape are estimated from 2-d or 3-d keypoints via nonconvex optimization. our first contribution is to develop pace3d* and pace2d*, the first certifiably optimal solvers for pose and shape estimation using 3-d and 2-d keypoints, respectively. both the solvers rely on the design of tight (i.e., exact) semidefinite relaxations. our second contribution is to develop outlier-robust versions of both the solvers, named pace3d# and pace2d#. toward this goal, we propose robin(reject outliers based on invariants), a general graph-theoretic framework to prune outliers, which uses compatibility hypergraphs to model measurements' compatibility. we show that in category-level perception problems, these hypergraphs can be built from the winding orders of the keypoints (in 2-d) or their convex hulls (in 3-d), and many outliers can be filtered out via maximum hyperclique computation. the last contribution is an extensive experimental evaluation. besides providing an ablation study on simulated datasets and on the pascal3d+ dataset, we combine our solver with a deep keypoint detector and show that pace3d# improves over the state of the art in vehicle pose estimation in the apolloscape datasets, and its runtime is compatible with practical applications. we release our code at https://github.com/mit-spark/pace.",AB_0575
"the lack of standardization and consistency of acquisition is a prominent issue in magnetic resonance (mr) imaging. this often causes undesired contrast variations in the acquired images due to differences in hardware and acquisition parameters. in recent years, image synthesis-based mr harmonization with disentanglement has been proposed to compensate for the undesired contrast variations. the general idea is to disentangle anatomy and contrast information from mr images to achieve cross-site harmonization. despite the success of existing methods, we argue that major improvements can be made from three aspects. first, most existing methods are built upon the assumption that multi-contrast mr images of the same subject share the same anatomy. this assumption is questionable, since different mr contrasts are specialized to highlight different anatomical features. second, these methods often require a fixed set of mr contrasts for training (e.g., both t1 weighted and t2-weighted images), limiting their applicability. lastly, existing methods are generally sensitive to imaging artifacts. in this paper, we present harmonization with attention-based contrast, anatomy, and artifact awareness (haca3), a novel approach to address these three issues. haca3 incorporates an anatomy fusion module that accounts for the inherent anatomical differences between mr contrasts. furthermore, haca3 can be trained and applied to any combination of mr contrasts and is robust to imaging artifacts. haca3 is developed and evaluated on diverse mr datasets acquired from 21 sites with varying field strengths, scanner platforms, and acquisition protocols. experiments show that haca3 achieves state-of-theart harmonization performance under multiple image quality metrics. we also demonstrate the versatility and potential clinical impact of haca3 on downstream tasks including white matter lesion segmentation for people with multiple sclerosis and longitudinal volumetric analyses for normal aging subjects. code is available at https://github.com/lianruizuo/haca3.",AB_0575
"nonlinear optical spectroscopy is a well-developed field with theoretical and experimental advances that have benefited multiple disciplines, including chemistry, biology, and physics. however, for the accurate interpretation of the corresponding multi-dimensional spectra, there is a need for precise quantum dynamical simulations based on model hamiltonians. in this article, we present the initial release of our code, qudpy (quantum dynamics in python), which provides a robust numerical platform for performing quantum dynamics simulations based on model systems, including open quantum systems. a distinguishing feature of our approach is the ability to specify various high-order optical response pathways in the form of double-sided feynman diagrams through a straightforward input syntax. this syntax outlines the time-ordering of ket-sided or bra-sided optical interactions acting on the time-evolving density matrix of the system. we utilize the quantum dynamics capabilities of qutip to simulate the spectral response of complex systems, allowing us to compute virtually any n-th order optical response of the model system. to illustrate the utility of our approach, we provide a series of example calculations.program summaryprogram title: qudpycpc library link to program files: https://doi.org/10.17632/5xm9pm24cz.1developer's repository link: https://github.com/sa-shah/qudpylicensing provisions: mit licenseprogramming language: python (v3.7)supplementary material: available as google colab files. example 1: https://tinyurl.com/y3j5jmmr example 2: https://tinyurl.com/37vwntn5external packages:& bull;qutip (v.4.7) and dependencies i.e. numpy, matplotlib (https://qutip.org/)& bull;ufss automatic diagram generator (https://github.com/peterarose/ufss)nature of problem: accurate quantum simulations of complex systems are required in order to understand and interpret multi-dimensional ultrafast spectroscopic signals. this code provides an open-source/multi-platform method that facilitates the generation of higher-order non-linear optical responses for an arbitrary molecular or material system given a model input hamiltonian and bath model.solution method: we use the double-sided feynman diagram method [1, 2] to generate (symbolically) a set of response functions corresponding to the ��ℎ order non-linear response of the system to a series of laser pulses using the ufss package [3] we then perform a series of accurate quantum dynamics calculations using the qutip package [4] to generate the numerical response and spectra which correspond to specific experimental conditions.references[1] s. mukamel, principles of nonlinear optics and spectroscopy, oxford university press, 1995.[2] p. hamm, m. zanni, concepts and methods of 2d infrared spectroscopy, cambridge university press, 2011.<br />[3] peter a. rose, jacob j. krich, j. chem. phys. 154 (2021) 034109.<br />[4] j. johansson, p. nation, f. nori, comput. phys. commun. 184 (4) (2013) 1234-1240.& copy; 2023 elsevier b.v. all rights reserved.",AB_0575
"background and objective: unsupervised domain adaptation (uda) is a powerful approach in tackling domain discrepancies and reducing the burden of laborious and error-prone pixel-level annotations for instance segmentation. however, the domain adaptation strategies utilized in previous instance segmentation models pool all the labeled/detected instances together to train the instance-level gan discriminator, which neglects the differences among multiple instance categories. such pooling prevents uda instance segmentation models from learning categorical correspondence between source and target domains for accurate instance classification;methods: to tackle this challenge, we propose an instance segmentation cyclegan (isc-gan) algorithm for uda multiclass-instance segmentation. we conduct extensive experiments on the multiclass nuclei recognition task to transfer knowledge from hematoxylin and eosin to immunohistochemistry stained pathology images. specifically, we fuse cyclegan with mask r-cnn to learn categorical correspondence with image-level domain adaptation and virtual supervision. moreover, we utilize curriculum learning to separate the learning process into two steps: (1) learning segmentation only on labeled source data, and (2) learning target domain segmentation with paired virtual labels generated by isc-gan. the performance was further improved through experiments with other strategies, including shared weights, knowledge distillation, and expanded source data.results: comparing to the baseline model or the three uda instance detection and segmentation models, isc-gan illustrates the state-of-the-art performance, with 39.1% average precision and 48.7% average recall. the source codes of isc-gan are available at https://github.com/sdw95927/instancesegmentation-cyclegan.conclusion: isc-gan adapted knowledge from hematoxylin and eosin to immunohistochemistry stained pathology images, suggesting the potential for reducing the need for large annotated pathological image datasets in deep learning and computer vision tasks.",AB_0575
"training segmentation models for medical images continues to be challenging due to the limited availability of data annotations. segment anything model (sam) is a foundation model trained on over 1 billion annotations, predominantly for natural images, that is intended to segment user-defined objects of interest in an interactive manner. while the model performance on natural images is impressive, medical image domains pose their own set of challenges. here, we perform an extensive evaluation of sam's ability to segment medical images on a collection of 19 medical imaging datasets from various modalities and anatomies. in our experiments, we generated point and box prompts for sam using a standard method that simulates interactive segmentation. we report the following findings: (1) sam's performance based on single prompts highly varies depending on the dataset and the task, from iou=0.1135 for spine mri to iou=0.8650 for hip x-ray. (2) segmentation performance appears to be better for well-circumscribed objects with prompts with less ambiguity such as the segmentation of organs in computed tomography and poorer in various other scenarios such as the segmentation of brain tumors. (3) sam performs notably better with box prompts than with point prompts. (4) sam outperforms similar methods ritm, simpleclick, and focalclick in almost all single-point prompt settings. (5) when multiple-point prompts are provided iteratively, sam's performance generally improves only slightly while other methods' performance improves to the level that surpasses sam's point-based performance. we also provide several illustrations for sam's performance on all tested datasets, iterative segmentation, and sam's behavior given prompt ambiguity. we conclude that sam shows impressive zero-shot segmentation performance for certain medical imaging datasets, but moderate to poor performance for others. sam has the potential to make a significant impact in automated medical image segmentation in medical imaging, but appropriate care needs to be applied when using it. code for evaluation sam is made publicly available at https://github.com/mazurowski-lab/segment-anything-medical-evaluation.",AB_0575
"structure-based virtual screening (vs) is an effectivemethod foridentifying potential small-molecule ligands, but traditional vs approachesconsider only a single binding-pocket conformation. consequently,they struggle to identify ligands that bind to alternate conformations.ensemble docking helps address this issue by incorporating multipleconformations into the docking process, but it depends on methodsthat can thoroughly explore pocket flexibility. we here introducesub-pocket explorer (subpex), an approach that uses weighted ensemble(we) path sampling to accelerate binding-pocket sampling. as proofof principle, we apply subpex to three proteins relevant to drug discovery:heat shock protein 90, influenza neuraminidase, and yeast hexokinase2. subpex is available free of charge without registration under theterms of the open-source mit license: http://durrantlab.com/subpex/.",AB_0575
"it is well-known that 3d shape and texture reconstruction from a single-view image is a very challenging and an ill-posed problem, especially without 3d supervision/ground truth. existing neural implicit surface reconstruction approaches do easily get trapped in the local minima and cannot produce high-fidelity geometry and high-quality textures (and rendered images) under single-view setting, even with provided highly sparse depth prior. in this paper, we propose a new self-supervised learning method diffsvr that represents a complicated surface as a new depth-aware occupancy function (dof) and utilizes an end-to-end differentiable surface rendering paradigm to optimize the neural dof field relying only on single-view image with highly sparse depth information. the developed surface-aware sampling, occupancy self-labeling, and differentiable surface rendering with inverse computation techniques can enhance both the neural implicit surface reconstruction and the neural renderer. the extensive experiments and comparisons on two real-world benchmark datasets (e.g., dtu and kitti) demonstrate that our approach not only numerically outperforms the current state-of-the-art methods by a large margin, but also produces surface mesh model with qualitatively better geometric details and more accurate textures, as well as exhibits good performance on generalizability and flexibility. the code and data are available at https://github.com/akomarichev/diffsvr.& copy; 2023 elsevier ltd. all rights reserved.",AB_0575
"weimplemented an ab initio ccs prediction workflowwhich incrementally refines generated structures using molecular mechanics,a deep learning potential, conformational clustering, and quantummechanics (qm). automating intermediate steps for a high performancecomputing (hpc) environment allows users to input the smiles structureof small organic molecules and obtain a boltzmann averaged collisionalcross section (ccs) value as output. the ccs of a molecular speciesis a metric measured by ion mobility spectrometry (ims) which canimprove annotation of untargeted metabolomics experiments. we reportonly a minor drop in accuracy when we expedite the ccs calculationby replacing the qm geometry refinement step with a single-point energycalculation. even though the workflow involves stochastic steps (i.e.,conformation generation and clustering), the final ccs value was highlyreproducible for multiple iterations on l-carnosine. finally, we illustratethat the gas phase ensembles modeled for the workflow are intermediatefiles which can be used for the prediction of other properties suchas aqueous phase nuclear magnetic resonance chemical shift prediction.the software is available at the following link: https://github.com/dassusanta/snakemake_ccs.",AB_0575
"objective. to develop and clinically implement a fully automated treatment planning system (tps) for volumetric modulated arc therapy (vmat). approach. we solve two constrained optimization problems sequentially. the tumor coverage is maximized at the first step while respecting all maximum/mean dose clinical criteria. the second step further reduces the dose at the surrounding organs-at-risk as much as possible. our algorithm optimizes the machine parameters (leaf positions and monitor units) directly and the resulting mathematical non-convexity is handled using the sequential convex programmingby solving a series of convex approximation problems. we directly integrate two novel convex surrogate metrics to improve plan delivery efficiency and reduce plan complexity by promoting aperture shape regularity and neighboring aperture similarity. the entire workflow is automated using the eclipse tps application program interface scripting and provided to users as a plug-in, requiring the users to solely provide the contours and their preferred arcs. our program provides the optimal machine parameters and does not utilize the eclipse optimization engine, however, it utilizes the eclipse final dose calculation engine. we have tested our program on 60 patients of different disease sites and prescriptions for stereotactic body radiotherapy (paraspinal (24 gy x 1, 9 gy x 3), oligometastis (9 gy x 3), lung (18 gy x 3,12 gy x 4)) and retrospectively compared the automated plans with the manual plans used for treatment. the program is currently deployed in our clinic and being used in our daily clinical routine to treat patients. main results. the automated plans found dosimetrically comparable or superior to the manual plans. for paraspinal (24 gy x 1), the automated plans especially improved tumor coverage (the average ptv (planning target volume) 95% from 96% to 98% and ctv100% from 95% to 97%) and homogeneity (the average ptv maximum dose from 120% to 116%). for other sites/prescriptions, the automated plans especially improved the duty cycle (23%-39.4%). significance. this work proposes a fully automated approach to the mathematically challenging vmat problem. it also shows how the capabilities of the existing (food and drug administration)fda-approved commercial tps can be enhanced using an in-house developed optimization algorithm that completely replaces the tps optimization engine. the code and pertained models along with a sample dataset will be released on our echo-vmat github (https://github.com/portpy-project/echo-vmat).",AB_0575
"humans are known to have significant , consistent differences in thickness throughout the cortex, with thick outer gyral folds and thin inner sulcal folds. our previous work has suggested a mechanical basis for this thickness pattern, with the forces generated during cortical folding leading to thick gyri and thin sulci , shown that cortical thickness varies along a gyral-sulcal spectrum in humans. while other primate species are expected to exhibit similar patterns of cortical thickness, it is currently unknown how these patterns scale across different sizes, forms, and foldedness. among primates, brains vary enormously from roughly the size of a grape to the size of a grapefruit, and from nearly smooth to dramatically folded; of these, human brains are the largest and most folded. these variations in size and form make comparative neuroanatomy a rich resource for investigating common trends that transcend differences between species. in this study, we examine 12 primate species in order to cover a wide range of sizes and forms, and investigate the scaling of their cortical thickness relative to the surface geometry. the 12 species were selected due to the public availability of either reconstructed surfaces and/or population templates. after obtaining or reconstructing 3d surfaces from publicly available neuroimaging data, we used our surface-based computational pipeline (https://github.com/mholla/curveball) to analyze patterns of cortical thickness and folding with respect to size (total surface area), geometry (i.e. curvature, shape, and sulcal depth), and foldedness (gyrification). in all 12 species, we found consistent cortical thickness variations along a gyral-sulcal spectrum, with convex shapes thicker than concave shapes and saddle shapes in between. furthermore, we saw an increasing thickness difference between gyri and sulci as brain size increases. our results suggest a systematic folding mechanism relating local cortical thickness to geometry. finally, all of our reconstructed surfaces and morphometry data are available for future research in comparative neuroanatomy.",AB_0575
