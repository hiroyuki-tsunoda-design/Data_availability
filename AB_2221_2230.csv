AB,NO
"this work presents unified contrastive arbitrary style transfer (ucast), a novel style representation learning and transfer framework, that can fit in most existing arbitrary image style transfer models, such as cnn-based, vit-based, and flow-based methods. as the key component in image style transfer tasks, a suitable style representation is essential to achieve satisfactory results. existing approaches based on deep neural networks typically use second-order statistics to generate the output. however, these hand-crafted features computed from a single image cannot leverage style information sufficiently, which leads to artifacts such as local distortions and style inconsistency. to address these issues, we learn style representation directly from a large number of images based on contrastive learning by considering the relationships between specific styles and the holistic style distribution. specifically, we present an adaptive contrastive learning scheme for style transfer by introducing an input-dependent temperature. our framework consists of three key components: a parallel contrastive learning scheme for style representation and transfer, a domain enhancement (de) module for effective learning of style distribution, and a generative network for style transfer. qualitative and quantitative evaluations showthe results of our approach are superior to those obtained via state-of-the-art methods. the code is available at https://github.com/ zyxelsa/cast_pytorch.",AB_0223
"clarifying the morphological characteristics of neurons can promote the understanding of brain function. however, traditional morphometrics fail to capture the modeling of each point in reconstructed neurons, leading to limited ability to distinguish massive nerve fibers and restricted application scenarios. to address these challenges, we propose morphognn, a single neuron morphological embedding based on a graph neural network in this study. morphognn learns the point-level structure information of reconstructed nerve fibers by considering their nearest neighbors on each hidden layer. this enables morphognn to capture the lower-dimensional representation of a single neuron through an end-to-end model. in order to meet the requirements of various tasks, both supervised and self-supervised training strategies are designed to learn the characteristics that fit artificial semantics or the morphological patterns of neurons, respectively. we quantitatively compare our embeddings with other features in neuron classification and retrieval tasks and demonstrate cutting-edge performance. additionally, we introduce our embeddings to the task of reconstruction quality classification and neuron clustering, where they can help detect reconstruction errors and obtain similar subtyping results to existing work. furthermore, our method can be handily combined with other modal features, such as microscopic image features and traditional morphometrics. ablation and robustness tests are also conducted to analyze the impact of several network components and low-quality reconstructed neurons on the performance of our method. the code is available at https://github.com/fun0515/morphognn.",AB_0223
"the pathophysiology of major depressive disorder (mdd) has been demonstrated to be highly associated with the dysfunctional integration of brain activity. existing studies only fuse multi-connectivity information in a one-shot approach and ignore the temporal property of functional connectivity. a desired model should utilize the rich information in multiple connectivities to help improve the performance. in this study, we develop a multi-connectivity representation learning framework to integrate multi-connectivity topological representation from structural connectivity, functional connectivity and dynamic functional connectivities for automatic diagnosis of mdd. briefly, structural graph, static functional graph and dynamic functional graphs are first computed from the diffusion magnetic resonance imaging (dmri) and resting state functional magnetic resonance imaging (rsfmri). secondly, a novel multi-connectivity representation learning network (mcrln) approach is developed to integrate the multiple graphs with modules of structural-functional fusion and static-dynamic fusion. we innovatively design a structural-functional fusion (sff) module, which decouples graph convolution to capture modality-specific features and modality-shared features separately for an accurate brain region representation. to further integrate the static graphs and dynamic functional graphs, a novel static-dynamic fusion (sdf) module is developed to pass the important connections from static graphs to dynamic graphs via attention values. finally, the performance of the proposed approach is comprehensively examined with large cohorts of clinical data, which demonstrates its effectiveness in classifying mdd patients. the sound performance suggests the potential of the mcrln approach for the clinical use in diagnosis. the code is available at https://github.com/list-kong/multiconnectivity-master.",AB_0223
"the multi-site approach has attracted increasing attention in brain disease diagnosis, because it can improve the prediction performance by integrating sample information from different medical institutions. however, its training procedure requires the transmission of subject's original images or features among sites, which may cause privacy disclosure. in this article, we propose a self-supervised federated adaptation (s2fa) framework for robust multi-site prediction, which can reduce the risk of privacy disclosure. as far as we know, it is the first work to investigate the cross-site brain disease diagnosis, which trains model on source sites and tests on target site, often occurring in clinical practice. first, we implement a decentralized federated optimization strategy, by which each site communicates model parameters periodically. second, we construct an auxiliary self-supervised model for target site through transferring knowledge from source sites with self-paced learning. then, a hash mapping is proposed to encode the target feature, simultaneously reducing the risk of privacy information disclosure and alleviating data heterogeneity among sites. finally, we achieve the cross-site prediction by weighted federated source model and auxiliary target model. experimental results on multi-site datasets show that the proposed s2fa can accurately identify brain disease. our codes are available at https://github.com/nuaayqm/s2fa.",AB_0223
"pre-training model on large-scale unlabeled web videos followed by task-specific fine-tuning is a canonical approach to learning video and language representations. however, the accompanying automatic speech recognition (asr) transcripts in these videos are directly transcribed from audio, which may be inconsistent with visual information and would impair the language modeling ability of the model. meanwhile, previous v-l models fuse visual and language modality features using single- or dual-stream architectures, which are not suitable for the current situation. besides, traditional v-l research focuses mainly on the interaction between vision and language modalities and leaves the modeling of relationships within modalities untouched. to address these issues andmaintain a smallmanual labor cost, we add automatically extracted dense captions as a supplementary text and propose a new trilinear video-language interaction framework tevl (trilinear encoder for video-language representation learning). tevl contains three unimodal encoders, a trilinear encoder (trio) block, and a temporal transformer. trio is specially designed to support effective text-vision-text interaction, which encourages inter-modal cooperation while maintaining intra-modal dependencies. we pre-train tevl on the howto100m and tv datasets with four task objectives. experimental results demonstrate that tevl can learn powerful video-text representation and achieve competitive performance on three downstream tasks, including multimodal video captioning, video question answering (qa), as well as video and language inference. implementation code is available at https://github.com/gufrannn/tevl.",AB_0223
"person re-identification (reid) plays an important role in applications such as public security and video surveillance. recently, learning from synthetic data [9], which benefits from the popularity of the synthetic data engine, has attracted great attention from the public. however, existing datasets are limited in quantity, diversity, and realisticity, and cannot be efficiently used for the reid problem. to address this challenge, we manually construct a large-scale person dataset named finegpr with fine-grained attribute annotations. moreover, aiming to fully exploit the potential of finegpr and promote the efficient training from millions of synthetic data, we propose an attribute analysis pipeline called aost based on the traditional machine learning algorithm, which dynamically learns attribute distribution in a real domain, then eliminates the gap between synthetic and real-world data and thus is freely deployed to new scenarios. experiments conducted on benchmarks demonstrate that finegpr with aost outperforms (or is on par with) existing real and synthetic datasets, which suggests its feasibility for the reid task and proves the proverbial less-is-more principle. our synthetic finegpr dataset is publicly available at https://github.com/jeremyxsc/finegpr.",AB_0223
"semantic segmentation of histopathological images is important for automatic cancer diagnosis, and it is challenged by time-consuming and labor-intensive annotation process that obtains pixel-level labels for training. to reduce annotation costs, weakly supervised semantic segmentation (wsss) aims to segment objects by only using image or patch-level classification labels. current wsss methods are mostly based on class activation map (cam) that usually locates the most discriminative object part with limited segmentation accuracy. in this work, we propose a novel two-stage weakly supervised segmentation framework based on high-resolution activation maps and interleaved learning (hamil). first, we propose a simple yet effective classification network with high-resolution activation maps (ham-net) that exploits a lightweight classification head combined with multiple layer fusion (mlf) of activation maps and monte carlo augmentation (mca) to obtain precise foreground regions. second, we use dense pseudo labels generated by ham-net to train a better segmentation model, where three networks with the same structure are trained with interleaved learning: the agreement between two networks is used to highlight reliable pseudo labels for training the third network, and at the same time, the two networks serve as teachers for guiding the third network via knowledge distillation. extensive experiments on two public histopathological image datasets of lung cancer demonstrated that our proposed hamil outperformed state-of-the-art weakly supervised and noisy label learning methods, respectively. the code is available at https://github.com/hilab-git/hamil.",AB_0223
"chromosome recognition is a critical way to diagnose various hematological malignancies and genetic diseases, which is however a repetitive and time-consuming process in karyotyping. to explore the relative relation between chromosomes, in this work, we start from a global perspective and learn the contextual interactions and class distribution features between chromosomes within a karyotype. we propose an end-to-end differentiable combinatorial optimization method, karyonet, which captures long-range interactions between chromosomes with the proposed masked feature interaction module (mfim) and conducts label assignment in a flexible and differentiable way with deep assignment module (dam). specially, a feature matching sub-network is built to predict the mask array for attention computation in mfim. lastly, type and polarity prediction head can predict chromosome type and polarity simultaneously. extensive experiments on r-band and g-band two clinical datasets demonstrate the merits of the proposed method. for normal karyotypes, the proposed karyonet achieves the accuracy of 98.41% on r-band chromosome and 99.58% on g-band chromosome. owing to the extracted internal relation and class distribution features, karyonet can also achieve state-of-the-art performances on karyotypes of patients with different types of numerical abnormalities. the proposed method has been applied to assist clinical karyotype diagnosis. our code is available at: https://github.com/xiabc612/karyonet.",AB_0223
"recently, segment anything model (sam) has become popular in computer vision field because of its powerful image segmentation ability and high interactivity of various prompts, which opens a new era of large vision foundation models. but is sam really omnipotent? in this letter, we establish a comprehensive bimodal few-shot segmentation indoor dataset vt-840-5i, and compare sam with eight state-of-the-art few-shot segmentation (fss) methods on two benchmark datasets. qualitative and quantitative experiment results show that although sam is very effective in general object segmentation, it still has room for improvement in some challenging scenarios. therefore, we introduce thermal infrared auxiliary information into the segmentation task and provide multiple fusion strategies (mfs) for readers to choose the most suitable approach for the specific task. finally, we discuss several potential research trends about sam in the future. our test results are available at: https://github. com/vdt-2048/bi-sam.",AB_0223
"the 2019 novel coronavirus (sars-cov-2) has infected millions of people worldwide and caused millions of deaths. the virus has gone numerous mutations to replicate faster, which can overwhelm the immune system of the host. linear b-cell epitopes are becoming promising in prevention of various deadly infectious diseases, breaking the general idea of their low immunogenicity and partial protection. however, there is still no public repository to host the linear b-cell epitopes for facilitating the development vaccines against sars-cov-2. therefore, we developed bcedb, a linear b-cell epitopes database specifically designed for hosting, exploring and visualizing linear b-cell epitopes and their features. the database provides a comprehensive repository of computationally predicted linear b-cell epitopes from spike protein; a systematic annotation of epitopes including sequence, antigenicity score, genomic locations of epitopes, mutations in different virus lineages, mutation sites on the 3d structure of spike protein and a genome browser to visualize them in an interactive manner. it represents a valuable resource for peptide-based vaccine development.database url: http://www.oncoimmunobank.cn/bcedbindex",AB_0223
