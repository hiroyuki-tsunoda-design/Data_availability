AB,NO
"the immune memory repertoire encodes the history of present and past infections and immunological attributes of the individual. as such, multiple methods were proposed to use t-cell receptor (tcr) repertoires to detect disease history. we here show that the counting method outperforms two leading algorithms. we then show that the counting can be further improved using a novel attention model to weigh the different tcrs. the attention model is based on the projection of tcrs using a variational autoencoder (vae). both counting and attention algorithms predict better than current leading algorithms whether the host had cmv and its hla alleles. as an intermediate solution between the complex attention model and the very simple counting model, we propose a new graph convolutional network approach that obtains the accuracy of the attention model and the simplicity of the counting model. the code for the models used in the paper is provided at: https://github.com/louzounlab/countingisalmostallyouneed.",AB_0565
"for fashion outfits to be considered aesthetically pleasing, the garments that constitute them need to be compatible in terms of visual aspects, such as style, category and color. previous works have defined visual compatibility as a binary classification task with items in a garment being considered as fully compatible or fully incompatible. however, this is not applicable to outfit maker applications where users create their own outfits and need to know which specific items may be incompatible with the rest of the outfit. to address this, we propose the visual incompatibility transformer (victor) that is optimized for two tasks: 1) overall compatibility as regression and 2) the detection of mismatching items and utilize fashion-specific contrastive language-image pre-training for fine tuning computer vision neural networks on fashion imagery. we build upon the polyvore outfit benchmark to generate partially mismatching outfits, creating a new dataset termed polyvore-misfits, that is used to train victor. a series of ablation and comparative analyses show that the proposed architecture can compete and even surpass the current state-of-the-art on polyvore datasets while reducing the instance-wise floating operations by 88%, striking a balance between high performance and efficiency. we release our code at https://github.com/stevejpapad/visual-incompatibility-transformer",AB_0565
"modern approaches to supervised learning like deep neural networks (dnns) typically implicitly assume that observed responses are statistically independent. in contrast, correlated data are prevalent in real-life large-scale applications, with typical sources of correlation including spatial, temporal and clustering structures. these correlations are either ignored by dnns, or ad-hoc solutions are developed for specific use cases. we propose to use the mixed models framework to handle correlated data in dnns. by treating the effects underlying the correlation structure as random effects, mixed models are able to avoid overfitted parameter estimates and ultimately yield better predictive performance. the key to combining mixed models and dnns is using the gaussian negative log-likelihood (nll) as a natural loss function that is minimized with dnn machinery including stochastic gradient descent (sgd). since nll does not decompose like standard dnn loss functions, the use of sgd with nll presents some theoretical and implementation challenges, which we address. our approach which we call lmmnn is demonstrated to improve performance over natural competitors in various correlation scenarios on diverse simulated and real datasets. our focus is on a regression setting and tabular datasets, but we also show some results for classification. our code is available at https://github.com/gsimchoni/lmmnn.",AB_0565
"brain tumors are one of the leading causes of death in adults. they come in various shapes and sizes from one patient to another. sometimes, they infiltrate surrounding normal tissues, making it challenging to delineate tumor boundaries. despite extensive research, the prognosis is still low. accurate and timely brain tumor segmentation is critical for treatment planning and disease progression monitoring. automatic segmentation of brain tumors using deep learning methods has produced high-quality and reproducible segmentation results. specifically, the encoder-decoder networks, like the u-nets, have dominated the previous brats challenges because of their superior performance. due to the importance of high-quality segmentation, most state-of-the-art models focus more on pushing the boundaries of the current methods at the expense of computational complexity. the computational budget for practical applications is minimal, requiring technological solutions that balance accuracy and available computational resources. in this study, we extended the u-net model in the nnu-net by replacing the basic 3d convolution blocks with bottleneck units utilizing depthwise-separable convolutions. furthermore, we introduced the shuffle attention mechanism in the skip connections to compensate for the slight loss in segmentation accuracy due to a reduction in the number of parameters. on the brain tumor dataset brats 2020, our network achieves dice scores of 79.2%, 91.2%, and 84.8% for enhancing tumor (et), whole tumor (wt), and tumor core (tc), respectively, with only 2.51m parameters and 55.26g flops. extensive experimental results of the brats 2020 dataset reviewed that the proposed modifications achieved competitive performance at a lower computational cost. the code for this project is available at https://github.com/tmagadza/efficientnnunet.git.",AB_0565
"the effectiveness of network intrusion detection systems, predominantly based on machine learning, is highly influenced by the dataset they are trained on. ensuring an accurate reflection of the multifaceted nature of benign and malicious traffic in these datasets is paramount for creating ids models capable of recognizing and responding to a wide array of intrusion patterns. however, existing datasets often fall short, lacking the necessary diversity and alignment with the contemporary network environment, thereby limiting the effectiveness of intrusion detection. this paper introduces tii-ssrc-23, a novel and comprehensive dataset designed to overcome these challenges. comprising a diverse range of traffic types and subtypes, our dataset is a robust and versatile tool for the research community. additionally, we conduct a feature importance analysis, providing vital insights into critical features for intrusion detection tasks. through extensive experimentation, we also establish firm baselines for supervised and unsupervised intrusion detection methodologies using our dataset, further contributing to the advancement and adaptability of ids models in the rapidly changing landscape of network security. our dataset is available at https://kaggle.com/datasets/daniaherzalla/tii-ssrc-23.",AB_0565
"skeleton-based human action recognition with graph convolutional networks is an active research field that has gained increased popularity over the last few years. a challenge in skeleton-based action recognition is the design of a model in a way that captures fine-grained motions and the relations between the movements of different parts of the skeleton towards the recognition of specific actions. in this paper, the use of a set of part-aware graphs for the skeleton representation is proposed aiming to enhance discrimination between actions in the recognition task since each action put emphasis on specific parts of the skeleton. extensive experimental work has been carried out in a consistent evaluation framework taking into account different combinations of part-aware graphs and feature representations leading to a configuration that achieves the optimal balance. based upon two well-established datasets, namely ntu rgb+d and ntu rgb+d 120, we demonstrate that the proposed methodology compares favourably with the state-of-the-art. code is publicly available at: https://github.com/joyios1/improving-skeleton-based-action-recognition-using-part-aware-graphs-in-a-multi-stream-fusion-context.",AB_0565
"in this research work, we proposed a novel childgan, a pair of gan networks for generating synthetic boys and girls facial data derived from stylegan2. childgan is built by performing smooth domain transfer using transfer learning. it provides photo-realistic, high-quality data samples. a large-scale dataset is rendered with a variety of smart facial transformations: facial expressions, age progression, eye blink effects, head pose, skin and hair color variations, and variable lighting conditions. the dataset comprises more than 300k distinct data samples. further, the uniqueness and characteristics of the rendered facial features are validated by running different computer vision application tests which include cnn-based child gender classifier, face localization and facial landmarks detection test, identity similarity evaluation using arcface, and lastly running eye detection and eye aspect ratio tests. the results demonstrate that synthetic child facial data of high quality offers an alternative to the cost and complexity of collecting a large-scale dataset from real children. the complete dataset along with the trained model are open-sourced on our github website and github page: https://github.com/mali-farooq/childgan.",AB_0565
"the co-authorship recommendation problem is attractive since it helps researchers extend collaboration to improve the quality of scientific articles as well as promote innovation. this problem involves suggesting authors join research groups based on their research interests, areas of expertise, and past collaborative experiences to write scientific articles together. in this paper, we tackle the co-authorship recommendation problem by modeling it as a co-authorship network, where each author is represented as a vertex, and each collaboration between two authors is represented as an edge. since the number of author pairs without collaboration is much larger than those with collaboration, datasets created from co-authorship networks are typically two-class imbalanced datasets. accordingly, we propose an improved algorithm of adaboost combined with the w-svm algorithm, called im.adaboost.w-svm, to solve the classification problem with two-class imbalanced datasets. to evaluate the performance of our im.adaboost.w-svm algorithm for the co-authorship recommendation problem, we collected author and article data from the website https://www.sciencedirect.com through sciencedirect apis and created two-class imbalanced datasets. our experimental results for our self-built co-authorship datasets with different sizes and imbalance ratios showed that our im.adaboost.w-svm algorithm outperforms the adaboost.decisiontree and adaboost.w-svm algorithms for the co-authorship recommendation problem.",AB_0565
"we present a novel end-to-end framework for solving the vehicle routing problem with stochastic demands (vrpsd) using reinforcement learning (rl). our formulation incorporates the correlation between stochastic demands through other observable stochastic variables, thereby offering an experimental demonstration of the theoretical premise that non-i.i.d. stochastic demands provide opportunities for improved routing solutions. our approach bridges the gap in the application of rl to vrpsd and consists of a parameterized stochastic policy optimized using a policy gradient algorithm to generate a sequence of actions that form the solution. our model outperforms previous state-of-the-art metaheuristics and demonstrates robustness to changes in the environment, such as the supply type, vehicle capacity, correlation, and noise levels of demand. moreover, the model can be easily retrained for different vrpsd scenarios by observing the reward signals and following feasibility constraints, making it highly flexible and scalable. these findings highlight the potential of rl to enhance the transportation efficiency and mitigate its environmental impact in stochastic routing problems. our implementation is available in https://github.com/zangir/svrp.",AB_0565
"adaptive sampling that exploits the spatiotemporal redundancy in videos is critical for always-on action recognition on wearable devices with limited computing and battery resources. the commonly used fixed sampling strategy is not context-aware and may under-sample the visual content, and thus adversely impacts both computation efficiency and accuracy. inspired by the concepts of foveal vision and pre-attentive processing from the human visual perception mechanism, we introduce a novel adaptive spatiotemporal sampling scheme for efficient action recognition. our system pre-scans the global scene context at low-resolution and decides to skip or request high-resolution features at salient regions for further processing. we validate the system on epic-kitchens and ucf-101 (split-1) datasets for action recognition, and show that our proposed approach can greatly speed up inference with a tolerable loss of accuracy compared with those from state-of-the-art baselines. source code is available in https://github.com/knmac/adaptive_spatiotemporal.",AB_0565
